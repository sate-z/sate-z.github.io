{"meta":{"title":"SateZheng","subtitle":"多读书，多看报，少吃零食，多睡觉","description":null,"author":"SateZheng","url":"http://yoursite.com"},"pages":[{"title":"","date":"2016-12-15T05:18:23.000Z","updated":"2016-12-15T05:47:06.000Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"作者： SateZheng简书地址：传送"}],"posts":[{"title":"Python_ConfigParser模块","slug":"Python-ConfigParser模块","date":"2017-01-16T08:01:59.000Z","updated":"2017-01-16T08:04:56.000Z","comments":true,"path":"2017/01/16/Python-ConfigParser模块/","link":"","permalink":"http://yoursite.com/2017/01/16/Python-ConfigParser模块/","excerpt":"","text":"ConfigParser 可以用来读取配置文件。是一个内置模块，不需要独立安装 简单读取配置文件示例 read(filename) 直接读取文件内容 get(section, option) 获取section 下具体某一配置项的值(返回的是字符串) sections() 得到所有的section，并以列表的形式返回 options(section) 得到该section的所有option items(section) 键值对的形式 得到该section的所有option getint(section,option)、cnf.getboolean(section,option)、getfloat(section,option) 获取整型、布尔型和浮点型的option的值 有配置文件set.ini如下： 12345678910[mysql] # sectiondb_ip = 127.0.0.1db_port = 3306db_user = mysqldb_pass = mysql[redis] # sectionredis_ip = 127.0.0.1redis_port = 3978redis_user = redis read(filename) 直接读取文件内容1234In [2]: cnf = ConfigParser.ConfigParser()In [4]: cnf.read('set.ini')Out[4]: ['set.ini'] get(section, option) 获取section 下具体某一配置项的值(返回的是字符串)12In [6]: cnf.get('mysql', 'db_port')Out[6]: '3306' sections() 得到所有的section，并以列表的形式返回12In [7]: cnf.sections()Out[7]: ['mysql', 'redis'] options(section) 得到该section的所有option12In [9]: cnf.options('mysql')Out[9]: ['db_ip', 'db_port', 'db_user', 'db_pass'] items(section) 键值对的形式 得到该section的所有option123456In [10]: cnf.items('mysql')Out[10]:[('db_ip', '127.0.0.1'), ('db_port', '3306'), ('db_user', 'mysql'), ('db_pass', 'mysql')] getint(section,option)、cnf.getboolean(section,option)、getfloat(section,option) 获取整型、布尔型和浮点型的option的值12345In [13]: cnf.getint('mysql', 'db_port')Out[13]: 3306In [15]: cnf.getfloat('mysql', 'db_port')Out[15]: 3306.0 简单的写入配置文件示例 add_section(section) 添加一个新的section set(section, option, value) 对section中添加 option 和 value remove_section(section) 删除某个 section remove_option(section, option) 删除某个 section 下的 option write() 将设置的新的 section 和 option 写到文件中 add_section(section) 添加一个新的section1In [16]: cnf.add_section('mongo') set(section, option, value) 对section中添加 option 和 value123In [17]: cnf.set('mongo', 'mongo_ip', '127.0.0.2')In [18]: cnf.set('mongo', 'mongo_port', 27001) write() 将设置的新的 section 和 option 写到文件中123456789In [19]: with open('set.ini', 'w+') as f: ...: cnf.write(f)# 看文件$ cat set.ini...[mongo]mongo_ip = 127.0.0.2mongo_port = 27001 remove_option(section, option) 删除某个 section 下的 option1234567891011In [20]: cnf.remove_option('mongo', 'mongo_port')Out[20]: TrueIn [21]: with open('set.ini', 'w+') as f: ...: cnf.write(f)# 看文件$ cat set.ini...[mongo]mongo_ip = 127.0.0.2 remove_section(section) 删除某个 section12345In [22]: cnf.remove_section('mongo')Out[22]: TrueIn [23]: with open('set.ini', 'w+') as f: ...: cnf.write(f)","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python 模块","slug":"Python-模块","permalink":"http://yoursite.com/tags/Python-模块/"}]},{"title":"Python_collections模块--deque","slug":"Python-collections模块-deque","date":"2017-01-09T07:51:36.000Z","updated":"2017-01-09T07:52:15.000Z","comments":true,"path":"2017/01/09/Python-collections模块-deque/","link":"","permalink":"http://yoursite.com/2017/01/09/Python-collections模块-deque/","excerpt":"","text":"deque 线程安全的双向队列 append(x) 在队列的右边添加 x 12345678In [104]: q = collections.deque()In [105]: q.append(1)In [106]: q.append(2)In [107]: qOut[107]: deque([1, 2]) appendleft(x) 在队列的左边添加 x 1234In [108]: q.appendleft(4)In [109]: qOut[109]: deque([4, 1, 2]) clear() 清除队列 count(x) 计算队列中等于 x 的元素个数 12345678In [116]: qOut[116]: deque([2, 4, 1, 2])In [117]: q.count(2)Out[117]: 2In [118]: q.count(1)Out[118]: 1 extend(iterable) 在队列的右边扩展可迭代的队列 1234In [119]: q.extend([6,7,8])In [120]: qOut[120]: deque([2, 4, 1, 2, 6, 7, 8]) extendleft(iterable) 在队列的左边扩展可迭代的队列 pop() 取出并删除右边的第一个元素 popleft() 取出并删除左边的第一个元素 remove(value) 删除队列中第一个匹配的元素 1234567In [120]: qOut[120]: deque([2, 4, 1, 2, 6, 7, 8])In [122]: q.remove(2)In [123]: qOut[123]: deque([4, 1, 2, 6, 7, 8]) reverse() 反转队列，返回None rotate(n) 队列向右旋转n， 如果n是负值，则向左 1234567In [127]: qOut[127]: deque([1, 4, 8, 7, 6, 2])In [128]: q.rotate(3)In [131]: qOut[131]: deque([7, 6, 2, 1, 4, 8])","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python模块","slug":"Python模块","permalink":"http://yoursite.com/tags/Python模块/"},{"name":"collections","slug":"collections","permalink":"http://yoursite.com/tags/collections/"}]},{"title":"Python_collections模块--nametuple","slug":"Python-collections模块-nametuple","date":"2017-01-09T07:50:26.000Z","updated":"2017-01-09T07:51:12.000Z","comments":true,"path":"2017/01/09/Python-collections模块-nametuple/","link":"","permalink":"http://yoursite.com/2017/01/09/Python-collections模块-nametuple/","excerpt":"","text":"nametuple 可命名元祖nametuple 为元祖中每个位置分配含义，可以在使用常规元祖的地方使用，并且添加了通过名称而不是位置索引访问字段的功能。 123456789101112In [97]: Mytuple = collections.namedtuple('mytuple', ['x','y'])In [98]: Mytuple(1,2)Out[98]: mytuple(x=1, y=2)In [101]: n = Mytuple(1,2)In [102]: nOut[102]: mytuple(x=1, y=2)In [103]: n.xOut[103]: 1","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python模块","slug":"Python模块","permalink":"http://yoursite.com/tags/Python模块/"},{"name":"collections","slug":"collections","permalink":"http://yoursite.com/tags/collections/"}]},{"title":"Python_collections模块--defaultdict","slug":"Python-collections模块-defaultdict","date":"2017-01-09T07:49:06.000Z","updated":"2017-01-09T07:50:07.000Z","comments":true,"path":"2017/01/09/Python-collections模块-defaultdict/","link":"","permalink":"http://yoursite.com/2017/01/09/Python-collections模块-defaultdict/","excerpt":"","text":"http://python.usyiyi.cn/python_278/library/collections.html class collections.defaultdict([default_factory[, ...]]) 可以为字典中的value设置默认类型 第一个参数提供的初始值为default_factory属性 ；它将默认为None。所有其余的参数是相同的处理，就像他们被传递到字典构造函数包括关键字参数. 使用列表，作为default_factory，会默认将字典中的value值作为列表处理123456789101112131415In [90]: dict1 = collections.defaultdict(list)In [91]: dict1['k1'].append(1)In [92]: dict1Out[92]: defaultdict(list, &#123;'k1': [1]&#125;)# 官方示例&gt;&gt;&gt; s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]&gt;&gt;&gt; d = defaultdict(list)&gt;&gt;&gt; for k, v in s:... d[k].append(v)...&gt;&gt;&gt; d.items()[('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])]","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python模块","slug":"Python模块","permalink":"http://yoursite.com/tags/Python模块/"},{"name":"collections","slug":"collections","permalink":"http://yoursite.com/tags/collections/"}]},{"title":"Python_collections模块--OrderedDict","slug":"Python-collections模块-OrderedDict","date":"2017-01-09T07:41:08.000Z","updated":"2017-01-09T07:42:09.000Z","comments":true,"path":"2017/01/09/Python-collections模块-OrderedDict/","link":"","permalink":"http://yoursite.com/2017/01/09/Python-collections模块-OrderedDict/","excerpt":"","text":"OrderedDict 有序字典字典是无序的，可以通过OrderedDict使其有序。当对字典做迭代时，它会严格按照元素的初始的添加的顺序进行。 1234567891011121314151617181920212223In [60]: o1 = collections.OrderedDict()In [79]: o1['foo'] = 1In [80]: o1['bar'] = 2In [81]: o1['spam'] = 3In [82]: o1['grok'] = 4In [83]: o1['aa'] = 5In [84]: o1Out[84]: OrderedDict([('foo', 1), ('bar', 2), ('spam', 3), ('grok', 4), ('aa', 5)])In [87]: for key in o1: ...: print key, o1[key] ...:foo 1bar 2spam 3grok 4aa 5 由于有序字典会记住其插入顺序，因此可以与排序结合使用以创建排序字典 1234567891011121314&gt;&gt;&gt; # regular unsorted dictionary&gt;&gt;&gt; d = &#123;'banana': 3, 'apple': 4, 'pear': 1, 'orange': 2&#125;&gt;&gt;&gt; # dictionary sorted by key&gt;&gt;&gt; OrderedDict(sorted(d.items(), key=lambda t: t[0]))OrderedDict([('apple', 4), ('banana', 3), ('orange', 2), ('pear', 1)])&gt;&gt;&gt; # dictionary sorted by value&gt;&gt;&gt; OrderedDict(sorted(d.items(), key=lambda t: t[1]))OrderedDict([('pear', 1), ('orange', 2), ('banana', 3), ('apple', 4)])&gt;&gt;&gt; # dictionary sorted by length of the key string&gt;&gt;&gt; OrderedDict(sorted(d.items(), key=lambda t: len(t[0])))OrderedDict([('pear', 1), ('apple', 4), ('orange', 2), ('banana', 3)])","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python模块","slug":"Python模块","permalink":"http://yoursite.com/tags/Python模块/"},{"name":"collections","slug":"collections","permalink":"http://yoursite.com/tags/collections/"}]},{"title":"Python_collections模块--Counter","slug":"Python-collections模块-Counter","date":"2017-01-09T07:38:19.000Z","updated":"2017-01-09T07:40:31.000Z","comments":true,"path":"2017/01/09/Python-collections模块-Counter/","link":"","permalink":"http://yoursite.com/2017/01/09/Python-collections模块-Counter/","excerpt":"","text":"https://docs.python.org/2/library/collections.html collections是Python内建的一个高性能容器数据类型，提供了许多有用的集合类。 namedtuple() :生成可以使用名字来访问元素内容的tuple子类 deque: 双端队列，可以快速的从另外一侧追加和推出对象 Counter: 计数器，主要用来计数 OrderedDict: 有序字典 defaultdict: 带有默认值的字典 Counter 计数器 列表重复元素的计数 12345678910111213141516171819202122In [3]: import collections# 列表重复元素的计数In [4]: c1 = collections.Counter('aaabbbsssdc')In [5]: print c1Counter(&#123;'a': 3, 's': 3, 'b': 3, 'c': 1, 'd': 1&#125;)# 空的计数器In [44]: c = collections.Counter()In [45]: cOut[45]: Counter()# 通过映射关系生成的计数器In [46]: c = collections.Counter(&#123;'red': 4, 'blue': 2&#125;)In [47]: cOut[47]: Counter(&#123;'blue': 2, 'red': 4&#125;)# 通过关键字生成的计数器In [48]: c = collections.Counter(cats=4, dogs=8)In [49]: cOut[49]: Counter(&#123;'cats': 4, 'dogs': 8&#125;) most_common(n) – 列出最多的前n项 12In [13]: c1.most_common(3)Out[13]: [('a', 3), ('s', 3), ('b', 3)] elements() – 以迭代器的方式取数据，如果某个元素的计数是负值，则忽略 12345678# elements() -- 以迭代器的方式取数据，如果某个元素的计数是负值，则忽略In [20]: c3 = collections.Counter(a=3, b=3, c=0, d=-2)In [21]: c3.elements()Out[21]: &lt;itertools.chain at 0x109127610&gt;In [22]: list(c3.elements())Out[22]: ['a', 'a', 'a', 'b', 'b', 'b'] subtract – 从可迭代或从另一映射（或计数器）中减去元素 123456789# subtract -- 从可迭代或从另一映射（或计数器）中减去元素In [25]: c = collections.Counter(a=4, b=2, c=0, d=-2)In [26]: d = collections.Counter(a=1, b=2, c=3, d=4)In [27]: c.subtract(d)In [28]: cOut[28]: Counter(&#123;'a': 3, 'b': 0, 'c': -3, 'd': -6&#125;) update – 和 subtract 相反，元素相加 123456789# update -- 和 subtract 相反，元素相加In [29]: c = collections.Counter(a=4, b=2, c=0, d=-2)In [30]: d = collections.Counter(a=1, b=2, c=3, d=4)In [31]: c.update(d)In [32]: cOut[32]: Counter(&#123;'a': 5, 'b': 4, 'c': 3, 'd': 2&#125;) clear – 清除 1234567In [33]: c1Out[33]: Counter(&#123;'a': 3, 'b': 3, 'c': 1, 'd': 1, 's': 3&#125;)In [34]: c1.clear()In [35]: c1Out[35]: Counter() 字典重复Key的计数 1234567891011# 字典重复Key的计数In [8]: dic1 = &#123; ...: 'a': 1, ...: 'b': 2, ...: 'a': 1, ...: 'a': 3&#125;In [10]: c2 = collections.Counter(dic1)In [11]: print c2Counter(&#123;'a': 3, 'b': 2&#125;)In [12]: c2['a']Out[12]: 3","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python模块","slug":"Python模块","permalink":"http://yoursite.com/tags/Python模块/"},{"name":"collections","slug":"collections","permalink":"http://yoursite.com/tags/collections/"}]},{"title":"Python_Scrapy入门","slug":"Python-Scrapy入门","date":"2016-12-15T10:25:47.000Z","updated":"2016-12-15T10:26:22.000Z","comments":true,"path":"2016/12/15/Python-Scrapy入门/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-Scrapy入门/","excerpt":"","text":"参考官方文档：http://scrapy-chs.readthedocs.io/zh_CN/1.0/intro/tutorial.html#spider 安装安装分别在ubunut和MAC系统下安装，过程如下： ubuntu系统： 123# 使用pip安装Scrapysudo pip install Scrapy# 遇到报错，报哪个包没有，就是用pip安装哪个 MAC系统: 12345678# 先确保已经安装 xcodexcode-select --install# 使用 pip 安装 Scrapysudo pip install Scrapy# 遇到报错 关于six-1.4.1的，无法升级到新的版本。如下两种解决办法：1、 sudo pip install scrapy --ignore-installed six # 跳过2、 sudo easy_install \"six&gt;=1.5.2\" # 使用easy_install 升级six。然后安装 创建项目：1234567891011121314151617181920$ scrapy startproject tutorial # 创建项目$ cd tutorial/ ; tree # 进入到目录，并展示目录结构.├── scrapy.cfg└── tutorial ├── __init__.py ├── items.py # 保存爬去到的数据的容器,继承 scrapy.Item 类 ├── pipelines.py ├── settings.py └── spiders └── __init__.py └── dmoz_spider.py # 该文件为自己创建，继承 scrapy.Spider 类。定义属性： # name（唯一，区别spider） # start_urls（spider启动时进行爬去的列表，第一个被获取到 的页面将是其中之一。 后续的URL则从初始的URL获取到的数据中提 取） # pasrse() 方法，被调用时，每个初始URL完成下载后生成的 Response 对象将会作为唯一的参数传递给该函数。 该方法负责解 析返回的数据(response data)，提取数据(生成item)以及生成 需要进一步处理的URL的 Request 对象。 编写第一个爬虫目的：获取url页面源码。(并未用到上边定义的Items) 创建一个spider，继承scrapy.Spider类，并定义一些属性： name: 用于区别Spider。 该名字必须是唯一的，不可以为不同的Spider设定相同的名字。 start_urls: 包含了Spider在启动时进行爬取的url列表。 因此，第一个被获取到的页面将是其中之一。 后续的URL则从初始的URL获取到的数据中提取 parse(): 是spider的一个方法。 被调用时，每个初始URL完成下载后生成的Response(页面内容)对象将会作为唯一的参数传递给该函数。 该方法负责解析返回的数据(response data)，提取数据(生成item)以及生成需要进一步处理的URL的Request对象。 在tutorial/spiders目录中创建dmoz_spider.py，如下： 123456789101112131415161718192021222324#coding=utf-8import scrapyclass DmozSpider(scrapy.Spider): name = \"dmoz\" allow_domains = [\"dmoz.org\"] start_urls = [ \"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/\", \"http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/\" ]#----- 从start_urls中读取页面源码信息,并写入本地---# def parse(self,response): # reponse.body 会输出请求url的源码,response.url 是所请求的 url 地址 # 通过下面的输出语句发现，start_urls 中的url地址的请求结果被分别带入到该方法中。 print \"debug---------\" print response.body print response.url print \"debug----------\" # 过滤出请求 url 地址的最后一段，并以该段的名字来创建文件，并写入对应的网页源码。 filename = response.url.split(\"/\")[-2] + '.html' with open(filename,\"wb\") as f: f.write(response.body) 执行： 进入项目的根目录，执行下列命令启动spider 1$ scrapy crawl dmoz 执行结果：在项目目录下，会生成两个文件，Books.html和Resources.html，文件内容分别是两个url页面的源码。 编写第二个项目（从选定的url地址中提取我们想要的信息）定义Item Item是保存爬取到的数据的容器。其使用方法和字典类似，虽然可以在Scrapy中直接使用dict，但是Item提供了额外保护机制来避免拼写错误导致的未定义字段错误。 编辑tutorial目录中的items.py文件,根据我们需要获取到的数据对item进行建模。下边分别定义了title、url和网站的描述。 123456789101112131415# -*- coding: utf-8 -*-# Define here the models for your scraped items## See documentation in:# http://doc.scrapy.org/en/latest/topics/items.htmlimport scrapyclass TutorialItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() title = scrapy.Field() link = scrapy.Field() desc = scrapy.Field() 通过开发者工具对页面的源码进行分析，我们要提取的信息如下： 在tutorial/spiders目录中创建dmoz_spider.py，如下： 12345678910111213141516171819202122#coding=utf-8import scrapyfrom tutorial.items import DmozItemclass DmozSpider(scrapy.Spider): name = \"dmoz\" allow_domains = [\"dmoz.org\"] start_urls = [ \"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/\", \"http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/\" ]# ----- 从start_urls中的页面源码中提取自己需要的,title、link、简介 def parse(self, response): for sel in response.xpath('//*[@class=\"title-and-desc\"]'): # item 对象是自定义的 python 字典，可以使用标准的字典语法来获取到每个段子的值，字段就是之前在items.py文件中用Field赋值的属性。 item = DmozItem() item['title'] = sel.xpath('a/div/text()').extract() item['link'] = sel.xpath('a/@href').extract() item['desc'] = sel.xpath('div/text()').extract() yield item 执行： 进入项目的根目录，执行下列命令启动spider 1$ scrapy crawl dmoz 在输出的debug信息中，可以看到生成的items列表。更直观一点可以将items写入文件： 12$ scrapy crawl dmoz -o items.json -t josn# -o 指定文件名称 -t 指定格式 查看items.json内容： 123456$ cat items.json | head -n 5[&#123;\"title\": [\"eff-bot's Daily Python URL \"], \"link\": [\"http://www.pythonware.com/daily/\"], \"desc\": [\"\\r\\n\\t\\t\\t\\r\\n Contains links to assorted resources from the Python universe, compiled by PythonWare.\\r\\n \", \"\\r\\n \"]&#125;,&#123;\"title\": [\"O'Reilly Python Center \"], \"link\": [\"http://oreilly.com/python/\"], \"desc\": [\"\\r\\n\\t\\t\\t\\r\\n Features Python books, resources, news and articles.\\r\\n \", \"\\r\\n \"]&#125;,&#123;\"title\": [\"Python Developer's Guide \"], \"link\": [\"https://www.python.org/dev/\"], \"desc\": [\"\\r\\n\\t\\t\\t\\r\\n Resources for reporting bugs, accessing the Python source tree with CVS and taking part in the development of Python.\\r\\n \", \"\\r\\n \"]&#125;,&#123;\"title\": [\"Social Bug \"], \"link\": [\"http://win32com.goermezer.de/\"], \"desc\": [\"\\r\\n\\t\\t\\t\\r\\n Scripts, examples and news about Python programming for the Windows platform.\\r\\n \", \"\\r\\n \"]&#125; 追踪链接项目上边两个项目，url地址都是直接给出，现在需要将一个页面中的url地址提取出来，并依次进行处理。 取http://www.dmoz.org/Computers/Programming/Languages/Python/中Related categories部分的url地址。如图： 更改tutorial/items.py文件，加入fromurl，来表明这个信息来自哪个链接。如下： 12345678910111213141516# -*- coding: utf-8 -*-# Define here the models for your scraped items## See documentation in:# http://doc.scrapy.org/en/latest/topics/items.htmlimport scrapyclass DmozItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() title = scrapy.Field() link = scrapy.Field() desc = scrapy.Field() fromurl = scrapy.Field() 在tutorial/spiders目录中创建dmoz_spider.py，如下： 1234567891011121314151617181920212223242526272829#coding=utf-8import scrapyfrom tutorial.items import DmozItemclass DmozSpider(scrapy.Spider): name = \"dmoz\" allow_domains = [\"dmoz.org\"] start_urls = [ \"http://www.dmoz.org/Computers/Programming/Languages/Python/\" ]# ----- 追踪链接----# def parse(self, response):# 提取需要爬取的链接，产生(yield)一个请求， 该请求使用 parse_dir_contents() 方法作为回调函数, 用于最终产生我们想要的数据.。 print response.url for link in response.xpath('//div[@class=\"see-also-row\"]/a/@href'): url = response.urljoin(link.extract()) yield scrapy.Request(url,callback=self.parse_dir_contents) def parse_dir_contents(self,response):# 提取信息，放入item中。这边增加了一个fromurl，所以在items.py 文件中，也要加入。 for sel in response.xpath('//*[@class=\"title-and-desc\"]'): item = DmozItem() item['title'] = sel.xpath('a/div/text()').extract() item['link'] = sel.xpath('a/@href').extract() item['fromurl'] = response.url item['desc'] = sel.xpath('div/text()').extract() yield item 执行： 进入项目的根目录，执行下列命令启动spider 1$ scrapy crawl dmoz -o items1.json -t josn 查看items1.json内容： 123456cat items2.json | head -n 5[&#123;\"link\": [\"http://en.wikipedia.org/wiki/Bytecode\"], \"title\": [\"Bytecode \"], \"fromurl\": \"http://www.dmoz.org/Computers/Programming/Languages/Interpreted/Bytecode/\", \"desc\": [\"\\r\\n\\t\\t\\t\\r\\n Growing article, with links to many related topics. [Wikipedia, open content, GNU FDL]\\r\\n \", \"\\r\\n \"]&#125;,&#123;\"link\": [\"http://www.parrotcode.org/\"], \"title\": [\"Parrotcode \"], \"fromurl\": \"http://www.dmoz.org/Computers/Programming/Languages/Interpreted/Bytecode/\", \"desc\": [\"\\r\\n\\t\\t\\t\\r\\n Home of Parrot Virtual Machine, made for dynamic languages, originally a target for Perl 6 compiler, hosts many language implementations in varied stages of completion: Tcl, Javascript, Ruby, Lua, Scheme, PHP, Python, Perl 6, APL, .NET. Open source.\\r\\n \", \"\\r\\n \"]&#125;,&#123;\"link\": [\"http://vvm.lip6.fr/\"], \"title\": [\"Virtual Virtual Machine \"], \"fromurl\": \"http://www.dmoz.org/Computers/Programming/Languages/Interpreted/Bytecode/\", \"desc\": [\"\\r\\n\\t\\t\\t\\r\\n VVM overview, history, members, projects, realizations, publications.\\r\\n \", \"\\r\\n \"]&#125;,&#123;\"link\": [\"http://os.inf.tu-dresden.de/L4/l3elan.html\"], \"title\": [\"ELAN \"], \"fromurl\": \"http://www.dmoz.org/Computers/Programming/Languages/Multiparadigm/\", \"desc\": [\"\\r\\n\\t\\t\\t\\r\\n Created 1974 by Technical University of Berlin group, as alternative to BASIC in teaching, for systematic programming, and related styles: top-down, bottom-up, recursive, modular, syntax-directed. Descriptions, brief resource list, documents. English, Deutsch.\\r\\n \", \"\\r\\n \"]&#125;,","categories":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"http://yoursite.com/categories/Python爬虫/"}],"tags":[{"name":"PythonScrapy","slug":"PythonScrapy","permalink":"http://yoursite.com/tags/PythonScrapy/"}]},{"title":"Python_Scrapy命令行工具","slug":"Python-Scrapy命令行工具","date":"2016-12-15T10:24:27.000Z","updated":"2016-12-15T10:25:26.000Z","comments":true,"path":"2016/12/15/Python-Scrapy命令行工具/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-Scrapy命令行工具/","excerpt":"","text":"scrapy.cfg存放的目录认定是 项目的根目录 scrapy 针对不同目的提供了多个命令。 创建项目1$ scrapy startproject my_pro 有些Scrapy命令(比如crawl)要求必须在Scrapy项目中运行，有些则不用 1234567891011121314151617# 全局命令（不需要在项目中执行）：startprojectsettingsrunspidershellfetchviewversion# 项目命令（必须在项目中执行）：crawlchecklisteditparsegenspiderbench 命令注解 startproject 语法:scrapy startproject &lt;project_name&gt; 全局命令 在 project_name 文件夹下创建一个名为 project_name 的Scrapy项目，如上边例子。 genspider 语法:scrapy genspider [-t template] &lt;name&gt; &lt;domain&gt; 项目命令 在当前项目中创建spider。 这仅仅是创建spider的一种快捷方法。该方法可以使用提前定义好的模板来生成spider。您也可以自己创建spider的源码文件。 查看模板的方法如下： 1234567891011121314151617181920212223# 查看模板$ scrapy genspider -lAvailable templates: basic crawl csvfeed xmlfeed# 编辑模板$ scrapy genspider -d basic# -*- coding: utf-8 -*-import scrapyclass $classname(scrapy.Spider): name = \"$name\" allowed_domains = [\"$domain\"] start_urls = ( 'http://www.$domain/', ) def parse(self, response): pass 根据模板来生成spider： 12345678910111213$ scrapy genspider -t basic sina sina.com$ scrapy genspider baidu baidu.com$ scrapy genspider zhihu zhihu.com$ scrapy listbaidusinazhihu$ ls my_pro/spiders/baidu.py baidu.pyc __init__.py __init__.pyc sina.py sina.pyc zhihu.py zhihu.pyc crawl 语法:scrapy crawl &lt;spider&gt; 项目命令 使用spider进行爬取 12# 例子$ scrapy crawl myspider check 语法:scrapy check [-l] &lt;spider&gt; 项目命令 运行contract检查。 list 语法:scrapy list 项目命令 列出当前项目中所有可用的spider。每行输出一个spider。 12345# 例子$ scrapy listbaidusinazhihu edit 语法:scrapy edit &lt;spider&gt; 项目命令 使用 EDITOR 中设定的编辑器编辑给定的spider 12# 例子$ scrapy edit baidu fetch 语法:scrapy fetch &lt;url&gt; 全局命令或项目命令，但结果不同 使用Scrapy下载器(downloader)下载给定的URL 该命令以spider下载页面的方式获取页面。例如，如果spider有 USER_AGENT 属性修改了 User Agent，该命令将会使用该属性。 因此，您可以使用该命令来查看spider如何获取某个特定页面。 该命令如果非项目中运行则会使用默认Scrapy downloader设定。 1234567891011121314151617# 例子：项目外边执行$ scrapy fetch --nolog --headers http://www.baidu.com&gt; Accept-Language: en&gt; Accept-Encoding: gzip,deflate&gt; Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&gt; User-Agent: Scrapy/1.1.1 (+http://scrapy.org)&gt;&lt; Bdqid: 0xfbf98a3b0000db32.........$ scrapy fetch --nolog http://www.baidu.com......... view 语法:scrapy view &lt;url&gt; 全局命令 在浏览器中打开给定的URL，并以Scrapy spider获取到的形式展现。 有些时候spider获取到的页面和普通用户看到的并不相同。 因此该命令可以用来检查spider所获取到的页面，并确认这是您所期望的。 1$ scrapy view http://www.baidu.com shell 语法:scrapy shell [url] 全局命令 以给定的URL(如果给出)或者空(没有给出URL)启动Scrapy shell 12$ scrapy shell$ scrapy shell http://www.baidu.com parse 语法:scrapy parse &lt;url&gt; [options] 全局命令 获取给定的URL并使用相应的spider分析处理。如果您提供 --callback 选项，则使用spider的该方法处理，否则使用 parse 。 settings 语法:scrapy settings [options] 全局命令 获取Scrapy的设定 在项目中运行时，该命令将会输出项目的设定值，否则输出Scrapy默认设定。 1234$ scrapy settings --get BOT_NAMEscrapybot$ scrapy settings --get DOWNLOAD_DELAY0 runspider 语法:scrapy runspider &lt;spider_file.py&gt; 全局命令 在未创建项目的情况下，运行一个编写在Python文件中的spider。 1$ scrapy runspider first_mod.py bench 语法:scrapy bench 全局命令 Scrapy提供了一个简单的性能测试工具。其创建了一个本地HTTP服务器，并以最大可能的速度进行爬取。 该测试性能工具目的是测试Scrapy在您的硬件上的效率，来获得一个基本的底线用于对比。 其使用了一个简单的spider，仅跟进链接，不做任何处理。 1$ scrapy bench","categories":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"http://yoursite.com/categories/Python爬虫/"}],"tags":[{"name":"PythonScrapy","slug":"PythonScrapy","permalink":"http://yoursite.com/tags/PythonScrapy/"}]},{"title":"Python_网络爬虫初识","slug":"Python-网络爬虫初识","date":"2016-12-15T10:22:54.000Z","updated":"2016-12-15T10:23:31.000Z","comments":true,"path":"2016/12/15/Python-网络爬虫初识/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-网络爬虫初识/","excerpt":"","text":"简单的下拉一个网页 1234import urllib2 response = urllib2.urlopen(\"http://120.26.45.230/dis/forum.php\")print response.read() urlopen一般接受三个参数,url、date、timeout url:请求的 URL data:访问 URL 时要传送的数据，默认是none timeout:这是超时时间，默认是socket._GLOBAL_DEFAULT_TIMEOUT 构造 Request: 和上边运行结果一样，中间多了一个request对象，逻辑上更清晰 12345import urllib2request = urllib2.Request(\"http://120.26.45.230/dis/forum.php\")response = urllib2.urlopen(request)print response.read() 在服务器上看nginx 的访问日志是： 1120.26.42.23 - - [29/Jun/2016:17:30:58 +0800] \"GET /dis/forum.php HTTP/1.1\" 200 12964 \"-\" \"Python-urllib/2.7\" POST、GET 数据传送大部分网站是动态页面，需要动态传递参数，如登录网站的时候。 数据传送分为POST和GET两种方式，两种方式有什么区别呢？ 最重要的区别是GET方式是直接以链接形式访问，链接中包含了所有的参数，当然如果包含了密码的话是一种不安全的选择，不过你可以直观地看到自己提交了什么内容。POST则不会在网址上显示所有的参数，不过如果你想直接查看提交了什么就不太方便了，大家可以酌情选择。 POST 方式 下边方式只是介绍 POST 和 GET 方式，可能会被屏蔽掉，因为没有 headers 信息 123456789import urllibimport urllib2values = &#123;\"username\":\"1016903103@qq.com\",\"password\":\"XXXX\"&#125;data = urllib.urlencode(values) url = \"https://passport.csdn.net/account/login?from=http://my.csdn.net/my/mycsdn\"request = urllib2.Request(url,data)response = urllib2.urlopen(request)print response.read() GET 方式 123456789101112import urllibimport urllib2values=&#123;&#125;values['username'] = \"1016903103@qq.com\"values['password']=\"XXXX\"data = urllib.urlencode(values) url = \"http://passport.csdn.net/account/login\"geturl = url + \"?\"+datarequest = urllib2.Request(geturl)response = urllib2.urlopen(request)print response.read() 设置 Headers有些网站会有安全策略，会过滤 Headers，比如上边的访问肯定会被屏蔽。 1120.26.42.23 - - [29/Jun/2016:17:30:58 +0800] \"GET /dis/forum.php HTTP/1.1\" 200 12964 \"-\" \"Python-urllib/2.7\" 设置 headers 中的 agent。 12345678910111213141516171819202122232425#!/usr/bin/env python#coding=utf-8import urllibimport urllib2# 指定访问的 url 地址url = \"http://120.26.45.230/dis/forum.php\"# 设置头信息中的请求agentuser_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'# 用户名和密码，如果不用可以省略values = &#123;'username':'admin','password':'zhaimi'&#125;# User-Agent 设置agent 信息，Referer 来对付防盗链headers = &#123;'User-Agent':user_agent,'Referer':'http://www.zhihu.com/articles'&#125;# 利用urllib的urlencode方法将字典编码data = urllib.urlencode(values)# 请求信息，如果不用密码和用户名，可以改成request = urllib2.Request(url,\"\",headers)request = urllib2.Request(url,data,headers)response = urllib2.urlopen(request)print response.read() Proxy 代理的设置123456789import urllib2enable_proxy = Trueproxy_handler = urllib2.ProxyHandler(&#123;\"http\" : 'http://some-proxy.com:8080'&#125;)null_proxy_handler = urllib2.ProxyHandler(&#123;&#125;)if enable_proxy: opener = urllib2.build_opener(proxy_handler)else: opener = urllib2.build_opener(null_proxy_handler)urllib2.install_opener(opener) 下载，比如一个图片，或者一个其他的文件使用urllib.urlretrieve方法. 1234import urlliburl = \"http://nginx.org/download/nginx-1.8.1.tar.gz\"urllib.urlretrieve(url,\"nginx.tar.gz\")","categories":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"http://yoursite.com/categories/Python爬虫/"}],"tags":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"http://yoursite.com/tags/Python爬虫/"}]},{"title":"Python_网络爬虫_cookies操作","slug":"Python-网络爬虫-cookies操作","date":"2016-12-15T10:21:13.000Z","updated":"2016-12-15T10:23:45.000Z","comments":true,"path":"2016/12/15/Python-网络爬虫-cookies操作/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-网络爬虫-cookies操作/","excerpt":"","text":"摘抄自 http://cuiqingcai.com/968.html 1、Opener当你获取一个URL你使用一个opener(一个urllib2.OpenerDirector的实例)。在前面，我们都是使用的默认的opener，也就是urlopen。它是一个特殊的opener，可以理解成opener的一个特殊实例，传入的参数仅仅是url，data，timeout。 如果我们需要用到Cookie，只用这个opener是不能达到目的的，所以我们需要创建更一般的opener来实现对Cookie的设置。 2、Cookieslibcookielib 模块的主要作用是提供可存储 cookies 的对象，以便于 urllib2 模块配合使用来访问 Internet 资源，我们可以利用本模块的 CookieJar 类的对象来捕获 cookie 并在后续连接请求时重新发送，可实现模拟登陆的功能。 该模块的主要对象有CookieJar、FileCookieJar、MozillaCookieJar、LWPCookieJar 他们的关系：CookieJar —-派生—-&gt;FileCookieJar —-派生—–&gt;MozillaCookieJar和LWPCookieJar 下边会从获取cookies开始，一步步实现模拟登陆 1)、获取cookies并保存到变量中首先，我们先利用CookieJar对象实现获取cookie的功能，存储到变量中 1234567891011121314151617181920212223import urllib2import cookielib# ----------------获取 cookies 保存到变量---------------# 声明一个 CookiesJar 对象实例来保存 cookiescookie = cookielib.CookieJar()# 利用 urllib2库的HTTPCookieProcessor对象来创建 cookie 处理器hander = urllib2.HTTPCookieProcessor(cookie)# 通过 hander 来构建 openeropener = urllib2.build_opener(hander)# 添加 headeropener.addheaders = [(\"User-Agent\",\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36\")]# 此处 open 方法和 urllib2的 urlopen 方法一样,也可以传入 requestresponse1 = opener.open('http://www.baidu.com')# response 变量保存网页信息,cookie 变量保存 cookies 信息print cookiefor i in cookie: print \"Name = \" + i.name print \"Value = \" + i.value 2)、获取cookies保存到文件中1234567891011121314151617181920212223import urllib2import cookielib# ----------------获取 cookies 保存到文件--------------#设置保存cookie的文件，同级目录下的cookie.txtfilename = 'cookie.txt'# 声明一个MozillaCookieJar对象实例来保存cookie，之后写入文件cookie = cookielib.MozillaCookieJar(filename)# 利用urllib2库的HTTPCookieProcessor对象来创建cookie处理器hander = urllib2.HTTPCookieProcessor(cookie)# 通过handler来构建openeropener = urllib2.build_opener(hander)# 添加 headeropener.addheaders = [(\"User-Agent\",\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36\")]# 创建一个请求，原理同urllib2的urlopenresponse2 = opener.open(\"http://www.baidu.com\")# 保存cookie到文件cookie.save(ignore_discard=True,ignore_expires=True) 3)、从文件中获取cookies并访问网站1234567891011121314151617181920212223import urllib2import cookielib# -----------------从文件中获取并访问-------------------# 创建 MozillaCookieJar 实例对象cookie = cookielib.MozillaCookieJar()# 从文件中读取 cookies 内容到变量cookie.load('cookie.txt',ignore_discard=True,ignore_expires=True)# 创建请求的 requestreq = urllib2.Request(\"http://www.baidu.com\")# 利用urllib2库的HTTPCookieProcessor对象来创建cookie处理器hander = urllib2.HTTPCookieProcessor(cookie)# 通过handler来构建openeropener = urllib2.build_opener(hander)# 添加 headeropener.addheaders = [(\"User-Agent\",\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36\")]response3 = opener.open(req)print response3.read()","categories":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"http://yoursite.com/categories/Python爬虫/"}],"tags":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"http://yoursite.com/tags/Python爬虫/"}]},{"title":"Python_模拟登录新浪微博","slug":"Python-模拟登陆新浪微博","date":"2016-12-15T10:19:50.000Z","updated":"2016-12-15T10:23:37.000Z","comments":true,"path":"2016/12/15/Python-模拟登陆新浪微博/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-模拟登陆新浪微博/","excerpt":"","text":"在极客学院中看了一个关于爬虫的视频，然后自己实现一遍，并做此记录。 视频链接：http://www.jikexueyuan.com/course/995_4.html?ss=1 使用requests模块，post需要的表单数据来登录新浪微博手机端（手机端简单点。。），并访问登录后的页面。该方法是定向页面的爬取，如果要批量爬取，使用框架会好一些。 确认登录所需的表单数据chrome浏览器中访问http://weibo.cn/pub/,点击登录，会进入手机端登录页面。登录微博，并通过开发者工具抓包来分析提交的form信息。如下图： 图1：登录页面(有验证码) 图2：打开开发者工具，输入账号密码登录，看需要提交的form信息 根据图2，发现需要提交的form信息有下边几个： 12345678910mobile:login_name #用户名password_8891:login_password #密码（password_8891 这个每次都变）code:fcjf #验证码remember:on #是否记住登录状态，相当于图1中选中的’记住登录状态‘选项backURL:http%3A%2F%2Fweibo.cn%2F #登录成功后返回的页面backTitle:微博tryCount: #尝试的登录次数vk:8891_ea7c_2358890024 # vk（每次登录可能会不一样）capId:2_5cb16cf8473df571 # capIdsubmit:登录 form表单中不固定，需要我们自己取的表单项有password_8891、code、vk、capId。这些值实际上是从图1中带过来的，使用浏览器打开图1的源码，会发现这些选项。如下图图3： 图3：图1登录页面的部分源码基本上我们可以从上图获取到form表单中所需的数据。使用lxml模块来分离出这些信息来。 处理验证码在表单信息中，有一个code的表单项，是图1中的验证码，自动识别验证码现在还不会，只能用人肉识别，处理方式是在图1的源码中取得验证码的url地址，并保存到本地，然后手动输入。 登录login页面使用requests模块登录页面，如果我们想访问一些登录后才能访问的页面，有两种方式。 方法一：一开始就访问目标页面，会跳转到登录页面，当我们成功登录后，会根据表单中的backURL自动跳转到目标页面，从而获取我们需要数据。 方法二：使用requests模块的session保持功能，直接请求登录页面，成功后，因为有cookies，所以我们可以直接访问我们需要的页面。这里使用这种方式。 程序代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# 刚学不久，比较low#!/usr/bin/env python#coding=utf-8import requestsfrom lxml import etreeimport urllib# 使用requests的会话方法s = requests.session()# 定义登录页面和最终要访问的页面（需要登录才能访问）url_login = \"http://login.weibo.cn/login/\"url_final = \"http://weibo.cn/msg/\"# 定义自己微博的账户和密码login_name = \"...\" login_password = \"...\"# 如果使用第一种方式，可以这样请求#res = requests.get(url_final).content# 请求登录页面，获取上面图3所示的源码res = s.get(url_login).content# 使用xpath的方式分离表单信息html = etree.HTML(res)password = html.xpath('//input[@type=\"password\"]/@name')[0]backURL = html.xpath('//input[@name=\"backURL\"]/@value')[0]vk = html.xpath('//input[@name=\"vk\"]/@value')[0]capID = html.xpath('//input[@name=\"capId\"]/@value')[0]codeurl = html.xpath('//img/@src')[0]action = html.xpath('//form/@action')[0]# 拼接 Request URL，用来提交表单，实现登录post_url = url_login + action# 下载验证码到当前目录，并手动输入验证码def download_code(codeurl): urllib.urlretrieve(codeurl,\"code.jpg\") code = raw_input(\"please input the code: \") return codecode = download_code(codeurl)# 定义表单信息post_data = &#123; \"mobile\" : login_name, password : login_password, \"code\" : code, \"remember\" : \"on\", \"backURL\" : backURL, \"backTitle\" : u\"微博\", \"tryCount\" : \"\", \"vk\" : vk, \"capId\" : capID, \"submit\" : u\"登录\"&#125;# 第一种方法，可以使用，返回的源码就是目标地址的源码#do_post = requests.post(post_url,data=post_data).content# 提交表单，完成登录do_post = s.post(post_url,data=post_data).content# 判断返回的页面是否是验证码错误的页面if \"验证码错误\" in do_post: print \"验证码输入错误\"else: # 请求最终页面 print s.get(url_final).content # 后续可以写各种匹配规则，来匹配出需要的信息。","categories":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"http://yoursite.com/categories/Python爬虫/"}],"tags":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"http://yoursite.com/tags/Python爬虫/"}]},{"title":"Python_request模块","slug":"Python-request模块","date":"2016-12-15T10:18:48.000Z","updated":"2016-12-15T10:19:05.000Z","comments":true,"path":"2016/12/15/Python-request模块/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-request模块/","excerpt":"","text":"官方文档链接 ： http://docs.python-requests.org/en/master/ requests模块 最简单的方式请求页面123&gt;&gt;&gt; import requests&gt;&gt;&gt; r = requests.get(\"http://www.baidu.com\")&gt;&gt;&gt; r.text 其他的HTTP请求类型： 12345&gt;&gt;&gt; r = requests.post(\"http://httpbin.org/post\")&gt;&gt;&gt; r = requests.put(\"http://httpbin.org/put\")&gt;&gt;&gt; r = requests.delete(\"http://httpbin.org/delete\")&gt;&gt;&gt; r = requests.head(\"http://httpbin.org/get\")&gt;&gt;&gt; r = requests.options(\"http://httpbin.org/get\") 带有参数的请求页面有时需要为 URL 的查询字符串(query string)传递某种数据，requests允许使用params关键字参数，并以一个字典来提供这些参数。举例如果想传递key1=value1和key2=value2到httpbin.org/get，可以使用如下方式： 1234567891011121314151617&gt;&gt;&gt; payload = &#123;\"key1\":\"value1\",\"key2\":\"value2\"&#125; # 定义传递的参数&gt;&gt;&gt; r = requests.get(\"http://httpbin.org/get\",params=payload) # 请求&gt;&gt;&gt; print r.text&#123; \"args\": &#123; \"key1\": \"value1\", \"key2\": \"value2\" &#125;, \"headers\": &#123; \"Accept\": \"*/*\", \"Accept-Encoding\": \"gzip, deflate\", \"Host\": \"httpbin.org\", \"User-Agent\": \"python-requests/2.10.0\" &#125;, \"origin\": \"180.168.112.222\", \"url\": \"http://httpbin.org/get?key2=value2&amp;key1=value1\"&#125; 读取响应内容1234567&gt;&gt;&gt; r = requests.get(\"http://www.jianshu.com\")&gt;&gt;&gt; print r.text # 可以读取到简书首页的html源码&gt;&gt;&gt; r.encoding # requests 根据头信息推测的编码'utf-8'&gt;&gt;&gt; r.encoding = 'ISO-8859-1' # 改变编码，并重新读取刚刚的页面&gt;&gt;&gt; print r.text # 会发现中文部分乱码 关于编码：requests会自动解码来自服务器的内容，大多数的unicode字符集都能被无缝的解码，请求发出后，requests会基于HTTP头部对响应的编码做出推测。r.encoding可以显示目前使用的编码，也可以赋值为其他的编码。 二进制响应内容可以以字节的方式访问请求响应体，对于非文本请求，requests会自动解码gzip和deflate传输编码的响应数据。 JSON 响应内容requests中也有一个内置的JSON解码器，r.json()来处理JSON数据。 原始响应内容在罕见的情况下，你可能想获取来自服务器的原始套接字响应，那么你可以访问r.raw，并确保初始请求中设置了stream=True。 12345&gt;&gt;&gt; r = requests.get('https://github.com/timeline.json', stream=True)&gt;&gt;&gt; r.raw&lt;requests.packages.urllib3.response.HTTPResponse object at 0x101194810&gt;&gt;&gt;&gt; r.raw.read(10)'\\x1f\\x8b\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x03' 定制 headers为请求添加HTTP头部，只要简单地传递一个dict给headers参数就可以了 1234567891011121314&gt;&gt;&gt; headers = &#123;\"user-agent\":\"hoho\"&#125;&gt;&gt;&gt; r = requests.get(\"http://httpbin.org/get\",headers = headers)&gt;&gt;&gt; print r.text&#123; \"args\": &#123;&#125;, \"headers\": &#123; \"Accept\": \"*/*\", \"Accept-Encoding\": \"gzip, deflate\", \"Host\": \"www.httpbin.org\", \"User-Agent\": \"hoho\" &#125;, \"origin\": \"180.168.112.222\", \"url\": \"http://www.httpbin.org/get\"&#125; 注意: 定制 header 的优先级低于某些特定的信息源，例如： 如果在.netrc中设置了用户认证信息，使用headers=设置的授权就不会生效。而如果设置了 auth=参数，.netrc的设置就无效了。 如果被重定向到别的主机，授权header就会被删除。 代理授权header会被URL中提供的代理身份覆盖掉。 在我们能判断内容长度的情况下,header的Content-Length会被改写。 POST 请求发送数据通常要发送一些编码为表单形式的数据，可以讲一个字典传递给data参数，数据字典在发出请求时会自动编码为表单形式： 123456789101112&gt;&gt;&gt; payload = &#123;'key1': 'value1', 'key2': 'value2'&#125;&gt;&gt;&gt; r = requests.post(\"http://httpbin.org/post\", data=payload)&gt;&gt;&gt; print(r.text)&#123; ... \"form\": &#123; \"key2\": \"value2\", \"key1\": \"value1\" &#125;, ...&#125; 有时候我们需要传送的信息不是表单形式的，需要我们传JSON格式的数据过去，所以我们可以用 json.dumps() 方法把表单数据序列化。 123456&gt;&gt;&gt; import json&gt;&gt;&gt; import requestspayload = &#123;'key1': 'value1', 'key2': 'value2'&#125;r = requests.post(\"http://httpbin.org/post\", data=json.dumps(payload))print r.text","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python模块","slug":"Python模块","permalink":"http://yoursite.com/tags/Python模块/"}]},{"title":"Python_random模块","slug":"Python-random模块","date":"2016-12-15T10:17:59.000Z","updated":"2016-12-15T10:18:30.000Z","comments":true,"path":"2016/12/15/Python-random模块/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-random模块/","excerpt":"","text":"摘自 http://my.oschina.net/cuffica/blog/33336 random用于生成随机数，可以随机生成数字或者选择字符串 1&gt;&gt;&gt; import random random.random 生成一个随机的浮点数，大小在 0.0 到 1.0 之间 12&gt;&gt;&gt; random.random()0.6754760175030391 random.uniform(a,b) 用于生成一个指定范围内的随机浮点数，a,b为上下限，只要a!=b,就会生成介于两者之间的一个浮点数，若a=b，则生成的浮点数就是a 123456&gt;&gt;&gt; random.uniform(1,5)3.5512959593743996&gt;&gt;&gt; random.uniform(5,1)1.7146358802022172&gt;&gt;&gt; random.uniform(5,5)5.0 random.randint(a,b) 用于生成一个指定范围内的整数，a为下限，b为上限，生成的随机整数a&lt;=n&lt;=b;若a=b，则n=a；若a&gt;b，报错 123456789101112&gt;&gt;&gt; random.randint(1,10)9&gt;&gt;&gt; random.randint(10,1) # 报错Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt; File \"/usr/lib/python2.7/random.py\", line 240, in randint return self.randrange(a, b+1) File \"/usr/lib/python2.7/random.py\", line 216, in randrange raise ValueError, \"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width)ValueError: empty range for randrange() (10,2, -8)&gt;&gt;&gt; random.randint(1,1)1 random.randrange([start], stop [,step]) 从指定范围内，按指定基数递增的集合中获取一个随机数，基数缺省值为1 123&gt;&gt;&gt; random.randrange(10,100) #输出为10到100间的任意数&gt;&gt;&gt; random.randrange(10,100,4) #输出为10到100内以4递增的序列[10,14,18,22...]&gt;&gt;&gt; random.choice(range(10,100,4)) #输出在结果上与上一条等效 random.choice(sequence) 从序列中获取一个随机元素，参数sequence表示一个有序类型，并不是一种特定类型，泛指list，tuple，字符串等 12345678&gt;&gt;&gt; random.choice(range(10)) #输出0到10内随机整数&gt;&gt;&gt; random.choice(range(10,100,2)) #输出随机值[10,12,14,16...]&gt;&gt;&gt; random.choice(\"I love python\") #输出随机字符I,o,v,p,y...&gt;&gt;&gt; random.choice((\"I love python\")) #同上&gt;&gt;&gt; random.choice([\"I love python\"]) #输出“I love python”&gt;&gt;&gt; random.choice(\"I\",\"love\",\"python\") #Error&gt;&gt;&gt; random.choice((\"I\",\"love\",\"python\")) #输出随机字符串“I”，“love”，“python”&gt;&gt;&gt; random.choice([\"I\",\"love\",\"python\"]) #输出随机字符串“I”，“love”，“python” random.shuffle(x[,random]) 用于将一个列表中的元素打乱 1234&gt;&gt;&gt; lis = [1,2,3,\"o\",\"b\"]&gt;&gt;&gt; random.shuffle(lis)&gt;&gt;&gt; print lis['b', 3, 1, 'o', 2] random.sample(sequence,k) 从指定序列中随机获取k个元素作为一个片段返回，sample函数不会修改原有序列 1234&gt;&gt;&gt; print lis['b', 3, 1, 'o', 2]&gt;&gt;&gt; random.sample(lis,3)['b', 3, 'o']","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python模块","slug":"Python模块","permalink":"http://yoursite.com/tags/Python模块/"}]},{"title":"Python_psutil模块","slug":"Python-psutil模块","date":"2016-12-15T10:17:03.000Z","updated":"2016-12-15T10:17:20.000Z","comments":true,"path":"2016/12/15/Python-psutil模块/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-psutil模块/","excerpt":"","text":"安装 下载 1https://pypi.python.org 网站下载 安装 123$ tar xvf psutil-4.1.0.tar.gz$ psutil-4.1.0$ python setup.py install 功能psutil 是一个跨平台库，能够轻松的实现获取系统运行的进程和系统利用率（包括cpu、内存、磁盘、网络等）信息。 获取系统性能信息(1) cpu 信息 1234567891011121314151617181920&gt;&gt;&gt; import psutil＃使用 cpu_times 方法获取CPU的完整信息&gt;&gt;&gt; psutil.cpu_times()scputimes(user=29835.75, nice=0.0, system=18475.44, idle=546295.5)&gt;&gt;&gt; psutil.cpu_times().user29851.7&gt;&gt;&gt; psutil.cpu_times().nice0.0# 指定方法变量 percpu=true ,显示所有逻辑cpu信息&gt;&gt;&gt; psutil.cpu_times(percpu=True)[scputimes(user=11854.24, nice=0.0, system=8223.53, idle=128562.62), scputimes(user=3587.42, nice=0.0, system=2143.94, idle=142905.42), scputimes(user=10573.42, nice=0.0, system=5857.35, idle=132206.04), scputimes(user=3817.91, nice=0.0, system=2248.85, idle=142570.0)]＃ 获取cpu逻辑个数，默认方法 logical=True&gt;&gt;&gt; psutil.cpu_count()4＃ 获取cpu物理个数&gt;&gt;&gt; psutil.cpu_count(logical=False)2 (2) 内存信息 Linux系统的内存利用率信息设计total（内存总数）、used（已使用的内存数）、free（空闲内存数）、buffers（缓冲使用数）、cache（缓存使用数）、swap（交换分区使用数）等，分别使用psutil.virtual_memory()与psutil.swap_memory()方法获取。 12345678910111213&gt;&gt;&gt; mem = psutil.virtual_memory()&gt;&gt;&gt; memsvmem(total=1043046400, available=489234432, percent=53.1, used=973860864, free=69185536, active=649924608, inactive=220930048, buffers=105512960, cached=314535936)&gt;&gt;&gt; psutil.virtual_memory()svmem(total=1043046400, available=489242624, percent=53.1, used=973860864, free=69185536, active=649924608, inactive=220938240, buffers=105521152, cached=314535936)&gt;&gt;&gt; psutil.virtual_memory().total1043046400&gt;&gt;&gt; psutil.virtual_memory().free68669440&gt;&gt;&gt; mem.free69185536&gt;&gt;&gt; psutil.swap_memory()sswap(total=0, used=0, free=0, percent=0.0, sin=0, sout=0) (3) 磁盘信息 123456789101112131415# psutil.disk_partitions 获取磁盘完整信息&gt;&gt;&gt; psutil.disk_partitions()[sdiskpart(device='/dev/xvda1', mountpoint='/', fstype='ext4', opts='rw,barrier=0')]# psutil.disk_usage 获取分区（参数）的使用情况&gt;&gt;&gt; psutil.disk_usage('/')sdiskusage(total=42273669120, used=3997454336, free=36128837632, percent=9.5)# psutil.disk_io_counters 获取磁盘总的IO个数&gt;&gt;&gt; psutil.disk_io_counters()sdiskio(read_count=73895, write_count=163753, read_bytes=1255839744, write_bytes=1650024448, read_time=470216, write_time=3454793, read_merged_count=268, write_merged_count=238305, busy_time=362447)# psutil.disk_io_counters(perdisk=Ture) 获取单个分区的IO个数&gt;&gt;&gt; psutil.disk_io_counters(perdisk=True)&#123;'xvda1': sdiskio(read_count=73895, write_count=163784, read_bytes=1255839744, write_bytes=1650151424, read_time=470216, write_time=3454878, read_merged_count=268, write_merged_count=238305, busy_time=362486)&#125; (4) 网络信息 1234567# 获取网络总的IO信息，默认 pernic=False&gt;&gt;&gt; psutil.net_io_counters()snetio(bytes_sent=60804444, bytes_recv=187669805, packets_sent=259503, packets_recv=344634, errin=0, errout=0, dropin=0, dropout=0)# 获取每个网络接口的IO信息&gt;&gt;&gt; psutil.net_io_counters(pernic=True)&#123;'lo': snetio(bytes_sent=22812792, bytes_recv=22812792, packets_sent=91403, packets_recv=91403, errin=0, errout=0, dropin=0, dropout=0), 'eth1': snetio(bytes_sent=36941320, bytes_recv=164227892, packets_sent=154261, packets_recv=245344, errin=0, errout=0, dropin=0, dropout=0), 'eth0': snetio(bytes_sent=1052292, bytes_recv=631555, packets_sent=13857, packets_recv=7922, errin=0, errout=0, dropin=0, dropout=0)&#125; (5) 其他系统信息 123456789101112# 获取当前登陆用户的信息&gt;&gt;&gt; psutil.users()[suser(name='root', terminal='pts/0', host='180.168.112.222', started=1461911552.0)]# 获取开机时长&gt;&gt;&gt; psutil.boot_time()1461576707.0# 将开机时长转换成自然格式&gt;&gt;&gt; import datetime,psutil&gt;&gt;&gt; datetime.datetime.fromtimestamp(psutil.boot_time()).strftime(\"%Y-%m-%d %H:%M:%S\")'2016-04-25 17:31:47' 系统进程管理方法(1) 进程信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&gt;&gt;&gt; import psutil# 列出所有进程PID&gt;&gt;&gt; psutil.pids()[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40, 42, 43, 73, 147, 148, 225, 226, 308, 525, 601, 823, 842, 874, 937, 969, 1003, 1020, 1022, 1024, 1026, 1027, 1029, 1031, 1059, 1094, 1392, 5427, 12014, 12016, 12105, 13842, 14099, 14191]# 实例化一个Process对象，参数为一进程PID&gt;&gt;&gt; p = psutil.Process(14191) # 进程名&gt;&gt;&gt; p.name()'java'# 进程bin路径&gt;&gt;&gt; p.exe()'/usr/local/jdk/bin/java'# 进程工作目录绝对路径&gt;&gt;&gt; p.cwd()'/usr/local/nginx/conf/vhosts'# 进程状态&gt;&gt;&gt; p.status()'sleeping'# 进程创建时间&gt;&gt;&gt; p.create_time()1461738772.66# 进程 uid 信息&gt;&gt;&gt; p.uids()puids(real=0, effective=0, saved=0)# 进程 git 信息&gt;&gt;&gt; p.gids()pgids(real=0, effective=0, saved=0)# 进程CPU时间信息，报错user、system两个CPU时间&gt;&gt;&gt; p.cpu_times()pcputimes(user=263.48, system=43.18, children_user=0.21, children_system=0.13)#get进程亲和度&gt;&gt;&gt; p.cpu_affinity()[0]# 进程内存利用率&gt;&gt;&gt; p.memory_percent()42.151973296681724＃ 进程内存rss、vms信息&gt;&gt;&gt; p.memory_info()pmem(rss=439664640, vms=2446684160, shared=8585216, text=4096, lib=0, data=2281676800, dirty=0)# 进程IO信息&gt;&gt;&gt; p.io_counters()pio(read_count=870377, write_count=40979, read_bytes=21909504, write_bytes=115916800)# 返回打开进程socket 的namedutples 列表，包括fd、family、laddr等信息&gt;&gt;&gt; p.connections()[pconn(fd=343, family=2, type=2, laddr=('0.0.0.0', 5353), raddr=(), status='NONE'), pconn(fd=330, family=2, type=1, laddr=('0.0.0.0', 54711), raddr=(), status='LISTEN'), pconn(fd=47, family=2, type=1, laddr=('0.0.0.0', 8009), raddr=(), status='LISTEN'), pconn(fd=341, family=2, type=2, laddr=('0.0.0.0', 33848), raddr=(), status='NONE'), pconn(fd=340, family=2, type=1, laddr=('0.0.0.0', 32996), raddr=(), status='LISTEN'), pconn(fd=46, family=2, type=1, laddr=('0.0.0.0', 8080), raddr=(), status='LISTEN'), pconn(fd=180, family=2, type=1, laddr=('127.0.0.1', 8005), raddr=(), status='LISTEN')]# 进程开启等线程数&gt;&gt;&gt; p.num_threads()54 (2) popen 类的使用 12345678# 通过psutil 的Popen方法启动的应用程序，可以跟踪该程序运行的所有相关信息&gt;&gt;&gt; psutil.Popen([\"/usr/bin/python\", \"-c\", \"print('hello')\"], stdout=PIPE)&lt;psutil.Popen(pid=12139, name='python') at 32848976&gt;&gt;&gt;&gt; p = psutil.Popen([\"/usr/bin/python\", \"-c\", \"print('hello')\"], stdout=PIPE)&gt;&gt;&gt; p.username()'root'&gt;&gt;&gt; p.communicate()('hello\\n', None)","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python模块","slug":"Python模块","permalink":"http://yoursite.com/tags/Python模块/"}]},{"title":"Python_IPy模块","slug":"Python-IPy模块","date":"2016-12-15T10:15:24.000Z","updated":"2016-12-15T10:16:20.000Z","comments":true,"path":"2016/12/15/Python-IPy模块/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-IPy模块/","excerpt":"","text":"IP地址、网段的基本处理 IPy模块包含IP类，可以方便的处理绝大部分个是为IPv6和IPv4的网络和地址。可以通过version方法就可以分出IPv4和IPv6，如： 12345&gt;&gt;&gt; import IPy&gt;&gt;&gt; IPy.IP('10.0.0.0/8').version()4&gt;&gt;&gt; IPy.IP('::1').version()6 通过指定网段输出该网段的IP个数以及所有IP地址清单，代码示例： 123456789[root@sate_z python]# cat ip_list.py#!/bin/python# print ip listfrom IPy import IPip = IP('192.168.0.0/24')print ip.len() # 输出该网段的IP个数for i in ip: # 列出所有网段中的IP print i 下面介绍IP类几个常见的方法，包括反向解析名称、IP类型、IP转换等 12345678910111213141516171819202122&gt;&gt;&gt; from IPy import IP&gt;&gt;&gt; ip = IP('58.217.200.15')＃反向解析地址格式&gt;&gt;&gt; ip.reverseNames()['15.200.217.58.in-addr.arpa.']＃判断ip类型，私有还是共有&gt;&gt;&gt; ip.iptype()'PUBLIC'＃转换成十六进制&gt;&gt;&gt; ip.strHex()'0x3ad9c80f'＃转换成二进制&gt;&gt;&gt; ip.strBin()'00111010110110011100100000001111'＃将十六进制转换成IP格式&gt;&gt;&gt; print(IP(0x3ad9c80f))58.217.200.15 123456＃也可以使用如下格式来使用&gt;&gt;&gt; from IPy import IP&gt;&gt;&gt; IP('10.0.0.1').iptype()'PRIVATE'&gt;&gt;&gt; IP('10.0.0.1').strHex()'0xa000001' IP方法也支持网络地址等转换，例如根据IP与掩码生产网段格式。例如12345678910111213&gt;&gt;&gt; from IPy import IP&gt;&gt;&gt; ip_mask = IP('10.0.0.0').make_net('255.255.255.0')&gt;&gt;&gt; print ip_mask10.0.0.0/24# 也可以&gt;&gt;&gt; print (IP('10.0.0.0').make_net('255.255.255.0'))10.0.0.0/24&gt;&gt;&gt; print (IP('10.0.0.0/255.255.255.0',make_net=True))10.0.0.0/24&gt;&gt;&gt; print (IP('10.0.0.0-10.0.0.255',make_net=True))10.0.0.0/24 通过strNormal方法指定不同wantprefixlen参数值以定制不同输出类型的网段。输出类型为字符串，如下：12345678&gt;&gt;&gt; IP('10.0.1.0/24').strNormal(0)'10.0.1.0'&gt;&gt;&gt; IP('10.0.1.0/24').strNormal(1)'10.0.1.0/24'&gt;&gt;&gt; IP('10.0.1.0/24').strNormal(2)'10.0.1.0/255.255.255.0'&gt;&gt;&gt; IP('10.0.1.0/24').strNormal(3)'10.0.1.0-10.0.1.255' 多网络计算方法详解判断两个网段是否存在包含关系。 12345678&gt;&gt;&gt; '10.0.0.1' in IP('10.0.0.0/24')True&gt;&gt;&gt; '10.0.0.0/26' in IP('10.0.0.0/24')True&gt;&gt;&gt; '10.0.0.0/24' in IP('10.0.0.0/24')True&gt;&gt;&gt; '10.0.0.0/23' in IP('10.0.0.0/24')False 判断两个网段是否存在重叠，采用IPy提供的overlaps方法，如： 1234567&gt;&gt;&gt; import IPy&gt;&gt;&gt; IPy.IP('10.0.0.0/24').overlaps('10.0.0.0/26')1&gt;&gt;&gt; IPy.IP('10.0.0.0/24').overlaps('10.0.0.0/23')1&gt;&gt;&gt; IPy.IP('10.0.0.0/24').overlaps('11.0.0.0/23')0","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python模块","slug":"Python模块","permalink":"http://yoursite.com/tags/Python模块/"}]},{"title":"Python_getpass模块","slug":"Python-getpass模块","date":"2016-12-15T10:14:46.000Z","updated":"2016-12-15T10:15:02.000Z","comments":true,"path":"2016/12/15/Python-getpass模块/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-getpass模块/","excerpt":"","text":"getpass模块提供了两个函数： getpass() 获取输入的密码，并且输入内容屏幕不显示，和Linux系统登录类似 getuser() 获取当前登录的用户名。 123456789# getpass()In [1]: import getpassIn [2]: password = getpass.getpass('input your password: ')input your password: # 输入密码In [3]: print passwordOut[3]: 'passwd' 1234# getuser()In [4]: getpass.getuser()Out[4]: 'zheng'","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python模块","slug":"Python模块","permalink":"http://yoursite.com/tags/Python模块/"}]},{"title":"Python_SocketSever模块","slug":"Python-SocketSever模块","date":"2016-12-15T10:14:17.000Z","updated":"2016-12-15T10:14:29.000Z","comments":true,"path":"2016/12/15/Python-SocketSever模块/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-SocketSever模块/","excerpt":"","text":"内容学习记录自 : https://docs.python.org/2/library/socketserver.html#asynchronous-mixins http://acen-chen.iteye.com/blog/290177 在SocketServer模块中有四个基础的类,比较常用的是TCPServer TCPServer(server_address, RequestHandlerClass, bind_and_activate=True) UDPServer(server_address, RequestHandlerClass, bind_and_activate=True) UnixStreamServer(server_address, RequestHandlerClass, bind_and_activate=True) UnixDatagramServer(server_address, RequestHandlerClass, bind_and_activate=True) 这四个类的进程是同步的，即一次只能连接一个客户机并处理她的请求，请求结束后再接受其他请求。 解决办法是创建新的进程或者线程来处理每个请求。ForkingMixIn和TheadingMixIn两个混合类可以用来支持这种异步的行为。 实际上，SocketServer模块提供了一些对些有用的类来解决你这个问题，它们是：ForkingUDPServer、ForkingTCPServer、ThreadingUDPServer、ThreadingTCPServer、ThreadingUnixStreamServer和ThreadingUnixDatagramServer。 fork是通过复制进程来实现多进程， threading是通过创建进程来实现同时处理多个请求。 如果要写一个自己的监听服务，我们要自己写一个请求处理的类来完成对请求数据的处理，SocketServer中的BaseRequestHandler是所有请求处理的类的父类。 例：写一个多线程服务，客户端发过来的数据，稍微处理再发送回去。 123456789101112131415161718192021222324252627# server 服务端import SocketServerclass MyTCPHandler(SocketServer.BaseRequestHandler): def handle(self): print self.request #客户端的socket对象,&lt;socket._socketobject object at 0x1048be830&gt; print self.client_address # 客户端的地址和IP,('127.0.0.1', 55270) print self.server # 服务端socketserver对象,&lt;SocketServer.ThreadingTCPServer instance at 0x1048eeab8&gt; print \"get connection from : \" ,self.client_address # 连接后，向客户端返回数据 self.request.send('hello') flag = True while flag: # 接收客户端发来的数据 self.data = self.request.recv(4096).strip() print self.data if self.data == 'exit': flag = False final_data = \"input is %s \\r\\n\" % self.data # 处理后返回数据 self.request.sendall(final_data)h, p = '127.0.0.1', 9999server = SocketServer.ThreadingTCPServer((h, p), MyTCPHandler)server.serve_forever() 123456789101112131415161718# client 客户端import socketclient = socket.socket()# 建立连接ip_port = ('127.0.0.1', 9999)client.connect(ip_port)while True: # 接受服务端发过来的数据 data = client.recv(1024) print data # 向服务端发送数据 inp = raw_input('client: ') client.send(inp) if inp == 'exit': break 在程序中，自定义了一个MyTCPHandler类来处理接受的数据，它的父类是BaseRequestHandler，当一个新的连接来到时，server会创建一个新的MyTCPHandler实例并调用hande()方法来处理该请求。server继承自SocketServer.ThreadingTCPServer，对于每个新的请求都会启动一个单独的线程来处理这个请求。如果用server.handle_request()替代server.serve_forever()，它将一个一个的处理连接请求，server.serve_forever()只是反复的调用server.handle_request() 一般来说，你只需使用socket服务之一，但是如果你需要创建你自己的子类的话，你可以覆盖我们下面提到的方法来定制它。 当服务被第一次创建的时候，__init__函数调用server_bind()方法来绑定监听socket(self.socket)到正确的地址(self.server_address)。然后调用server_activate()来激活这个服务(默认情况下，调用socket的listen方法)。 这个socket服务不做任何事情直到调用了handle_request或serve_forever方法。handle_request调用get_request()去等待和接收一个新的socket连接，然后调用verify_request(request,client_address)去看服务是否会处理这个连接(你可以在访问控制中使用这个，默认情况下面verify_request总是返回true)。如果会处理这个请求，handle_request然后调用process_request(request,client_address)，如果process_request(request,client_address)导致一个异常的话，将调用handle_error(request,client_address)。默认情况下，process_request简单地调用finish_request(request,client_address)；子进程和线程类覆盖了这个行为去开始一新的进程或线程，然后调用finish_request。finish_request实例化一个新的请求处理器，请求处理器轮流调用它们的handle()方法。 当SocketServer创建一个新的请求处理器时，它传递给这个处理器的__init__函数的self变量，以便于这个处理器能够访问关于这个服务的信息。 SocketServer的fileno()方法返回监听socket的文件描述符。address_family成员变量指定了监听socket的socket族(如AF_INET)，server_address包含了监听socket被绑定到的地址。socket变量包含监听socket自身。 请求处理器中： 即我们自己写的MyTCPHandler类，请求处理器有setup()、handle()和finish()方法，你可以覆盖它们来定制你自己的行为。一般情况下，你只需要覆盖handle()方法。BaseRequestHandler的__init__函数调用setup()方法来做初始化的工作，handle()服务于请求，finish()用于执行清理工作，如果handle或setup导致一个异常，finish不会被调用。记住，你的请求处理器会为每个请求创建一个新的实例。 SocketServer模块也定义了BaseRequestHandler的两个子类：StreamRequestHandler和DatagramRequestHandler。它们覆盖了setup和finish方法并创建了两个文件对象rfile和wfile，你可以用这两个文件对象来向客户端读写数据，从而代替使用socket方法。如下例子： 1234567891011121314151617181920212223242526#-*- coding:utf-8 -*-from SocketServer import ThreadingTCPServer, StreamRequestHandlerimport tracebackclass MyStreamRequestHandlerr(StreamRequestHandler): def handle(self): while True: try: data = self.rfile.readline().strip() if not data: break print \"receive from (%r):%r\" % (self.client_address, data) self.wfile.write(data.upper()) except: traceback.print_exc() breakif __name__ == \"__main__\": host = \"\" #主机名，可以是ip,像localhost的主机名,或\"\" port = 9999 #端口 addr = (host, port) #ThreadingTCPServer从ThreadingMixIn和TCPServer继承 #class ThreadingTCPServer(ThreadingMixIn, TCPServer): pass server = ThreadingTCPServer(addr, MyStreamRequestHandlerr) server.serve_forever()","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python模块","slug":"Python模块","permalink":"http://yoursite.com/tags/Python模块/"}]},{"title":"Python_socket模块","slug":"Python-socket模块","date":"2016-12-15T10:13:43.000Z","updated":"2016-12-15T10:13:57.000Z","comments":true,"path":"2016/12/15/Python-socket模块/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-socket模块/","excerpt":"","text":"socket 也称套接字，用于描述IP地址和端口，是一个通信链的句柄，应用程序通过“套接字”向网络发出请求或者应答网络请求 简单使用123456789101112131415161718192021222324252627282930313233343536# server 端import socket# 创建socket对象sk = socket.socket()# 绑定端口和IPip_port = ('127.0.0.1', 9999)sk.bind(ip_port)sk.listen(5)# 处理完一个请求后，会处理下一个，持续监听。while True: # 建立监听, sk.accept() 返回值为一个元祖,conn的值为客户端的socket对象,address为客户端连接过来的地址。 conn, address = sk.accept() print conn #结果==》&lt;socket._socketobject object at 0x1066330c0&gt; # 当客户端连接上之后,向客户端发送数据 conn.send('hello') # 定义标志位，用来跳出循环 flag = True # 该循环用于和一个用户的持续连接 while flag: # 接收客户端的数据 data = conn.recv(1024) print data if data == 'exit': flag = False # 向客户端发送数据 conn.send('sb') conn.close() 1234567891011121314151617181920# client 端import socketclient = socket.socket()# 建立连接ip_port = ('127.0.0.1', 9999)client.connect(ip_port)while True: # 接受服务端发过来的数据 data = client.recv(1024) print data # 向服务端发送数据 inp = raw_input('client: ') client.send(inp) if inp == 'exit': break socket 参数12# 实例化时，不加参数，默认是如下参数sk = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0) 1234567891011121314# 参数一： 地址簇socket.AF_INET :服务器之间网络通信，用于ipv4（默认）socket.AF_UNIX :只能够用于单一的unix系统进程间通信，不能进行网络通信socket.AF_INET6 :IPV6# 参数二： 类型socket.SOCK_STREAM 流式socket，for TCP（默认）socket.SOCK_DGRAM 数据报式socket，for UDPsocket.SOCK_RAW 原始套接字，普通的套接字无法处理ICMP、IGMP等网络报文，而SOCK_RAW可以。其次SOCK_RAW也可以处理特殊的IPv4报文；使用原始套接字，可以通过IP_HDRINCL套接字选项由用户构造IP头socket.SOCK_RDM 一种课改的UDP形式，保证数据但不保证顺序，很少用socket.SOCK_SEQPACKET 可靠的连续数据包服务，很少用# 参数三： 协议0 （默认），于特定的地址家族相关的协议，如果是0，则系统会根据地址格式和套接类别自动选择一个合适的协议 socket 方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566sk.bind(address): s.bind(address) 将套接字绑定到地址。address地址的格式取决于地址族。在AF_INET下，以元组（host,port）的形式表示地址。sk.listen(backlog): 开始监听传入连接。backlog指定在拒绝连接之前，可以挂起的最大连接数量。backlog等于5， 表示内核已经接到了连接请求，但服务器还没有调用accept进行处理的连接个数最大为5, 这个值不能无限大，因为要在内核中维护连接队列sk.setblocking(bool): 是否阻塞（默认True），如果设置False，那么accept和recv时一旦无数据，则报错。sk.accept(): 接受连接并返回（conn,address）,其中conn是新的套接字对象，可以用来接收和发送数据。address是连接客户端的地址。 接收TCP 客户的连接（阻塞式）等待连接的到来sk.connect(address): 连接到address处的套接字。一般，address的格式为元组（hostname,port）,如果连接出错，返回socket.error错误。sk.connect_ex(address) 同上，只不过会有返回值，连接成功时返回 0 ，连接失败时候返回编码，例如：10061sk.close(): 关闭套接字sk.recv(bufsize[,flag]): 接受套接字的数据。数据以字符串形式返回，bufsize指定最多可以接收的数量。flag提供有关消息的其他信息，通常可以忽略。sk.recvfrom(bufsize[.flag]): 与recv()类似，但返回值是（data,address）。其中data是包含接收数据的字符串，address是发送数据的套接字地址。sk.send(string[,flag]): 将string中的数据发送到连接的套接字。返回值是要发送的字节数量，该数量可能小于string的字节大小。即：可能未将指定内容全部发送。sk.sendall(string[,flag]): 将string中的数据发送到连接的套接字，但在返回之前会尝试发送所有数据。成功返回None，失败则抛出异常。 内部通过递归调用send，将所有内容发送出去。sk.sendto(string[,flag],address): 将数据发送到套接字，address是形式为（ipaddr，port）的元组，指定远程地址。返回值是发送的字节数。该函数主要用于UDP协议。sk.settimeout(timeout): 设置套接字操作的超时期，timeout是一个浮点数，单位是秒。值为None表示没有超时期。一般，超时期应该在刚创建套接字时设置，因为它们可能用于连接的操作（如 client 连接最多等待5s ）sk.getpeername(): 返回连接套接字的远程地址。返回值通常是元组（ipaddr,port）。sk.getsockname(): 返回套接字自己的地址。通常是一个元组(ipaddr,port) sk.fileno(): 套接字的文件描述符","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python模块","slug":"Python模块","permalink":"http://yoursite.com/tags/Python模块/"}]},{"title":"Python_Redis的订阅和发布","slug":"Python-Redis的订阅和发布","date":"2016-12-15T10:12:50.000Z","updated":"2016-12-15T10:13:08.000Z","comments":true,"path":"2016/12/15/Python-Redis的订阅和发布/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-Redis的订阅和发布/","excerpt":"","text":"订阅1234567891011# 订阅功能终端&gt;&gt;&gt; import redis&gt;&gt;&gt; r = redis.Redis()# 打开订阅功能&gt;&gt;&gt; sub = r.pubsub()# 声明订阅的频道&gt;&gt;&gt; sub.subscribe('fm87.7')# 开始订阅,第一次会返回一条订阅信息，第二次开始持续订阅&gt;&gt;&gt; sub.parse_response()['subscribe', 'fm87.7', 1L]&gt;&gt;&gt; sub.parse_response() #此时会一直等待数据 发布打开新的终端，执行发布部分 12345# 发布功能终端&gt;&gt;&gt; import redis&gt;&gt;&gt; r = redis.Redis()# 指定频道发送数据&gt;&gt;&gt; r.publish('fm87.7', 'send msg') 执行后，订阅终端会受到发布终端发布信息，如下： 1['message', 'fm87.7', 'send msg'] 可以将订阅终端使用while循环，进行持续订阅。如下 12345678&gt;&gt;&gt; import redis&gt;&gt;&gt; r = redis.Redis()&gt;&gt;&gt; sub = r.pubsub()&gt;&gt;&gt; sub.subscribe('fm87.7')&gt;&gt;&gt; while True:... sub.parse_response()...# 可以持续接受消息。","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python模块","slug":"Python模块","permalink":"http://yoursite.com/tags/Python模块/"}]},{"title":"Python_Mysqldb模块","slug":"Python-Mysql模块","date":"2016-12-15T10:11:02.000Z","updated":"2016-12-15T10:12:27.000Z","comments":true,"path":"2016/12/15/Python-Mysql模块/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-Mysql模块/","excerpt":"","text":"安装12345678系统：Ubuntu 14.04MySQLdb$ pip install Mysql-python-&gt; 报错：EnvironmentError: mysql_config not found （安装libmysqlclient-dev）$ apt-get install libmysqlclient-dev$ pip install Mysql-python如果是MAC系统，则需要先安装 mysql 服务。 使用 查数据示例（fetchall()获取数据） 1234567891011121314151617181920212223242526import MySQLdb# 建立连接conn = MySQLdb.connect(host='127.0.0.1', user='sate', db='dbtest', passwd='password')# 设置游标cur = conn.cursor()# 执行SQL命令，并不会直接返回查询结果，而是返回SQL语句影响的行数reCount = cur.execute('select * from Products;')print reCount # 输出一个数字，是SQL影响的行数# 使用 fetchall()方法获取数据，循环输出结果，以元祖的方式输出for data in cur.fetchall(): print data # 关闭连接cur.close()conn.close()# 结果==》5('00001', 'hilife')('00002', 'GTL')('00003', 'GLA')('000004', 'TYA')('000005', 'TUH') 插入或者更改数据 1234567891011121314import MySQLdbconn = MySQLdb.connect(host='127.0.0.1', user='sate', db='dbtest', passwd='password')cur = conn.cursor()# 定义SQL语句sql = 'insert into Products(prod_id, prod_name) values(%s, %s);'# 定义数据params = ('00002', 'GLA')reCount = cur.execute(sql, params) #为了防止SQL注入,可以使用该方法conn.commit() #提交cur.close()conn.close() 批量插入数据 1234567891011121314151617import MySQLdbconn = MySQLdb.connect(host='127.0.0.1', user='sate', db='dbtest', passwd='password')cur = conn.cursor()# 要批量插入的数据li = [ ('000004', 'TYA'), ('000005', 'TUH')]sql = 'insert into Products(prod_id, prod_name) values(%s, %s);'# 批量使用executemanyreCount = cur.executemany(sql, li) #为了防止SQL注入,可以使用该方法conn.commit() #提交cur.close()conn.close() 之前查看数据时，返回是元祖形式，有时看起来并不明显，我们可以选择用字典的方式，将列名一起输出。 12345678910111213141516171819202122import MySQLdbconn = MySQLdb.connect(host='127.0.0.1', user='zheng', db='satezheng', passwd='satezheng')# 使用字典形式返回数据cur = conn.cursor(cursorclass = MySQLdb.cursors.DictCursor)# 执行命令，并不会直接打印,可以使用fetchall来读取。reCount1 = cur.execute('select * from Products')print reCount1 # 输出一个数字，是SQL影响的行数for data in cur.fetchall(): print datacur.close()conn.close()# 结果==》5&#123;'prod_name': 'hilife', 'prod_id': '00001'&#125;&#123;'prod_name': 'GLA', 'prod_id': '00002'&#125;&#123;'prod_name': 'GTL', 'prod_id': '00003'&#125;&#123;'prod_name': 'TYA', 'prod_id': '000004'&#125;&#123;'prod_name': 'TUH', 'prod_id': '000005'&#125; cursor读取执行结果的方法有： fetchall() 把所有的都读出来 fetchmany(n) 输出指定数量n的行 fetchone() 只返回第一条结果 fetchone() 一次只返回一条结果，下次返回第二条，和文件的readlines类似 对应的也会有指针的概念，scroll()可以指定读取的位置 12cur.scroll(0, mode='absolute') # 绝对指针， 0 就是指针的位置cur.scroll(-1, mode='relative') # 相对指针， -1 指针位置向前移一位（指针位置-1） 123456789101112131415161718192021222324252627282930313233343536373839404142434445import MySQLdbconn = MySQLdb.connect(host='127.0.0.1', user='zheng', db='satezheng', passwd='satezheng')cur = conn.cursor()reCount = cur.execute('select * from Products;')# 使用 fetchone()方法获取数据data = cur.fetchone()print datadata = cur.fetchone()print datadata = cur.fetchone()print data# 结果==》('00001', 'hilife')('00002', 'GTL')('00003', 'GLA')# 使用绝对指针时...data = cur.fetchone()print datadata = cur.fetchone()print datacur.scroll(0, mode='absolute') # 将指针指向 0data = cur.fetchone()print data# 结果==》('00001', 'hilife')('00002', 'GTL')('00001', 'hilife')# 使用相对指针data = cur.fetchone()print datadata = cur.fetchone()print datacur.scroll(-1, mode='relative') # 指针位置减1data = cur.fetchone()print data# 结果==》('00001', 'hilife')('00002', 'GTL')('00002', 'GTL') cur.lastrawid() 获取自增id","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python模块","slug":"Python模块","permalink":"http://yoursite.com/tags/Python模块/"}]},{"title":"Python异常","slug":"Python异常","date":"2016-12-15T09:55:13.000Z","updated":"2016-12-15T09:55:42.000Z","comments":true,"path":"2016/12/15/Python异常/","link":"","permalink":"http://yoursite.com/2016/12/15/Python异常/","excerpt":"","text":"什么是异常Python 用异常处理来表示异常情况。 事实上每个异常都是一些类的实例，可以被引发，也可以用很多方法进行捕捉，并对其处理。 引发异常异常可以自己引发 raise语句12345678&gt;&gt;&gt; raise ExceptionTraceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;Exception&gt;&gt;&gt; raise Exception(\"oh,error\")Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;Exception: oh,error 一些重要的内建异常类： 类名 描述 Exception 所有异常的基类 AttributeError 特性引用或赋值失败时引发 IOError 试图打开不存在的文件时引发 IndexError 在使用序列中不存在的索引时引发 keyError 在使用映射中不存在的键时引发 NameError 在找不到名字（变量）时引发 SyntaxError 在代码为错误形式时引发 TypeError 在内建操作或者函数应用于错误类型的对象时引发 ValueError 在内建操作或者函数应用于正确类型的对象，但是该对象使用不合适的值时引发 ZeroDivisionError 在除法或者模除操作的第二个参数为0时引发 自定义异常类和其他类一样，只要确保从Exception类继承。 1class SomeCustomException(Exception): pass","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python_zabbix_api","slug":"Python-zabbix-api","date":"2016-12-15T09:53:46.000Z","updated":"2016-12-15T09:54:15.000Z","comments":true,"path":"2016/12/15/Python-zabbix-api/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-zabbix-api/","excerpt":"","text":"运维生存时间: http://www.ttlsa.com/zabbix/zabbix-dev-api/ zabbix api 官方文档: https://www.zabbix.com/documentation/2.4/manual/api zabbix 提供api来完成实现我们需要做的各种操作，如获取数据，创建监控项等。 zabbix接口地址：http://zabbix地址/api_jsonrpc.php,请求是必须包括Content-Type头信息，值为application/json-rpc、application/json 或 application/jsonrequest 通过zabbix api登录，获取token要想通过zabbix api来进行各种操作，首先要先通过api的认证，带着返回的token值来获取操作的权限。 1234567891011121314151617181920212223242526import urllib2import jsonimport pprinturl = 'https://zabbix地址/api_jsonrpc.php'username = '*******'password = '****'def Authid(url, username, password): values = &#123;'jsonrpc': '2.0', #JSON-RPC版本 'method': 'user.login', #调用的API方法 'params': &#123; #传递的参数 'user': username, 'password': password &#125;, 'id': 0 #请求标志 &#125; data = json.dumps(values) req = urllib2.Request(url, data, &#123;'Content-Type': 'application/json-rpc'&#125;) response = urllib2.urlopen(req) output = json.loads(response.read()) return outputprint authid(url, username, password)# 结果&#123;u'jsonrpc': u'2.0', u'result': u'04033a250a41c8786d8dc9045b2b1a7c', u'id': 0&#125; 通过token来获取zabbix数据上边函数已经将token取出，现在我们根据官方提供的方法来获取数据。 可以参照官方文档中：https://www.zabbix.com/documentation/2.4/manual/api/reference 123456789101112131415161718192021222324252627282930313233# 定义获取数据的函数def gethostinfo(auth): values = &#123; \"jsonrpc\": \"2.0\", \"method\": \"host.get\", #调用host.get方法 \"params\": &#123; \"output\": [\"hostid\", \"host\"], \"selectInterfaces\": [ \"interfaceid\", \"ip\"], \"filter\": &#123; \"host\": [\"zabbix-node1\"] #指定一个zabbix中的一个host，否则会输出全部的host &#125;, &#125;, \"auth\": auth, #使用上一步获取的token值 \"id\": 1 &#125; data = json.dumps(values) req = urllib2.Request(url, data, &#123;'Content-Type': 'application/json-rpc'&#125;) response = urllib2.urlopen(req) output = json.loads(response.read()) return outputauth = authid()['result'] #获取token值hostinfo = gethostinfo(auth) #带入token，获取数据pprint.pprint(hostinfo) #输出，为了格式的好看，使用pprint# 结果&#123;u'id': 1, u'jsonrpc': u'2.0', u'result': [&#123;u'host': u'zabbix-node1', u'hostid': u'10156', u'interfaces': [&#123;u'interfaceid': u'53', u'ip': u'10.47.123.35'&#125;]&#125;]&#125; 获取到数据后， 就可以交给其他的程序来处理并输出。 整理为了程序的整洁性，调整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#!/usr/bin/env python# coding=utf-8import urllib2import jsonimport pprinturl = 'https://zabbix地址/api_jsonrpc.php'username = '******'password = '****'def get_data(values): data = json.dumps(values) req = urllib2.Request(url, data, &#123;'Content-Type': 'application/json-rpc'&#125;) response = urllib2.urlopen(req) output = json.loads(response.read()) return output['result']def authid(): values = &#123;'jsonrpc': '2.0', 'method': 'user.login', 'params': &#123; 'user': username, 'password': password &#125;, 'id': 1 &#125; return get_data(values)def get_host_info(auth): values = &#123; \"jsonrpc\": \"2.0\", \"method\": \"host.get\", \"params\": &#123; \"output\": [\"hostid\", \"host\"], \"selectInterfaces\": [ \"interfaceid\", \"ip\"], \"filter\": &#123; \"host\": [\"zabbix-node1\"] &#125;, &#125;, \"auth\": auth, \"id\": 1 &#125; return get_data(values)auth = authid()hostinfo = get_host_info(auth)pprint.pprint(hostinfo)","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python_virtualenv教程","slug":"Python-virtualenv教程","date":"2016-12-15T09:52:01.000Z","updated":"2016-12-15T09:52:33.000Z","comments":true,"path":"2016/12/15/Python-virtualenv教程/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-virtualenv教程/","excerpt":"","text":"文中知识点学习自 : http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001432712108300322c61f256c74803b43bfd65c6f8d0d0000 在开发Python应用程序的时候，系统安装的Python3只有一个版本：3.4。所有第三方的包都会被pip安装到Python3的site-packages目录下。 如果我们要同时开发多个应用程序，那这些应用程序都会共用一个Python，就是安装在系统的Python 3。如果应用A需要jinja 2.7，而应用B需要jinja 2.6怎么办？ 这种情况下，每个应用可能需要各自拥有一套“独立”的Python运行环境。virtualenv就是用来为一个应用创建一套“隔离”的Python运行环境。 安装： 1$ sudo pip install virtualenv 使用： 1、创建项目目录 12$ mkdir virenv$ cd virenv/ 2、创建一个独立的Python运行环境，命名为venv 123$ virtualenv --no-site-packages venvNew python executable in /root/virenv/venv/bin/pythonInstalling setuptools, pip, wheel...done. 命令virtualenv就可以创建一个独立的Python运行环境，我们还加上了参数--no-site-packages，这样，已经安装到系统Python环境中的所有第三方包都不会复制过来，这样，我们就得到了一个不带任何第三方包的“干净”的Python运行环境。 3、进入环境 新建的Python环境被放到当前目录下的venv目录。有了venv这个Python环境，可以用source进入该环境： 123$ source venv/bin/activate(venv) root@sate-z:~/virenv## 注意到命令提示符变了，有个(venv)前缀，表示当前环境是一个名为venv的Python环境。 下面正常安装各种第三方包，并运行python命令 1root@sate-z:~/virenv# pip install lxml 在venv环境下，用pip安装的包都被安装到venv这个环境下，系统Python环境不受任何影响。也就是说，venv环境是专门针对myproject这个应用创建的。 退出当前的venv环境，使用deactivate命令： 12(venv) root@sate-z:~/virenv# deactivateroot@sate-z:~/virenv# virtualenv是如何创建“独立”的Python运行环境的呢？原理很简单:就是把系统Python复制一份到virtualenv的环境，用命令source venv/bin/activate进入一个virtualenv环境时，virtualenv会修改相关环境变量，让命令python和pip均指向当前的virtualenv环境。","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python装饰器","slug":"Python装饰器","date":"2016-12-15T09:50:37.000Z","updated":"2016-12-15T09:51:11.000Z","comments":true,"path":"2016/12/15/Python装饰器/","link":"","permalink":"http://yoursite.com/2016/12/15/Python装饰器/","excerpt":"","text":"文中知识点和代码示例学习自慕课网，python进阶部分（http://www.imooc.com/learn/317）.学习笔记 装饰器的理解： 装饰器本质上是一个高阶函数，接受一个函数，进行处理，然后返回一个新的函数。 12345678910111213141516171819202122232425262728293031323334# 有一个简单的函数def f1(x): return x * 2print f1(5)#输出：10# 实现运行该函数时，输出该函数的名称的日志功能# 法一：直接在函数中写出，好理解，但是如果函数很多，那每个函数都要加一遍def f1(x): print \"call \" + f1.__name__ + \"()..\" return x*2print f1(5)#输出：#call f1()..#10# 法二：使用装饰器，创建装饰器函数def flog(f): #定义装饰器函数，接受参数是 f 函数 def fn(x): #定义新的函数，来处理 f 函数，添加我们需要的日志信息，并返回 f 函数，参数 x 是 f1 的参数，如果 f1 函数有多个，这边也要写多个，要让 @log 自适应任何参数定义的函数，可以利用Python的 *args 和 **kw，保证任意个数的参数总是能正常调用 print \"call \" + f.__name__ + \"()..\" return f(x) #执行原 f 函数 return fn #返回新的函数# 调用装饰器，效果和 g1 = flog(f1);print g1(5) 一致。@flog def f1(x): return x * 2print f1(5)#输出：#call f1()..#10 注： 上边f1(x)只接受一个函数，如果接受两个函数就会报错，要让 @flog 自适应任何参数定义的函数，可以利用Python的 *args 和 **kw，保证任意个数的参数总是能正常调用 例：计算函数调用的时间可以记录调用前后的当前时间戳，然后计算两个时间戳的差。 1234567891011121314151617import time# 定义装饰器def performance(f): def fn(*args, **kw): #可以接受任意参数 t1 = time.time() #记录执行前的时间 r = f(*args, **kw) #执行原函数，并保存执行结果到变量 r 中 t2 = time.time() #记录执行结束后的时间 print 'call %s() in %fs' % (f.__name__, (t2 - t1)) #添加自定义输出内容 return r #返回原函数的执行结果 return fn #返回新函数#调用装饰器@performancedef factorial(n): return reduce(lambda x,y: x*y, range(1, n+1))print factorial(10) 带参数的装饰器上边的实现的装饰器函数，只能输出固定的内容，除了f.__name__所定义的函数名称。如果想要根据函数的不同来给输出的日志划分等级的，如 a 函数日志等级为info，b 函数日志等级为debug，这里需要用到带参数的装饰器。如: 123@log('DEBUG')def my_func(): pass @log(&#39;DEBUG&#39;)等于之前无参数的装饰器的@log，即@log(&#39;DEBUG&#39;)这个返回的函数相当于之前无参数装饰器的@log。所以要在无参数的装饰器上层再加一个函数的嵌套。 例：输出日志等级 123456789101112131415161718192021222324#coding=utf-8\"\"\" 带参数的装饰器,写三层嵌套的函数\"\"\"def flog(devel): # 定义带参数的装饰器. def log_decorator(f): #和无参数的装饰器相同 def add_self(*args,**kwargs): #添加输出的日志，执行f函数 print \"[%s],call %s()..\" % (devel,f.__name__) return f(*args,**kwargs) return add_self return log_decorator #返回给flog(\"INFO\")@flog(\"INFO\")def factorial(n): return reduce(lambda x,y: x*y, range(1, n+1))print factorial(10)\"\"\"输出[INFO],call factorial()..3628800\"\"\" 例2：上一节的@performance只能打印秒，请给@performace增加一个参数，允许传入&#39;s&#39;或&#39;ms&#39;： 1234567891011121314151617import timedef performance(unit):s def perf_decorator(f): def wrapper(*args, **kw): t1 = time.time() r = f(*args, **kw) t2 = time.time() t = (t2 - t1) * 1000 if unit=='ms' else (t2 - t1) print 'call %s() in %f %s' % (f.__name__, t, unit) return r return wrapper return perf_decorator@performance('ms')def factorial(n): return reduce(lambda x,y: x*y, range(1, n+1))print factorial(10) 完善装饰器经过@decorator“改造”后的函数，和原函数相比会有不同的地方，如： 12345678910111213141516171819# 在没有decorator的情况下，打印函数名：def f1(x): passprint f1.__name__#输出：f1# 有decorator的情况下，再打印函数名：def log(f): def wrapper(*args, **kw): print 'call...' return f(*args, **kw) return wrapper@logdef f2(x): passprint f2.__name__#输出：wrapper 可见，由于decorator返回的新函数函数名已经不是&#39;f2&#39;，而是@log内部定义的&#39;wrapper&#39;。这对于那些依赖函数名的代码就会失效。decorator还改变了函数的__doc__等其它属性。如果要让调用者看不出一个函数经过了@decorator的“改造”，就需要把原函数的一些属性复制到新函数中。 Python内置的functools可以用来自动化完成这个“复制”的任务： 1234567import functoolsdef log(f): @functools.wraps(f) #增加该行 def wrapper(*args, **kw): print 'call...' return f(*args, **kw) return wrapper 最后需要指出，由于我们把原函数签名改成了(*args, **kw)，因此，无法获得原函数的原始参数信息。即便我们采用固定参数来装饰只有一个参数的函数 例：该方法使用到上节的例子中 123456789101112131415161718import time, functoolsdef performance(unit): def perf_decorator(f): @functools.wraps(f) def wrapper(*args, **kw): t1 = time.time() r = f(*args, **kw) t2 = time.time() t = (t2 - t1) * 1000 if unit=='ms' else (t2 - t1) print 'call %s() in %f %s' % (f.__name__, t, unit) return r return wrapper return perf_decorator@performance('ms')def factorial(n): return reduce(lambda x,y: x*y, range(1, n+1))print factorial.__name__","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python正则2","slug":"Python正则2","date":"2016-12-15T09:49:50.000Z","updated":"2016-12-15T09:50:11.000Z","comments":true,"path":"2016/12/15/Python正则2/","link":"","permalink":"http://yoursite.com/2016/12/15/Python正则2/","excerpt":"","text":"python自带re模块提供了对正则表达式的支持 re模块主要用到的方法列举如下： 函数 描述 re.compile(pattern[, flags] 根据包含正则表达式的字符串创建模式对象 re.search(pattern, string[, flags]) 在字符串中寻找模式 re.match(pattern, string[, flags]) 在字符串的开始处中寻找匹配模式 re.split(pattern, string[, maxsplit=0]) 根据模式的匹配项来分割字符串 re.findall(pattern, string) 列出字符串中模式的所有匹配项 re.finditer(pattern, string[, flags]) 返回一个顺序访问每一个匹配结果（Match对象）的迭代器 re.sub(pat, repl, string[, count=0]) 将字符串中所有的 pat 的匹配项用 repl 替换 re.subn(pattern, repl, string[, count]) 返回 (sub(repl, string[, count]) 替换次数)。 re.escape(string) 将字符串中所有特殊正则表达式字符转义","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python正则1","slug":"Python正则1","date":"2016-12-15T09:48:50.000Z","updated":"2016-12-15T09:49:23.000Z","comments":true,"path":"2016/12/15/Python正则1/","link":"","permalink":"http://yoursite.com/2016/12/15/Python正则1/","excerpt":"","text":"re模块包含对正则表达式的支持 先讲一些正则中的匹配规则 通配符 ..可以匹配任何字符（除了换行符\\n，在 DOTALL 模式中也能匹配换行符）。只能匹配一个字符 对特殊字符进行转义 \\如果想要匹配 &#39;python.org&#39; 可以使用 &#39;python\\\\.org&#39; 这边使用两个反斜线，一是通过解释器转义，二是通过re模块转义，建议使用原始字符串，如r&#39;python\\.org&#39; 字符集 []字符集可以匹配它所包含的任意字符 例：[pj]ython 匹配 python 和 jython 例：[a-z] 匹配 a 到 z 所有字母（字符集只能匹配一个这样的字符） 例：[a-zA-Z0-9] 匹配任意大小写字母和数字（字符集只能匹配一个这样的字符） 反转字符集 [^]例： [^abc] 匹配任何除了 a,b,c 之外的字符 选择符合和子模式 |选择符： 例： &#39;python|perl&#39; 匹配 python 或者 perl 子模式： 用圆括号括起来需要的部分称为子模式 例： &#39;p(yhon|erl)&#39; 匹配 python 或者 perl 可选项和重复子模式 ?可选项：在子模式的后边加上问好就变成了可选项。它可以出现在匹配字符串中，但并非是必须的。 例：r&#39;(http://)?(www\\.)?python\\.org&#39; 可以匹配到的下列字符串 &#39;http://www.python.org&#39; &#39;http://python.org&#39; &#39;www.python.org&#39; &#39;python.org&#39; 重复子模式：允许子模式重复多次的运算符 (pattern)* 允许模式重复0次或多次 (pattern)+ 允许模式重复1次或多次 (pattern){m,n} 允许模式重复 m ~ n 次 例： r&#39;w*\\.python\\.org&#39; 可以匹配.python.org、w.python.org、wwwww.python.org等等等等。 字符串的开始和结尾 ^``$只匹配开始： 例： 只想在字符串的开头而不是其他位置匹配&#39;ht+p&#39;,可以使用&#39;^ht+p&#39;匹配，可以匹配到&#39;http://python,org&#39;等等，而不会匹配&#39;www.http.com&#39;. 只匹配结尾： 如果只想匹配字符串结尾，可以使用$","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python文件和目录的操作","slug":"Python文件和目录的操作","date":"2016-12-15T09:47:06.000Z","updated":"2016-12-15T09:47:36.000Z","comments":true,"path":"2016/12/15/Python文件和目录的操作/","link":"","permalink":"http://yoursite.com/2016/12/15/Python文件和目录的操作/","excerpt":"","text":"操作文件和目录的函数一部分放在os模块中，一部分放在os.path模块中，这一点要注意一下。查看、创建和删除目录可以这么调用： 创建和删除目录12345678# 查看当前目录的绝对路径:&gt;&gt;&gt; os.path.abspath('.')'/Users/michael'# 创建一个目录:&gt;&gt;&gt; os.mkdir('/Users/michael/testdir')# 删掉一个目录:&gt;&gt;&gt; os.rmdir('/Users/michael/testdir') 列出某目录下的目录12&gt;&gt;&gt; os.listdir(\"/root\")['.ansible-console_history', '.ipython', '.ssh', 'virenv', '.lesshst', 'socket_server.py', '.java', '.rnd', '.python_history', '.bashrc', '.bash_history', '.vim', '.ansible_async', '.pip', '.profile', '.ansible', '.mysql_history', 'sina.html', '.viminfo', '.jenkins', '.gitconfig', '.rediscli_history', '.vimrc', '.cache'] 路径的合并和拆分这些合并、拆分路径的函数并不要求目录和文件要真实存在，它们只对字符串进行操作。 把两个路径合成一个时，不要直接拼字符串，而要通过os.path.join()函数，这样可以正确处理不同操作系统的路径分隔符。 12&gt;&gt;&gt; os.path.join('/Users/michael', 'testdir')'/Users/michael/testdir' 同样的道理，要拆分路径时，也不要直接去拆字符串，而要通过os.path.split()函数，这样可以把一个路径拆分为两部分，后一部分总是最后级别的目录或文件名： 12&gt;&gt;&gt; os.path.split('/Users/michael/testdir/file.txt')('/Users/michael/testdir', 'file.txt') 获取文件扩展名os.path.splitext()可以直接让你得到文件扩展名，很多时候非常方便： 12&gt;&gt;&gt; os.path.splitext('/path/to/file.txt')('/path/to/file', '.txt') 文件的重命名和删除1234# 对文件重命名:&gt;&gt;&gt; os.rename('test.txt', 'test.py')# 删掉文件:&gt;&gt;&gt; os.remove('test.py') 如何利用Python的特性来过滤文件。比如我们要列出当前目录下的所有目录，只需要一行代码 12&gt;&gt;&gt; [x for x in os.listdir('.') if os.path.isdir(x)]['.lein', '.local', '.m2', '.npm', '.ssh', '.Trash', '.vim', 'Adlm', 'Applications', 'Desktop', ...] 要列出所有的.py文件，也只需一行代码： 12&gt;&gt;&gt; [x for x in os.listdir('.') if os.path.isfile(x) and os.path.splitext(x)[1]=='.py']['apis.py', 'config.py', 'models.py', 'pymonitor.py', 'test_db.py', 'urls.py', 'wsgiapp.py']","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python同步_异步_阻塞_非阻塞","slug":"Python同步-异步-阻塞-非阻塞","date":"2016-12-15T09:46:04.000Z","updated":"2016-12-15T09:46:29.000Z","comments":true,"path":"2016/12/15/Python同步-异步-阻塞-非阻塞/","link":"","permalink":"http://yoursite.com/2016/12/15/Python同步-异步-阻塞-非阻塞/","excerpt":"","text":"抄自原文 ：http://www.jianshu.com/p/aed6067eeac9 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# 同步、异步同步：就是一个任务的完成需要依赖另外一个任务时，只有等待被依赖的任务完成后，依赖的任务才能算完成，这是一种可靠的任务序列异步：是不需要等待被依赖的任务完成，只是通知被依赖的任务要完成什么工作，依赖的任务也立即执行，只要自己完成了整个任务就算完成了。# 阻塞、非阻塞阻塞与非阻塞主要是程序（线程）等待消息通知时的状态角度来说的阻塞调用：是指调用结果返回之前，当前线程会被挂起，一直处于等待消息通知，不能够执行其他业务阻塞调用 和 同步调用 是不同的。对于同步调用来说，很多时候当前线程可能还是激活的，只是从逻辑上当前函数没有返回而已，此时，这个线程可能也会处理其他的消息# 同步阻塞、同步非阻塞同步非阻塞：如果这个线程在等待当前函数返回时，仍在执行其他消息处理同步阻塞：如果这个线程在等待当前函数返回时，没有执行其他消息处理，而是处于挂起等待状态# 异步阻塞、异步非阻塞， 同理如果在这个等待的过程中，等待者除了等待消息通知之外不能做其它的事情，那么该机制就是阻塞的同步非阻塞形式实际上是效率低下的，异步非阻塞形式却没有这样的问题，因为打电话是你(等待者)的事情，而通知你则是柜台(消息触发机制)的事情，程序没有在两种不同的操作中来回切换。1、同步阻塞形式效率是最低的，拿上面的例子来说，就是你专心排队，什么别的事都不做。实际程序中：就是未对fd 设置O_NONBLOCK标志位的read/write 操作；2、异步阻塞形式如果在银行等待办理业务的人采用的是异步的方式去等待消息被触发（通知），也就是领了一张小纸条，假如在这段时间里他不能离开银行做其它的事情，那么很显然，这个人被阻塞在了这个等待的操作上面；异步操作是可以被阻塞住的，只不过它不是在处理消息时阻塞，而是在等待消息通知时被阻塞。比如select 函数，假如传入的最后一个timeout参数为NULL，那么如果所关注的事件没有一个被触发，程序就会一直阻塞在这个select 调用处。3、同步非阻塞形式实际上是效率低下的，想象一下你一边打着电话一边还需要抬头看到底队伍排到你了没有，如果把打电话和观察排队的位置看成是程序的两个操作的话，这个程序需要在这两种不同的行为之间来回的切换，效率可想而知是低下的。很多人会写阻塞的read/write 操作，但是别忘了可以对fd设置O_NONBLOCK 标志位，这样就可以将同步操作变成非阻塞的了。4、异步非阻塞形式效率更高，因为打电话是你(等待者)的事情，而通知你则是柜台(消息触发机制)的事情，程序没有在两种不同的操作中来回切换。比如说，这个人突然发觉自己烟瘾犯了，需要出去抽根烟，于是他告诉大堂经理说，排到我这个号码的时候麻烦到外面通知我一下(注册一个回调函数)，那么他就没有被阻塞在这个等待的操作上面，自然这个就是异步+非阻塞的方式了。如果使用异步非阻塞的情况，比如aio_*组的操作，当发起一个aio_read操作时，函数会马上返回不会被阻塞，当所关注的事件被触发时会调用之前注册的回调函数进行处理。 123456789101112131415161718192021222324252627282930313233#### 小明的故事对上面所讲的概念再次进行一个场景梳理，上面已经明确说明，同步/异步关注的是消息通知的机制，而阻塞/非阻塞关注的是程序（线程）等待消息通知时的状态。以小明下载文件打个比方，从这两个关注点来再次说明这两组概念，希望能够更好的促进大家的理解。1、同步阻塞：小明一直盯着下载进度条，到 100% 的时候就完成。同步体现在：等待下载完成通知；阻塞体现在：等待下载完成通知过程中，不能做其他任务处理；2、同步非阻塞：小明提交下载任务后就去干别的，每过一段时间就去瞄一眼进度条，看到 100% 就完成。同步体现在：等待下载完成通知；非阻塞体现在：等待下载完成通知过程中，去干别的任务了，只是时不时会瞄一眼进度条；【小明必须要在两个任务间切换，关注下载进度】3、异步阻塞：小明换了个有下载完成通知功能的软件，下载完成就“叮”一声。不过小明仍然一直等待“叮”的声音（看起来很傻，不是吗）。异步体现在：下载完成“叮”一声通知；阻塞体现在：等待下载完成“叮”一声通知过程中，不能做其他任务处理；4、异步非阻塞：仍然是那个会“叮”一声的下载软件，小明提交下载任务后就去干别的，听到“叮”的一声就知道完成了。异步体现在：下载完成“叮”一声通知；非阻塞体现在：等待下载完成“叮”一声通知过程中，去干别的任务了，只需要接收“叮”声通知即可；【软件处理下载任务，小明处理其他任务，不需关注进度，只需接收软件“叮”声通知，即可】也就是说，同步/异步是“下载完成消息”通知的方式（机制），而阻塞/非阻塞则是在等待“下载完成消息”通知过程中的状态（能不能干其他任务），在不同的场景下，同步/异步、阻塞/非阻塞的四种组合都有应用。所以，综上所述，同步和异步仅仅是关注的消息如何通知的机制，而阻塞与非阻塞关注的是等待消息通知时的状态。也就是说，同步的情况下，是由处理消息者自己去等待消息是否被触发，而异步的情况下是由触发机制来通知处理消息者，所以在异步机制中，处理消息者和触发机制之间就需要一个连接的桥梁：在银行的例子中，这个桥梁就是小纸条上面的号码。在小明的例子中，这个桥梁就是软件“叮”的声音。","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python私有字段","slug":"Python私有字段","date":"2016-12-15T09:44:35.000Z","updated":"2016-12-15T09:44:58.000Z","comments":true,"path":"2016/12/15/Python私有字段/","link":"","permalink":"http://yoursite.com/2016/12/15/Python私有字段/","excerpt":"","text":"@property 在类中一般和私有字段一起使用。 类中如果有私有字段在外部是无法直接访问的，通过@property使其可读或可写。 经典类经典类中的私有字段是可读可写的。（没有只读功能） 123456789101112class Person: def __init__(self): self.__name = 'sate' @property def Name(self): return self.__namep1 = Person()print p1.Name #通过@property 可读。p1.Name = 'zheng' #可写print p1.Name 新式类新式类中的私有字段是只读，不可写，如果要可写，需要再创建一个被@xxx.setter修饰的特性。 如果想设置为外部只读或者外部可写特性，可使用如下方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# coding=utf-8class Class_1(object): def __init__(self, name, age): self.name = name # 定义一个私有字段age,外部无法直接访问 self.__age = age def read_name(self): print 'my name is %s ' % self.name# 外部无法访问,但是可以通过内部访问到。 def read_age(self): print 'my age is %s' % self.__age# 使用属性方法将age()方法变为一个类的静态属性。使之变为可读属性。 @property def age(self): return self.__age# 使__age私有字段变成可写,只需调用age属性并直接赋值即可(装饰器格式为‘@函数名.setter’)# 如果私有变量要设置为只读不可写，则直接去除本段即可。 @age.setter def age(self, value): self.__age = valuecla = Class_1('sate', 12)# 读取正常字段cla.read_name()# 调用方法读取__age私有字段cla.read_age()# 使用属性方法读取__age私有字段print cla.age# 更改类中的__私有字段cla.age = 18print cla.age# 结果==&gt;my name is sate my age is 121218","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python生成器","slug":"Python生成器","date":"2016-12-15T09:42:57.000Z","updated":"2016-12-15T09:43:36.000Z","comments":true,"path":"2016/12/15/Python生成器/","link":"","permalink":"http://yoursite.com/2016/12/15/Python生成器/","excerpt":"","text":"通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。而且，创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。 在Python中，这种一边循环一边计算的机制，称为生成器（Generator） 创建生成器1、将列表生成器的[]改为()就会创建一个generator 1234567891011121314151617181920212223242526# 列表生成器，一次性全部生成&gt;&gt;&gt; L = [i*i for i in range(5)]&gt;&gt;&gt; print L[0, 1, 4, 9, 16]# 创建生成器&gt;&gt;&gt; g = (i*i for i in range(5))&gt;&gt;&gt; print g&lt;generator object &lt;genexpr&gt; at 0x7fbbdbd68b90&gt;# 使用next()方法一个个打印出来。&gt;&gt;&gt; g.next()0&gt;&gt;&gt; g.next()1&gt;&gt;&gt; g.next()4&gt;&gt;&gt; g.next()9&gt;&gt;&gt; g.next()16&gt;&gt;&gt; g.next()Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;StopIteration&gt;&gt;&gt; 注：generator保存的是算法，每次调用next()，就计算出下一个元素的值，直到计算到最后一个元素，没有更多的元素时，抛出StopIteration的错误。这种情况下，使用for循环会更好，因为是可迭代的。 123456789&gt;&gt;&gt; g = (i*i for i in range(5))&gt;&gt;&gt; for i in g:... print i...014916 例：斐波那契数列，用函数实现，如下： 123456789101112131415161718192021222324252627282930313233# 普通函数&gt;&gt;&gt; def fib(max):... n,a,b = 0,0,1... while n &lt; max:... print b... a,b = b,a+b... n += 1...&gt;&gt;&gt; fib(6)112358# 使用生成器&gt;&gt;&gt; def fib(max):... n,a,b = 0,0,1... while n &lt; max:... yield b... a,b = b,a+b... n += 1...&gt;&gt;&gt; for i in fib(6):... print i...112358 2、使用yield关键字，该函数就变为一个生成器。 generator和函数的执行流程不一样。函数是顺序执行，遇到return语句或者最后一行函数语句就返回。而变成generator的函数，在每次调用next()的时候执行，遇到yield语句返回，再次执行时从上次返回的yield语句处继续执行。 12345678910111213141516171819202122&gt;&gt;&gt; def odd():... print \"step 1\"... yield 1... print \"step 2\"... yield 3... print \"step 3\"... yield 5...&gt;&gt;&gt; o = odd()&gt;&gt;&gt; o.next()step 11&gt;&gt;&gt; o.next()step 23&gt;&gt;&gt; o.next()step 35&gt;&gt;&gt; o.next()Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;StopIteration","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python排序","slug":"Python排序","date":"2016-12-15T09:42:04.000Z","updated":"2016-12-15T09:42:33.000Z","comments":true,"path":"2016/12/15/Python排序/","link":"","permalink":"http://yoursite.com/2016/12/15/Python排序/","excerpt":"","text":"内置函数sorted() / list.sort()的使用1234567891011121314# sorted()不会改变原有列表，并且可以在所有可迭代类型上使用&gt;&gt;&gt; help(sorted)Help on built-in function sorted in module __builtin__:sorted(...) sorted(iterable, cmp=None, key=None, reverse=False) --&gt; new sorted list# list.sort()改变原有列表，只能应用在 list中&gt;&gt;&gt; help(list.sort)Help on method_descriptor:sort(...) L.sort(cmp=None, key=None, reverse=False) -- stable sort *IN PLACE*; cmp(x, y) -&gt; -1, 0, 1 iterable：是可迭代类型; cmp：用于比较的函数，比较什么由key决定,有默认值，迭代集合中的一项; key：用列表元素的某个属性和函数进行作为关键字，有默认值，迭代集合中的一项; reverse：排序规则(升序或者降序). reverse = True (降序) 或者 reverse = False (降序，默认值)。 返回值：是一个经过排序的可迭代类型，与iterable一样。 ———cmp和key可以使用lambda表达式。 用key函数排序 (效率key&gt;cmp) 123456&gt;&gt;&gt; lis = [('Jim', 'C', 12), ('Tom', 'A', 18), ('Lili', 'B', 24)]&gt;&gt;&gt; &gt;&gt;&gt; print sorted(lis, key=lambda x:x[2])[('Jim', 'C', 12), ('Tom', 'A', 18), ('Lili', 'B', 24)]&gt;&gt;&gt; print sorted(lis, key=lambda x:x[1])[('Tom', 'A', 18), ('Lili', 'B', 24), ('Jim', 'C', 12)] 用cmp函数排序 12&gt;&gt;&gt; print sorted(lis, cmp=lambda x,y:cmp(x[2],y[2]))[('Jim', 'C', 12), ('Tom', 'A', 18), ('Lili', 'B', 24)] operator.itemgetter函数的使用operator模块提供itemgetter函数用于获取对象的哪些维的数据或者哪些key对应的数据,参数就是索引号或key值.可以设置多个索引号或key值。 对列表的操作： 12345678import operatora = ['a','b','c']b = operator.itemgetter(1) # 定义b函数，获取对象的1索引值print b # &lt;operator.itemgetter at 0x10db69b50&gt;print b(a) # 'b'b = operator.itemgetter(1,2)print b(a) # ('b', 'c') 对字典的操作： 123456789students = [&#123;'name':'fang', 'age':24&#125;, &#123;'name':'job', 'age':20&#125;, &#123;'name':'zen', 'age':40&#125;]b = operator.itemgetter('name', 'age')for i in students: print b(i) ....: ('fang', 24)('job', 20)('zen', 40) 注：operator.itemgetter函数获取的不是值，而是定义了一个函数，通过该函数作用到对象上才能获取值。其多与sorted函数一块使用,如下方法实现和上边一样的效果 123456789&gt;&gt;&gt; from operator import itemgetter&gt;&gt;&gt; lis = [('Jim', 'C', 12), ('Tom', 'A', 18), ('Lili', 'B', 24)]&gt;&gt;&gt; # 通过student的第三个域排序&gt;&gt;&gt; sorted(lis, key=itemgetter(2))[('Jim', 'C', 12), ('Tom', 'A', 18), ('Lili', 'B', 24)]# 根据第二个域和第三个域进行排序&gt;&gt;&gt; sorted(lis, key=itemgetter(1,2))[('Tom', 'A', 18), ('Lili', 'B', 24), ('Jim', 'C', 12)]","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python局部变量和全局变量","slug":"Python局部变量和全局变量","date":"2016-12-15T09:40:25.000Z","updated":"2016-12-15T09:41:07.000Z","comments":true,"path":"2016/12/15/Python局部变量和全局变量/","link":"","permalink":"http://yoursite.com/2016/12/15/Python局部变量和全局变量/","excerpt":"","text":"局部变量在函数定义中声明的变量，他们与在函数外使用的其它同名变量没有任何关系，即变量名称对函数来说是局部的。 123456789101112x = 50 #全局变量def func1(): x = 20 #局部变量，虽然和函数外边的 x 变量同名，但互不影响 print '局部变量x: ', xfunc1()print '全局变量x: ', x# 结果如下， 函数内的赋值并没有影响到函数外 x 的值局部变量x: 20全局变量x: 50 全局声明如果想在函数内改变某一个全局变量，那必须使用global语句。 123456789101112x = 50 # 全局变量def func1(): global x #定义全局变量 x = 20 #定义后的 x 变量可以在全局范围内更改 print '函数内变量x: ', xfunc1()print '全局变量x: ', x# 结果，函数内的赋值更改了函数外 x 的值局部变量x: 20全局变量x: 20","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python高阶函数","slug":"Python高阶函数","date":"2016-12-15T09:38:14.000Z","updated":"2016-12-15T09:39:22.000Z","comments":true,"path":"2016/12/15/Python高阶函数/","link":"","permalink":"http://yoursite.com/2016/12/15/Python高阶函数/","excerpt":"","text":"文中知识点和代码示例学习自慕课网，python进阶部分（http://www.imooc.com/learn/317）.学习笔记 把函数作为参数例1：求两个数字绝对值的和(abs(x)+abs(y)) 12345def add(x,y,f): return f(x) + f(y)# add 函数的x,y,f 参数可以是任何值，如果 f 是个函数，则 x，y 两个参数分别带入到 f 函数中求值后，再做为 add 函数的参数传入。print add(-5,9,abs) 例2：求√x + √y的值 123456import mathdef add(x, y, f): return f(x) + f(y)print add(25, 9, math.sqrt) map() 函数它接收一个函数f和一个list，并通过把函数f依次作用在list的每个元素上，得到一个新的list 并返回。 例1：把列表总每个元素都取二次方 12345def f(x): return x * xprint map(f,[1,2,3,4,5,6,7,8,9])#[1, 4, 9, 16, 25, 36, 49, 64, 81] 例2：将列表中的字符串都变为首字母大写 12345def format_name(s): return s.title()print map(format_name, ['adam', 'LISA', 'barT'])#['Adam', 'Lisa', 'Bart'] reduce() 函数reduce()函数接收的参数和map()类似，一个函数f，一个list，但行为和map()不同，reduce()传入的函数f必须接收两个参数,reduce()对list的每个元素反复调用函数f，并返回最终结果值。 例1：求一个列表中所有元素的和 1234567891011def f(x,y): return x + yprint reduce(f,[1,2,3,4,5])先计算头两个元素：f(1, 2)，结果为3；再把结果和第3个元素计算：f(3, 3)，结果为6；再把结果和第4个元素计算：f(6, 4)，结果为10；再把结果和第5个元素计算：f(10, 5)，结果为15；由于没有更多的元素了，计算结束，返回结果15.#15 filter() 函数filter()函数接收一个函数f和一个list，这个函数f的作用是对每个元素进行判断，返回True或False,filter()根据判断结果自动过滤掉不符合条件的元素，返回由符合条件元素组成的新list。 例：删除一个list中的偶数，保留奇数 12345def is_odd(x): return x % 2 == 1print filter(is_odd(),[1,2,3,4,5,6,6,7,8,9])#[1, 3, 5, 7, 9] 可以用来删除一个列表中我们不需要的元素。也可以使用如下方法来完成： 123[i for i in [1,2,3,4,5,6,6,7,8,9] if i % 2 ==1 ]#[1, 3, 5, 7, 9] sorted() 函数Python内置的 sorted()函数可对list进行排序： 12&gt;&gt;&gt;sorted([36, 5, 12, 9, 21])[5, 9, 12, 21, 36] 但 sorted()也是一个高阶函数，它可以接收一个比较函数来实现自定义排序，比较函数的定义是，传入两个待比较的元素 x, y，如果 x 应该排在 y 的前面，返回 -1，如果 x 应该排在 y 的后面，返回 1。如果 x 和 y 相等，返回 0。 例：实现倒序排列 12345678910def reversed_cmp(x, y): if x &gt; y: return -1 if x &lt; y: return 1 return 0print sorted([36, 5, 12, 9, 21], reversed_cmp)#[36, 21, 12, 9, 5] 其他方法： 123456# 先排序，后反转&gt;&gt;&gt; sorted([36, 21, 12, 9, 5])[::-1][36, 21, 12, 9, 5]# 使用reversed()方法，返回一个迭代器。 如果使用reverse(),是直接修改原列表，不会返回新的列表&gt;&gt;&gt; list(reversed(sorted([36, 5, 12, 9, 21])))[36, 21, 12, 9, 5] 返回函数Python的函数不但可以返回int、str、list、dict等数据类型，还可以返回函数！ 例1：定义一个函数 f()，我们让它返回一个函数 g 1234567891011121314def f(): print 'call f()...' # 定义函数g: def g(): print 'call g()...' # 返回函数g: return g &gt;&gt;&gt; x = f() # 调用f()call f()...&gt;&gt;&gt; x # 变量x是f()返回的函数g：&lt;function g at 0x1037bf320&gt;&gt;&gt;&gt; x() # x指向函数g，因此可以调用call g()... # 调用x()就是执行g()函数定义的代码 例2：写一个函数calc_prod(lst)，它接收一个list，返回一个函数，返回函数可以计算参数的乘积。 123456789def calc_prod(lst): def f(x,y): return x * y def chengji(): return reduce(f,lst) return chengjif = calc_prod([1, 2, 3, 4])print f() 闭包例如上一小节返回函数中的例2，chengji内层函数引用了外层函数calc_prod的lst变量。像这种内层函数引用了外层函数的变量（参数也算变量），然后返回内层函数的情况，称为闭包（Closure）。 闭包的特点：返回的函数还引用了外层函数的局部变量，所以，要正确使用闭包，就要确保引用的局部变量在函数返回后不能变。举例如下： 123456789101112# 希望一次返回3个函数，分别计算1x1,2x2,3x3:def count(): fs = [] for i in range(1, 4): def f(): return i*i fs.append(f) return fsf1, f2, f3 = count()#9 9 9 原因就是当count()函数返回了3个函数时，这3个函数所引用的变量i的值已经变成了3。由于f1、f2、f3并没有被调用，所以，此时他们并未计算i*i，当 f1 被调用时： 12&gt;&gt;&gt; f1()9 # 因为f1现在才计算i*i，但现在i的值已经变为3 因此，返回函数不要引用任何循环变量，或者后续会发生变化的变量。因此改成如下代码： 1234567891011121314151617181920212223242526272829303132333435# 法一def count(): fs = [] for i in range(1, 4): def f(j): # 借助函数f来避免引用循环变量i def g(): return j*j return g r = f(i) fs.append(r) return fsf1, f2, f3 = count()print f1(), f2(), f3()#1 4 9# 法二def count(): fs = [] def f(j): def g(): return j*j return g for i in range(1, 4): r = f(i) fs.append(r) return fsf1, f2, f3 = count()print f1(), f2(), f3()#1 4 9 匿名函数 lambda高阶函数可以接收函数做参数，有些时候，我们不需要显式地定义函数，直接传入匿名函数更方便。 在Python中，对匿名函数提供了有限支持。还是以map()函数为例，计算f(x)=x*x时，除了定义一个f(x)的函数外，还可以直接传入匿名函数 12345&gt;&gt;&gt; a = lambda x:x*x&gt;&gt;&gt; a(5)25&gt;&gt;&gt; map(lambda x: x * x, [1, 2, 3, 4, 5, 6, 7, 8, 9])[1, 4, 9, 16, 25, 36, 49, 64, 81] 匿名函数有个限制，就是只能有一个表达式，不写return，返回值就是该表达式的结果。 123def is_not_empty(s): return s and len(s.strip()) &gt; 0filter(is_not_empty, ['test', None, '', 'str', ' ', 'END']) 返回函数的时候，也可以返回匿名函数： 123456# 使用 if..else 来实现abs函数的功能&gt;&gt;&gt; myabs = lambda x: -x if x &lt; 0 else x &gt;&gt;&gt; myabs(-1)1&gt;&gt;&gt; myabs(1)1 例：使用匿名函数简化代码 12345678910# 源代码def is_not_empty(s): return s and len(s.strip()) &gt; 0filter(is_not_empty, ['test', None, '', 'str', ' ', 'END'])# 使用匿名函数print filter(lambda x:x and len(x.strip()) &gt; 0,['test', None, '', 'str', ' ', 'END'])# 使用 for..in..if 语句print [i for i in ['test', None, '', 'str', ' ', 'END'] if i and len(i.strip())&gt;0] 偏函数当一个函数有很多参数时，调用者就需要提供多个参数。如果减少参数个数，就可以简化调用者的负担。 比如，int()函数可以把字符串转换为整数，当仅传入字符串时，int()函数默认按十进制转换： 12&gt;&gt;&gt; int('12345')12345 但int()函数还提供额外的base参数，默认值为10。如果传入base参数，就可以做 N 进制的转换： 1234&gt;&gt;&gt; int('12345', base=8)5349&gt;&gt;&gt; int('12345', 16)74565 假设要转换大量的二进制字符串，每次都传入int(x, base=2)非常麻烦，于是，我们想到，可以定义一个int2()的函数，默认把base=2传进去： 12345678def int2(x, base=2): return int(x, base) # 这样，我们转换二进制就非常方便了：&gt;&gt;&gt; int2('1000000')64&gt;&gt;&gt; int2('1010101')85 functools.partial就是帮助我们创建一个偏函数的，不需要我们自己定义int2()，可以直接使用下面的代码创建一个新的函数int2： 123456&gt;&gt;&gt; import functools&gt;&gt;&gt; int2 = functools.partial(int, base=2)&gt;&gt;&gt; int2('1000000')64&gt;&gt;&gt; int2('1010101')85 所以，functools.partial可以把一个参数多的函数变成一个参数少的新函数，少的参数需要在创建时指定默认值，这样，新函数调用的难度就降低了。","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python构造和析构函数","slug":"Python构造和析构函数","date":"2016-12-15T09:36:12.000Z","updated":"2016-12-15T09:36:55.000Z","comments":true,"path":"2016/12/15/Python构造和析构函数/","link":"","permalink":"http://yoursite.com/2016/12/15/Python构造和析构函数/","excerpt":"","text":"构造函数：__init__(self) 构析函数：__del__(self),一般情况下不会使用，会在最后执行。 __call__方法：__call__ 使用方式如下: 123456789101112131415161718192021# coding=utf-8class Foo(object): # 构造函数 def __init__(self): pass # __call__ 方法 def __call__(self, *args, **kwargs): print '调用__call__方法', args, kwargs # 析构函数，当检测到没有对象使用时，会自动关闭 def __del__(self): print '解释器马上要销毁自己了' foo = Foo()foo(123,name = 'sate') ## 执行类的__call__方法, 可带入参数# 结果==&gt;调用__call__方法 (123,) &#123;'name': 'sate'&#125;解释器马上要销毁自己了 #在最后执行","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python反射","slug":"Python反射","date":"2016-12-15T09:34:48.000Z","updated":"2016-12-15T09:35:12.000Z","comments":true,"path":"2016/12/15/Python反射/","link":"","permalink":"http://yoursite.com/2016/12/15/Python反射/","excerpt":"","text":"反射： 通过字符串的形式来导入模块，并以字符串的形式执行函数 123456789101112131415#例： 根据变量temp， 来导入模块 sys。这样实现了通过字符串的形式来导入模块# 通过 __import__ 函数来获取字符串中定义的模块temp = 'sys'model1 = __import__(temp)print model1.path# 例：以字符串的形式执行函数,# 通过 getattr 函数来获取字符串定义的模块中的方法。func = 'path'Func = getattr(model1, func)for i in Func: print i 应用，大部分应用在web框架中。12345678910111213141516171819# 目录结构： 当前目录下有backend项目包#- backend# - __init__.py# - account.py # 里边有 def login(): 函数#- __init__.py#- index.py #当前文件# 输入 account/logindate = raw_input('输入地址: ')lis = date.split('/')userspance = __import__('backend.' + lis[0])model = getattr(userspance, lis[0])func = getattr(model, lis[1])func()","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python多重继承顺序","slug":"Python多重继承顺序","date":"2016-12-15T09:33:19.000Z","updated":"2016-12-15T09:33:54.000Z","comments":true,"path":"2016/12/15/Python多重继承顺序/","link":"","permalink":"http://yoursite.com/2016/12/15/Python多重继承顺序/","excerpt":"","text":"本文借鉴自 http://www.cnblogs.com/panyinghua/p/3283726.html 当类有多个超类，而且超类中有相同的方法时，继承顺序就很重要，如下： 12345678910 class A (def save(self):...) # A 中有self方法 / \\ / \\class B class C (def save(self):...) # B 和 C 中都继承 A，只有C中重写save方法 \\ / \\ / \\ / class D # 继承 B 和 C 旧式类在旧式类中，会根据深度优先(depth-first)的顺序来继承，由左至右依次查找save()方法，D -&gt; B -&gt; A -&gt;C,当查到方法时，立刻放回，不在继续查找。 1234567891011121314151617181920212223242526# 例：class A: def __init__(self): print 'it is A' def save(self): print 'save method from A'class B(A): def __init__(self): print 'it is B'class C(A): def __init__(self): print 'it is C' def save(self): print 'save method from C'class D(B, C): def __init__(self): print 'it is D'd = D()d.save()# 结果 ==》it is Dsave method from A # 根据上边的顺序，查到A中的save方法，即返回。 新式类新式类中会根据方法解析顺序（MRO）来进行搜索，广度优先，当查到对应方法属性时，立即返回，不再继续查找。 __mro__属性，标记了python继承层次中父类的查找顺序，Python的多重继承机制就是按照__mro__的顺序进行查找，一旦找到对应属性，则查找马上返回。 12345678910111213141516171819202122232425262728# 例 1class A(object): def __init__(self): print 'it is A' def save(self): print 'save method from A'class B(A): def __init__(self): print 'it is B'class C(A): def __init__(self): print 'it is C' def save(self): print 'save method from C'class D(B, C): def __init__(self): print 'it is D'print D.__mro__d = D()d.save()# 结果==》(&lt;class '__main__.D'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;type 'object'&gt;)it is Dsave method from C 12345678910111213141516171819202122# 例 2class A(object): def save(self): print ('save A')class B(object): def save(self): print ('save B')class C(object): def save(self): print ('save C')class D(B,C,A): passprint D.__mro__cla = D()cla.save()# 结果(&lt;class '__main__.D'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;type 'object'&gt;)save B 12345678910111213141516171819202122232425262728293031# 例 2class B(object): def foo(self): print ('foo B') def bar(self): print 'bar B'class A(object): def foo(self): print ('foo A')class C1(A, B): passclass C2(A, B): def bar(self): print 'bar C2'class D(C1, C2): passprint D.__mro__d = D()d.foo()d.bar()# 结果(&lt;class '__main__.D'&gt;, &lt;class '__main__.C1'&gt;, &lt;class '__main__.C2'&gt;, &lt;class '__main__.A'&gt;, &lt;class '__main__.B'&gt;, &lt;type 'object'&gt;)foo Abar C2","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python调试","slug":"Python调试","date":"2016-12-15T09:31:18.000Z","updated":"2016-12-15T09:32:46.000Z","comments":true,"path":"2016/12/15/Python调试/","link":"","permalink":"http://yoursite.com/2016/12/15/Python调试/","excerpt":"","text":"官方文档：https://docs.python.org/2/library/pdb.html 从命令行运行1$ python -m pdb my_script.py 从脚本内部运行也可以在脚本内部设置断点，这样就可以在某些特定点查看变量信息和各种执行时信息了。这里将使用pdb.set_trace()方法来实现。举个例子： 1234567import pdbdef make_bread(): pdb.set_trace() return \"I don't have time\"print(make_bread()) 试下保存上面的脚本后运行之。你会在运行时马上进入debugger模式。 命令列表 c: 继续执行 w: 显示当前正在执行的代码行的上下文信息 a: 打印当前函数的参数列表 s: 执行当前代码行，并停在第一个能停的地方（相当于单步进入） n: 继续执行到当前函数的下一行，或者当前行直接返回（单步跳过） 单步跳过n(next)和单步进入s(step)的区别在于， 单步进入会进入当前行调用的函数内部并停在里面， 而单步跳过会（几乎）全速执行完当前行调用的函数，并停在当前函数的下一行。 更多的命令在官方文档","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python类","slug":"Python类","date":"2016-12-15T09:26:59.000Z","updated":"2016-12-15T09:27:36.000Z","comments":true,"path":"2016/12/15/Python类/","link":"","permalink":"http://yoursite.com/2016/12/15/Python类/","excerpt":"","text":"###新式类和旧式类 在python2.x的版本中，有“新式类”和“旧式类（也叫做经典类）”之分。新式类是python2.2引进的，在此后的版本中，我们一般用的都是新式类。 定义旧式类： 123&gt;&gt;&gt; class AA:... pass... 定义新式类的方法: 第一种： 123&gt;&gt;&gt; class BB(object):... pass... 跟旧式类的区别就在于类的名字后面跟上(object)，这其实是一种名为“继承”的类的操作，当前的类BB是以类object为上级的（object被称为父类），即BB是继承自类object的新类。在python3中，所有的类自然地都是类object的子类，就不用彰显出继承关系了。 第二种： 在类的前面写上这么一句：__metaclass__ == type，然后定义类的时候，就不需要在名字后面写(object)了。 123456789&gt;&gt;&gt; __metaclass__ = type&gt;&gt;&gt; class CC:... pass... &gt;&gt;&gt; cc = CC()&gt;&gt;&gt; cc.__class__&lt;class '__main__.CC'&gt;&gt;&gt;&gt; type(cc)&lt;class '__main__.CC'&gt; ###创建类 例：定义一个比较常见的类，一般情况下，都是这样子的。 1234567891011121314#!/usr/bin/env python# coding=utf-8__metaclass__ = typeclass Person: def __init__(self, name): self.name = name def getName(self): return self.name def color(self, color): print \"%s is %s\" % (self.name, color) 新式类 __metaclass__ = type，意味着下面的类是新式类。 定义类 class Person，这是在声明创建一个名为”Person”的类。类的名称一般用大写字母开头，这是惯例。如果名称是两个单词，那么两个单词的首字母都要大写，例如class HotPerson，这种命名方法有一个形象的名字，叫做“驼峰式命名”。当然，如果故意不遵循此惯例，也未尝不可，但是，会给别人阅读乃至于自己以后阅读带来麻烦，不要忘记“代码通常是给人看的，只是偶尔让机器执行”。 接下来，分别以缩进表示的，就是这个类的内容了。其实那些东西看起来并不陌生，你一眼就认出它们了——就是已经学习过的函数。没错，它们就是函数。不过，很多程序员喜欢把类里面的函数叫做“方法”。是的，就是上节中说到的对象的“方法”。我也看到有人撰文专门分析了“方法”和“函数”的区别。但是，我倒是认为这不重要，重要的是类的中所谓“方法”和前面的函数，在数学角度看，丝毫没有区别。所以，你尽可以称之为函数。当然，听到有人说方法，也不要诧异和糊涂。它们本质是一样的。 需要再次提醒，函数的命名方法是以def发起，并且函数名称首字母不要用大写，可以使用aa_bb的样式，也可以使用aaBb的样式，一切看你的习惯了。 不过，要注意的是，类中的函数（方法）的参数跟以往的参数样式有区别，那就是每个函数必须包括self参数，并且作为默认的第一个参数。这是需要注意的地方。 初始化 def __init__，这个函数是一个比较特殊的，并且有一个名字，叫做初始化函数（注意，很多教材和资料中，把它叫做构造函数，这种说法貌似没有错误，但是一来从字面意义上看，它对应的含义是初始化，二来在python中它的作用和其它语言比如java中的构造函数还不完全一样，因为还有一个__new__的函数，是真正地构造。所以，在本教程中，我称之为初始化函数）。它是以两个下划线开始，然后是init，最后以两个下划线结束。 123所谓初始化，就是让类有一个基本的面貌，而不是空空如也。做很多事情，都要初始化，让事情有一个具体的起点状态。比如你要喝水，必须先初始化杯子里面有水。在python的类中，初始化就担负着类似的工作。这个工作是在类被实例化的时候就执行这个函数，从而将初始化的一些属性可以放到这个函数里面。 此例子中的初始化函数，就意味着实例化的时候，要给参数name提供一个值，作为类初始化的内容。通俗点啰嗦点说，就是在这个类被实例化的同时，要通过name参数传一个值，这个值被一开始就写入了类和实例中，成为了类和实例的一个属性。比如： 1girl = Person('sate') girl是一个实例对象，就如同前面所说的一样，它有属性和方法。这里仅说属性吧。当通过上面的方式实例化后，就自动执行了初始化函数，让实例girl就具有了name属性。 很多时候，并不是每次都要从外面传入数据，有时候会把初始化函数的某些参数设置默认值，如果没有新的数据传入，就应用这些默认值。比如： 1234567891011121314151617181920212223242526272829class Person: def __init__(self, name, lang=\"golang\", website=\"www.google.com\"): self.name = name self.lang = lang self.website = website self.email = \"qiwsir@gmail.com\"laoqi = Person(\"LaoQi\") info = Person(\"qiwsir\",lang=\"python\",website=\"qiwsir.github.io\")print \"laoqi.name=\",laoqi.nameprint \"info.name=\",info.nameprint \"-------\"print \"laoqi.lang=\",laoqi.langprint \"info.lang=\",info.langprint \"-------\"print \"laoqi.website=\",laoqi.websiteprint \"info.website=\",info.website#运行结果laoqi.name= LaoQiinfo.name= qiwsir-------laoqi.lang= golanginfo.lang= python-------laoqi.website= www.google.cominfo.website= qiwsir.github.io ###函数（方法） 还是回到本节开头的那个类。构造函数下面的两个函数：def getName(self),def color(self, color)，这两个函数和前面的初始化函数有共同的地方，即都是以self作为第一个参数。 12def getName(self): return self.name 这个函数中的作用就是返回在初始化时得到的值。 12girl = Person('canglaoshi')name = girl.getName() girl.getName()就是调用实例girl的方法。调用该方法的时候特别注意，方法名后面的括号不可少，并且括号中不要写参数，在类中的getName(self)函数第一个参数self是默认的，当类实例化之后，调用此函数的时候，第一个参数不需要赋值。那么，变量name的最终结果就是name = “canglaoshi”。 ###类和实例 有必要总结一下类和实例的关系： “类提供默认行为，是实例的工厂”（源自Learning Python），这句话非常经典，一下道破了类和实例的关系。所谓工厂，就是可以用同一个模子做出很多具体的产品。类就是那个模子，实例就是具体的产品。所以，实例是程序处理的实际对象。 类是由一些语句组成，但是实例，是通过调用类生成，每次调用一个类，就得到这个类的新的实例。 对于类的：class Person，class是一个可执行的语句。如果执行，就得到了一个类对象，并且将这个类对象赋值给对象名（比如Person）。 ###self的作用 在Person实例化的过程中girl = Person(“canglaoshi”)，字符串”canglaoshi”通过初始化函数（__init__()）的参数已经存入到内存中，并且以Person类型的面貌存在，组成了一个对象，这个对象和变量girl建立引用关系。这个过程也可说成这些数据附加到一个实例上。这样就能够以:object.attribute的形式，在程序中任何地方调用某个数据，例如上面的程序中以girl.name的方式得到”canglaoshi”。这种调用方式，在类和实例中经常使用，点号“.”后面的称之为类或者实例的属性。 这是在程序中，并且是在类的外面。如果在类的里面，想在某个地方使用实例化所传入的数据（”canglaoshi”），怎么办？ 在类内部，就是将所有传入的数据都赋给一个变量，通常这个变量的名字是self。注意，这是习惯，而且是共识，所以，看官不要另外取别的名字了。 在初始化函数中的第一个参数self，就是起到了这个作用——接收实例化过程中传入的所有数据，这些数据是初始化函数后面的参数导入的。显然，self应该就是一个实例（准确说法是应用实例），因为它所对应的就是具体数据。 如果将上面的类稍加修改，看看效果： 12345678910#!/usr/bin/env python# coding=utf-8__metaclass__ = typeclass Person: def __init__(self, name): self.name = name print self #新增 print type(self) #新增 其它部分省略。当初始化的时候，就首先要运行构造函数，同时就打印新增的两条。结果是 12&lt;__main__.Person object at 0xb7282cec&gt;&lt;class '__main__.Person'&gt; 证实了推理。self就是一个实例（准确说是实例的引用变量）。 self这个实例跟前面说的那个girl所引用的实例对象一样，也有属性。那么，接下来就规定其属性和属性对应的数据。上面代码中： 1self.name = name 就是规定了self实例的一个属性，这个属性的名字也叫做name，这个属性的值等于初始化函数的参数name所导入的数据。注意，self.name中的name和初始化函数的参数name没有任何关系，它们两个一样，只不过是一种起巧合（经常巧合，其实是为了省事和以后识别方便，故意让它们巧合。），或者说是写代码的人懒惰，不想另外取名字而已，无他。当然，如果写成self.xxxooo = name，也是可以的。 其实，从效果的角度来理解，这么理解更简化：类的实例girl对应着self，girl通过self导入实例属性的所有数据。 当然，self的属性数据，也不一定非得是由参数传入的，也可以在构造函数中自己设定。比如： 12345678910111213#!/usr/bin/env python#coding:utf-8__metaclass__ = typeclass Person: def __init__(self, name): self.name = name self.email = \"qiwsir@gmail.com\" #这个属性不是通过参数传入的info = Person(\"qiwsir\") #换个字符串和实例化变量print \"info.name=\",info.nameprint \"info.email=\",info.email #info通过self建立实例，并导入实例属性数据 运行结果 12info.name= qiwsirinfo.email= qiwsir@gmail.com #打印结果 通过这个例子，其实让我们拓展了对self的认识，也就是它不仅仅是为了在类内部传递参数导入的数据，还能在初始化函数中，通过self.attribute的方式，规定self实例对象的属性，这个属性也是类实例化对象的属性，即做为类通过初始化函数初始化后所具有的属性。所以在实例info中，通过info.email同样能够得到该属性的数据。在这里，就可以把self形象地理解为“内外兼修”了。或者按照前面所提到的，将info和self对应起来，self主内，info主外。","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python函数4","slug":"Python函数4","date":"2016-12-15T09:19:31.000Z","updated":"2016-12-15T09:25:46.000Z","comments":true,"path":"2016/12/15/Python函数4/","link":"","permalink":"http://yoursite.com/2016/12/15/Python函数4/","excerpt":"","text":"递归如果用上面的做递归的定义，总感觉有点调侃，来个严肃的(选自维基百科)： 递归（英语：Recursion），又译为递回，在数学与计算机科学中，是指在函数的定义中使用函数自身的方法。 根据斐波那契数列的定义，可以直接写成这样的斐波那契数列递归函数。 1234567891011121314151617#!/usr/bin/env python# coding=utf-8def fib(n): \"\"\" This is Fibonacci by Recursion. \"\"\" if n==0: return 0 elif n==1: return 1 else: return fib(n-1) + fib(n-2)if __name__ == \"__main__\": f = fib(10) print f fib(n-1) + fib(n-2)就是又调用了这个函数自己，实现递归。为了明确递归的过程，下面走一个计算过程（考虑到次数不能太多，就让n=3） 12345671. n=3,fib(3)，自然要走return fib(3-1) + fib(3-2)分支2. 先看fib(3-1),即fib(2)，也要走else分支，于是计算fib(2-1) + fib(2-2)3. fib(2-1)即fib(1)，在函数中就要走elif分支，返回1，即fib(2-1)=1。同理，容易得到fib(2-2)=0。将这两个值返回到上面一步。得到fib(3-1)=1+0=14. 再计算fib(3-2),就简单了一些，返回的值是1，即fib(3-2)=15. 最后计算第一步中的结果：fib(3-1) + fib(3-2) = 1 + 1 = 2，将计算结果2作为返回值从而得到fib(3)的结果是2。 从上面的过程中可以看出，每个递归的过程，都是向着最初的已知条件a0=0,a1=1方向挺近一步，直到通过这个最底层的条件得到结果，然后再一层一层向上回馈计算机结果。 其实，上面的代码有一个问题。因为a0=0,a1=1是已知的了，不需要每次都判断一边。所以，还可以优化一下。优化的基本方案就是初始化最初的两个值。 1234567891011121314151617181920#!/usr/bin/env python# coding=utf-8\"\"\"the better Fibonacci\"\"\"meno = &#123;0:0, 1:1&#125; #初始化def fib(n): if not n in meno: #如果不在初始化范围内 meno[n] = fib(n-1) + fib(n-2) return meno[n]if __name__ == \"__main__\": f = fib(10) print f#运行结果$ python 20402.py 55 几个特殊的函数filter、map、reduce、lambda、yield lambda例子：讲list中每个数字增加3，并输出到新的list中 1234567891011121314&gt;&gt;&gt; def add(x): #定义一个函数，将输入的变量增加3,然后返回增加之后的值... x += 3... return x... &gt;&gt;&gt; numbers = range(10)&gt;&gt;&gt; numbers[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] #有这样一个list，想让每个数字增加3,然后输出到一个新的list中&gt;&gt;&gt; new_numbers = []&gt;&gt;&gt; for i in numbers:... new_numbers.append(add(i)) #调用add()函数，并append到list中... &gt;&gt;&gt; new_numbers[3, 4, 5, 6, 7, 8, 9, 10, 11, 12] 在这个例子中，add()只是一个中间操作。当然，上面的例子完全可以用别的方式实现。比如： 1234&gt;&gt;&gt; numbers = range(10)&gt;&gt;&gt; new_numbers = [ i+3 for i in numbers ]&gt;&gt;&gt; new_numbers[3, 4, 5, 6, 7, 8, 9, 10, 11, 12] 使用lambda实现，如下： 12345678910111213141516171819202122# 简单的例子&gt;&gt;&gt; lam = lambda x:x+3&gt;&gt;&gt; lam(1)4&gt;&gt;&gt; lam(2)5&gt;&gt;&gt; lam = lambda x:x*3&gt;&gt;&gt; lam(2)6&gt;&gt;&gt; lam = lambda x,y:x*y&gt;&gt;&gt; lam(2,3)6# 实现上述方法：&gt;&gt;&gt; numbers = range(10)&gt;&gt;&gt; lam = lambda x:x+3&gt;&gt;&gt; n2 = []&gt;&gt;&gt; for i in numbers:... n2.append(lam(i))... &gt;&gt;&gt; n2[3, 4, 5, 6, 7, 8, 9, 10, 11, 12] 通过上面例子，总结一下lambda函数的使用方法： 在lambda后面直接跟变量 变量后面是冒号 冒号后面是表达式，表达式计算结果就是本函数的返回值 1lambda arg1, arg2, ...argN : expression using arguments 要特别提醒看官：虽然lambda 函数可以接收任意多个参数 (包括可选参数) 并且返回单个表达式的值，但是lambda 函数不能包含命令，包含的表达式不能超过一个。不要试图向 lambda 函数中塞入太多的东西；如果你需要更复杂的东西，应该定义一个普通函数，然后想让它多长就多长。 就lambda而言，它并没有给程序带来性能上的提升，它带来的是代码的简洁。比如，要打印一个list，里面依次是某个数字的1次方，二次方，三次方，四次方。用lambda可以这样做： 12345&gt;&gt;&gt; lamb = [ lambda x:x,lambda x:x**2,lambda x:x**3,lambda x:x**4 ]&gt;&gt;&gt; for i in lamb:... print i(3),... 3 9 27 81 ###mapmap()是python的一个内置函数，它的基本样式是： 1map(func,seq) func是一个函数，seq是一个序列对象。在执行的时候，序列对象中的每个元素，按照从左到右的顺序，依次被取出来，并塞入到func那个函数里面，并将func的返回值依次存到一个list中。 123456789101112131415161718&gt;&gt;&gt; items = [1,2,3,4,5]&gt;&gt;&gt; squared = []&gt;&gt;&gt; for i in items:... squared.append(i**2)... &gt;&gt;&gt; squared[1, 4, 9, 16, 25]&gt;&gt;&gt; def sqr(x): return x**2... &gt;&gt;&gt; map(sqr,items)[1, 4, 9, 16, 25]&gt;&gt;&gt; map(lambda x: x**2, items)[1, 4, 9, 16, 25]&gt;&gt;&gt; [ x**2 for x in items ] #这个我最喜欢了，一般情况下速度足够快，而且可读性强[1, 4, 9, 16, 25] 理解要点： 对iterable中的每个元素，依次应用function的方法（函数）（这本质上就是一个for循环）。 将所有结果返回一个list。 如果参数很多，则对那些参数并行执行function。 例如: 1234&gt;&gt;&gt; lst1 = [1,2,3,4,5]&gt;&gt;&gt; lst2 = [6,7,8,9,0]&gt;&gt;&gt; map(lambda x,y: x+y, lst1,lst2) #将两个列表中的对应项加起来，并返回一个结果列表[7, 9, 11, 13, 5] 请看官注意了，上面这个例子如果用for循环来写，还不是很难，如果扩展一下，下面的例子用for来改写，就要小心了： 12345&gt;&gt;&gt; lst1 = [1,2,3,4,5]&gt;&gt;&gt; lst2 = [6,7,8,9,0]&gt;&gt;&gt; lst3 = [7,8,9,2,1]&gt;&gt;&gt; map(lambda x,y,z: x+y+z, lst1,lst2,lst3)[14, 17, 20, 15, 6] ###reduce 12&gt;&gt;&gt; reduce(lambda x,y: x+y,[1,2,3,4,5]15 原来map是上下运算，reduce是横着逐个元素进行运算。 为了锻炼思维，看这么一个问题，有两个list，a = [3,9,8,5,2],b=[1,4,9,2,6],计算：a[0]b[0]+a[1]b[1]+…的结果。 12345678910111213141516171819202122232425262728&gt;&gt;&gt; a[3, 9, 8, 5, 2]&gt;&gt;&gt; b[1, 4, 9, 2, 6]&gt;&gt;&gt; zip(a,b) #复习一下zip，下面的方法中要用到[(3, 1), (9, 4), (8, 9), (5, 2), (2, 6)]&gt;&gt;&gt; sum(x*y for x,y in zip(a,b)) #解析后直接求和133&gt;&gt;&gt; new_list = [x*y for x,y in zip(a,b)] #可以看做是上面方法的分布实施&gt;&gt;&gt; #这样解析也可以：new_tuple = (x*y for x,y in zip(a,b))&gt;&gt;&gt; new_list[3, 36, 72, 10, 12]&gt;&gt;&gt; sum(new_list) #或者:sum(new_tuple)133&gt;&gt;&gt; reduce(lambda sum,(x,y): sum+x*y,zip(a,b),0) #这个方法是在耍酷呢吗？133&gt;&gt;&gt; from operator import add,mul #耍酷的方法也不止一个&gt;&gt;&gt; reduce(add,map(mul,a,b))133&gt;&gt;&gt; reduce(lambda x,y: x+y, map(lambda x,y: x*y, a,b)) #map,reduce,lambda都齐全了，更酷吗？133 filter通过下面代码体会： 123456789101112&gt;&gt;&gt; numbers = range(-5,5)&gt;&gt;&gt; numbers[-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]&gt;&gt;&gt; filter(lambda x: x&gt;0, numbers) [1, 2, 3, 4]&gt;&gt;&gt; [x for x in numbers if x&gt;0] #与上面那句等效[1, 2, 3, 4]&gt;&gt;&gt; filter(lambda c: c!='i', 'qiwsir') #能不能对应上面文档说明那句话呢？'qwsr' #“If iterable is a string or a tuple, the result also has that type;”","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python函数3","slug":"Python函数3","date":"2016-12-15T09:19:28.000Z","updated":"2016-12-15T09:22:40.000Z","comments":true,"path":"2016/12/15/Python函数3/","link":"","permalink":"http://yoursite.com/2016/12/15/Python函数3/","excerpt":"","text":"多个参数的函数既然有很多不确定性，那么函数的参数的个数，也当然有不确定性，函数怎么解决这个问题呢？python用这样的方式解决参数个数的不确定性： 123456789def func(x,*arg): print x #输出参数x的值 result = x print arg #输出通过*arg方式得到的值 for i in arg: result +=i return resultprint func(1,2,3,4,5,6,7,8,9) #赋给函数的参数个数不仅仅是2个 运行此代码后，得到如下结果： 1231 #这是函数体内的第一个print，参数x得到的值是1(2, 3, 4, 5, 6, 7, 8, 9) #这是函数内的第二个print，参数arg得到的是一个元组45 #最后的计算结果 从上面例子可以看出，如果输入的参数个数不确定，其它参数全部通过*arg，以元组的形式由arg收集起来。对照上面的例子不难发现： 值1传给了参数x 值2,3,4,5,6.7.8.9被塞入一个tuple里面，传给了arg 为了能够更明显地看出args（名称可以不一样，但是符号必须要有），可以用下面的一个简单函数来演示： 123&gt;&gt;&gt; def foo(*args):... print args #打印通过这个参数得到的对象... 下面演示分别传入不同的值，通过参数*args得到的结果： 1234567891011&gt;&gt;&gt; foo(1,2,3)(1, 2, 3)&gt;&gt;&gt; foo(\"qiwsir\",\"qiwsir.github.io\",\"python\")('qiwsir', 'qiwsir.github.io', 'python')&gt;&gt;&gt; foo(\"qiwsir\",307,[\"qiwsir\",2],&#123;\"name\":\"qiwsir\",\"lang\":\"python\"&#125;)('qiwsir', 307, ['qiwsir', 2], &#123;'lang': 'python', 'name': 'qiwsir'&#125;)&gt;&gt;&gt; foo(\"python\")('python',) 即使只有一个值，也是用tuple收集它。特别注意，在tuple中，如果只有一个元素，后面要有一个逗号。 还有一种可能，就是不给那个*args传值，也是许可的。例如： 1234567&gt;&gt;&gt; def foo(x, *args):... print \"x:\",x... print \"tuple:\",args... &gt;&gt;&gt; foo(7)x: 7tuple: () 除了用args这种形式的参数接收多个值之外，还可以用*kargs的形式接收数值，不过这次有点不一样： 12345&gt;&gt;&gt; def foo(**kargs):... print kargs...&gt;&gt;&gt; foo(a=1,b=2,c=3) #注意观察这次赋值的方式和打印的结果&#123;'a': 1, 'c': 3, 'b': 2&#125; 如果这次还用foo(1,2,3)的方式，会有什么结果呢？ 1234&gt;&gt;&gt; foo(1,2,3)Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;TypeError: foo() takes exactly 0 arguments (3 given) 如果用**kargs的形式收集值，会得到dict类型的数据，但是，需要在传值的时候说明“键”和“值”，因为在字典中是以键值对形式出现的。 另一种传值方式12345&gt;&gt;&gt; def add(x,y):... return x + y... &gt;&gt;&gt; add(2,3)5 这是通常的函数调用方法，在前面已经屡次用到。这种方法简单明快，很容易理解。但是，世界总是多样性的，有时候你秀出下面的方式，甚至在某种情况用下面的方法可能更优雅。 123&gt;&gt;&gt; bars = (2,3)&gt;&gt;&gt; add(*bars)5 先把要传的值放到元组中，赋值给一个变量bars，然后用add(*bars)的方式，把值传到函数内。这有点像前面收集参数的逆过程。注意的是，元组中元素的个数，要跟函数所要求的变量个数一致。如果这样就报错了： 12345&gt;&gt;&gt; bars = (2,3,4)&gt;&gt;&gt; add(*bars)Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;TypeError: add() takes exactly 2 arguments (3 given) 这是使用一个星号*，是以元组形式传值，如果用**的方式，是不是应该以字典的形式呢？理当如此。 123456&gt;&gt;&gt; def book(author,name):... print \"%s is writing %s\" % (author,name)... &gt;&gt;&gt; bars = &#123;\"name\":\"Starter learning Python\",\"author\":\"Kivi\"&#125;&gt;&gt;&gt; book(**bars)Kivi is writing Starter learning Python","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python函数2","slug":"Python函数2","date":"2016-12-15T09:19:25.000Z","updated":"2016-12-15T09:21:46.000Z","comments":true,"path":"2016/12/15/Python函数2/","link":"","permalink":"http://yoursite.com/2016/12/15/Python函数2/","excerpt":"","text":"###返回值 通过例子函数来说明，如下（输出斐波那契数列）： 123456789101112#!/usr/bin/env python# coding=utf-8def fibs(n): result = [0,1] for i in range(n-2): result.append(result[-2] + result[-1]) return resultif __name__ == \"__main__\": lst = fibs(10) print lst 观察fibs函数，最后有一个语句return result，意思是将变量result的值返回。返回给谁呢？这要看我们当前在什么位置调用该函数了。在上面的程序中，以lst = fibs(10)语句的方式，调用了函数，那么函数就将值返回到当前状态，并记录在内存中，然后把它赋值给变量lst。如果没有这个赋值语句，函数照样返回值，但是它飘忽在内存中，我们无法得到，并且最终还被当做垃圾被python回收了。 注意：上面的函数只返回了一个返回值（是一个列表），有时候需要返回多个，是以元组形式返回。 123456&gt;&gt;&gt; def my_fun():... return 1,2,3... &gt;&gt;&gt; a = my_fun()&gt;&gt;&gt; a(1, 2, 3) 如果没有使用return。事实上返回的是一个None，这种模样的函数，通常采用下面的方式，因为他们返回的是None，似乎这个返回值利用价值不高，于是就不用找一个变量来接受返回值了。 12345&gt;&gt;&gt; def my_fun():... print \"I am doing somthin.\"...&gt;&gt;&gt; my_fun()I am doing somthin. return还有一个作用，结束正在执行的函数，有点类似循环中的break的作用。如下： 1234567&gt;&gt;&gt; def my_fun():... print \"I am coding.\"... return... print \"I finished.\"... &gt;&gt;&gt; my_fun()I am coding. 函数中的文档一般在每个函数名字的下面，还要比较多的说明，这个被称为“文档”，在文档中主要是说明这个函数的用途。 12345678&gt;&gt;&gt; def my_fun():... \"\"\"... This is my function.... \"\"\"... print \"I am a craft.\"... &gt;&gt;&gt; my_fun.__doc__'\\n This is my function.\\n ' 在这个函数的名称下面，用三个引号的方式，包裹着对这个函数的说明，那个就是函数文档,doc它的内容就来自这里。 全局变量和局部变量123456789x = 2def funcx(): x = 9 print \"this x is in the funcx:--&gt;\",xfuncx()print \"--------------------------\"print \"this x is out of funcx:--&gt;\",x 那么，这段代码输出的结果是什么呢？看： 123this x is in the funcx:--&gt; 9--------------------------this x is out of funcx:--&gt; 2 从输出看出，运行funcx()，输出了funcx()里面的变量x=9；然后执行代码中的最后一行，print “this x is out of funcx:–&gt;”,x 特别要关注的是，前一个x输出的是函数内部的变量x;后一个x输出的是函数外面的变量x。两个变量彼此没有互相影响，虽然都是x。从这里看出，两个x各自在各自的领域内起到作用。 把那个只在函数体内（某个范围内）起作用的变量称之局部变量。 全局变量的例子如下： 123456789x = 2def funcx(): global x #跟上面函数的不同之处 x = 9 print \"this x is in the funcx:--&gt;\",xfuncx()print \"--------------------------\"print \"this x is out of funcx:--&gt;\",x 以上两段代码的不同之处在于，后者在函数内多了一个global x，这句话的意思是在声明x是全局变量，也就是说这个x跟函数外面的那个x同一个，接下来通过x=9将x的引用对象变成了9。所以，就出现了下面的结果。 123this x is in the funcx:--&gt; 9--------------------------this x is out of funcx:--&gt; 9","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python函数1","slug":"Python函数1","date":"2016-12-15T09:19:22.000Z","updated":"2016-12-15T09:20:06.000Z","comments":true,"path":"2016/12/15/Python函数1/","link":"","permalink":"http://yoursite.com/2016/12/15/Python函数1/","excerpt":"","text":"变量本质上是一个占位符 就是先把那个位置用变量占上，表示这里有一个东西，至于这个位置放什么东西，以后再说，反正先用一个符号占着这个位置（占位符）。 上一个简单的例子： 123456789#!/usr/bin/env python#coding:utf-8def add_function(a, b): #在声明要建立一个函数的时候，一定要使用def(define),（a,b)这个括号里面的是这个函数的参数，也就是函数变量。 c = a + b print cif __name__ == \"__main__\": add_function(2, 3) 当以交互的方式运行 Python 时，局部 __name__ 变量被赋予值 ‘__main__‘ 。同样地，当从命令行执行 Python 模块，而不是将其导入另一个模块时，其 __name__ 属性被赋予值 ‘__main\\‘ ，而不是该模块的实际名称。这样，模块可以查看其自身的 __name__ 值来自行确定它们自己正被如何使用，是作为另一个程序的支持，还是作为从命令行执行的主应用程序。 ###函数的赋值 1、按照参数次序赋值，根据参数的位置，值与之对应。 1234567891011121314&gt;&gt;&gt; def add(x,y): #为了能够更明了显示参数赋值特点，重写此函数... print \"x=\",x #分别打印参数赋值结果... print \"y=\",y... return x+y... &gt;&gt;&gt; add(10,3) #x=10,y=3x= 10y= 313&gt;&gt;&gt; add(3,10) #x=3,y=10x= 3y= 1013 2、还可以直接把赋值语句写到里面，就明确了参数和对象的关系。当然，这时候顺序就不重要了，也可以这样 1234&gt;&gt;&gt; add(y=10,x=3) #x=3,y=10x= 3y= 1013 3、在定义函数的时候，参数可以像前面那样，等待被赋值，也可以定义的时候就赋给一个默认值。例如： 123456789101112131415161718192021222324&gt;&gt;&gt; def times(x,y=2): #y的默认值为2... print \"x=\",x... print \"y=\",y... return x*y... &gt;&gt;&gt; times(3) #x=3,y=2x= 3y= 26&gt;&gt;&gt; times(x=3) #同上x= 3y= 26&gt;&gt;&gt; times(3,4) #x=3,y=4,y的值不再是2x= 3y= 412&gt;&gt;&gt; times(\"qiwsir\") #再次体现了多态特点x= qiwsiry= 2'qiwsirqiwsir'","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python字符串3","slug":"Python字符串3","date":"2016-12-15T09:16:09.000Z","updated":"2016-12-15T09:18:09.000Z","comments":true,"path":"2016/12/15/Python字符串3/","link":"","permalink":"http://yoursite.com/2016/12/15/Python字符串3/","excerpt":"","text":"字符串格式化输出占位符 1234&gt;&gt;&gt; \"I like %s\" % \"python\"'I like python'&gt;&gt;&gt; \"I like %s\" % \"Pascal\"'I like Pascal' 常用的有%s和%d，或者再加上%f 新的格式化方法(string.format()) 123&gt;&gt;&gt; s1 = \"I like &#123;0&#125; &#123;1&#125;\".format(\"python\",2016)&gt;&gt;&gt; print s1I like python 2016 这是 python 非常提倡的string.format()的格式化方法，其中{索引值}为占位符 也可以直接指定，如： 123&gt;&gt;&gt; s1 = \"I like &#123;name&#125; &#123;num&#125;,&#123;num&#125;\".format(name=\"python\",num=2016)&gt;&gt;&gt; print s1I like python 2016,2016 字典格式化，如： 123&gt;&gt;&gt; lang = \"python\"&gt;&gt;&gt; print \"I love %(program)s\"%&#123;\"program\":lang&#125;I love python 常用的字符串方法分割字符串 split 将字符串根据某个分隔符分割，获得一个列表 123&gt;&gt;&gt; str = \"I love python\"&gt;&gt;&gt; str.split(\" \")['I', 'love', 'python'] 拼接字符串 join 可以将列表中的字符串拼接成一个 123456&gt;&gt;&gt; list['I', 'love', 'python']&gt;&gt;&gt; \" \".join(list)'I love python'&gt;&gt;&gt; \",\".join(list)'I,love,python' 去掉字符串两头的空格 strip() 经常用在用户登录或者输入一些信息时，去除输入内容左右两边的空格 123456789&gt;&gt;&gt; str = \" hello \"&gt;&gt;&gt; str.strip()'hello'&gt;&gt;&gt; str' hello '&gt;&gt;&gt; str.lstrip() # 去除左边的空格'hello '&gt;&gt;&gt; str.rstrip() # 去除右边的空格' hello' 字符大小写的转换 在python中有下面一堆内建函数，用来实现各种类型的大小写转化 S.upper() # S中的字母大写 S.lower() # S中的字母小写 S.capitalize() # 首字母大写 S.title() # 将字符换首字母都变为大写 S.isupper() # S中的字母是否全是大写 S.islower() # S中的字母是否全是小写 S.istitle() # S中字符串中所有的单词拼写首字母是否为大写，且其他字母为小写","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python字符串2","slug":"Python字符串2","date":"2016-12-15T09:14:30.000Z","updated":"2016-12-15T09:14:59.000Z","comments":true,"path":"2016/12/15/Python字符串2/","link":"","permalink":"http://yoursite.com/2016/12/15/Python字符串2/","excerpt":"","text":"在python中，把字符串这样的对象类型统称为 序列。 索引和切片几个例子： 12345678910111213141516# 从左到右，从0开始，从右到左，从-1开始&gt;&gt;&gt; num = \"0123456789\"&gt;&gt;&gt; num[0]'0'&gt;&gt;&gt; num[0:8]'01234567'&gt;&gt;&gt; num[:8]'01234567'&gt;&gt;&gt; num[1:]'123456789'&gt;&gt;&gt; num[:]'0123456789'&gt;&gt;&gt; num[-1]'9'&gt;&gt;&gt; num[-2]'8' 字符串的基本操作+ 连接字符串 1234567&gt;&gt;&gt; str1 = \"hello\"&gt;&gt;&gt; str2 = \"sate\"&gt;&gt;&gt; str1 + str2'hellosate'&gt;&gt;&gt; str1 + \" \" + str2'hello sate'&gt;&gt;&gt; in 12345&gt;&gt;&gt; str1 = \"hello\"&gt;&gt;&gt; \"hel\" in str1True&gt;&gt;&gt; \"helo\" in str1False 最值 是根据字符在计算机中编码来计算的 12345&gt;&gt;&gt; str1 = \"hello\"&gt;&gt;&gt; max(str1)'o'&gt;&gt;&gt; min(str1)'e' 比较 两个字符串的比较是先将字符串中的符号转化为对应编码的数字，然后比较。如果返回负数，则第一个小于第二个如果返回整数，则第一个大于第二个如果返回零，则两个相等。 1234567&gt;&gt;&gt; hehe = \"hehe\"&gt;&gt;&gt; haha = \"haha\"&gt;&gt;&gt; cmp(hehe,haha)1&gt;&gt;&gt; cmp(haha,hehe)-1&gt;&gt;&gt; ord()是一个内建函数，可以返回某个字符的 ASCII 值，根据该值来比较。chr()正好反过来，根据整数值得到相应的字符。 1234&gt;&gt;&gt; ord(\"a\")97&gt;&gt;&gt; chr(97)'a' * 字符串中的“乘法” 12345&gt;&gt;&gt; a = \"hahe\"&gt;&gt;&gt; a*3'hahehahehahe'&gt;&gt;&gt; \"-\"*20'--------------------' len() 123&gt;&gt;&gt; a = \"hello\"&gt;&gt;&gt; len(a)5","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python字符串1","slug":"Python字符串1","date":"2016-12-15T09:12:26.000Z","updated":"2016-12-15T09:12:53.000Z","comments":true,"path":"2016/12/15/Python字符串1/","link":"","permalink":"http://yoursite.com/2016/12/15/Python字符串1/","excerpt":"","text":"拼接字符串： 12345678&gt;&gt;&gt; a = \"hello\"&gt;&gt;&gt; b = 2016&gt;&gt;&gt; print a + str(b) # str转换为字符串格式hello2016&gt;&gt;&gt; print a + repr(b) # 创建一个字符串，以合法的python表达式的形式来表示值hello2016&gt;&gt;&gt; print a + `b` # 作用和repr()一样，不太使用，python3.0不再使用hello2016 raw_input和input 123456789101112&gt;&gt;&gt; name = raw_input(\"input your name : \")input your name : sate'sate'# raw_input会将所有输入当作原始数据，然后放入字符串中，不管输入的是什么，name变量赋值的都是字符串&gt;&gt;&gt; name = input(\"input your name : \")input your name : \"sate\"'sate'# input 会假设用户输入的是合法的Python表达式，输入字符串时要加双引号，输入整数时不需要，name变量是个整形(int)# 大部分情况下会使用raw_input 长字符串、原始字符串、Unicode 如果需要写一个非常长的多行字符串，可以使用三个引号，可以在字符串中使用单引号和双引号而不用转义。 1234567891011&gt;&gt;&gt; print \"\"\"... hi,all:... my name is \"sate\"... nice to meet \\nyou!... \"\"\"hi,all: my name is \"sate\" nice to meetyou!# 注： python的转义字符依然有效 原始字符串：就是指字符串里面的每个字符都是原始含义，比如反斜杠，不会被看做转义符。 原始字符串应用场景：有时我们需要输出目录。例如 C:\\new\\team 123&gt;&gt;&gt; print \"C:\\new\\team\"C:ew eam 我们可以使用\\来进行转义，但对于长路径可能需要很多反斜线，麻烦，我们可以使用原始字符串来解决 12&gt;&gt;&gt; print r\"C:\\new\\team\"C:\\new\\team 这种方法在做网站设置网站目录结构的时候非常有用。 注：原始字符串最后一个字符不能是反斜线，如果是Python就不能清楚是否应该结束字符串 1234567891011&gt;&gt;&gt; print r\"C:\\new\\team\\\" File \"&lt;stdin&gt;\", line 1 print r\"C:\\new\\team\\\" ^SyntaxError: EOL while scanning string literal&gt;&gt;&gt; print r\"C:\\new\\team\\\\\" # 如果使用反斜线进行转义，用于转义的反斜线也会被输出C:\\new\\team\\\\&gt;&gt;&gt; print r\"C:\\new\\team\" \"\\\\\" # 可以使用该方法进行输出C:\\new\\team\\","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python四则运算","slug":"Python四则运算","date":"2016-12-15T09:10:02.000Z","updated":"2016-12-15T09:10:32.000Z","comments":true,"path":"2016/12/15/Python四则运算/","link":"","permalink":"http://yoursite.com/2016/12/15/Python四则运算/","excerpt":"","text":"加、减、乘、除 12345678910&gt;&gt;&gt; 1+23&gt;&gt;&gt; 2-11&gt;&gt;&gt; 1*22&gt;&gt;&gt; 1/20&gt;&gt;&gt; 1/2.00.5 有问题的地方： 12345678&gt;&gt;&gt; 10.0/33.3333333333333335&gt;&gt;&gt; 0.1 + 0.20.30000000000000004&gt;&gt;&gt; 0.1 + 0.2 - 0.20.10000000000000003&gt;&gt;&gt; 0.1 + 0.2 - 0.35.551115123125783e-17 我们输入的是十进制，计算机要把十进制的数转化为二进制，然后再计算。但是,在转化中，浮点数转化为二进制，转化为二进制后，不会精确等于十进制的0.1。同时，计算机存储的位数是有限制的，所以，就出现上述现象了。对于需要非常精确的情况，可以使用 decimal 模块，它实现的十进制运算适合会计方面的应用和高精度要求的应用。 余数 1234&gt;&gt;&gt; 5%21&gt;&gt;&gt; 5%2.01.0 可以使用内建函数divmod()来返回商和余数 123456&gt;&gt;&gt; divmod(5,2) #表示5除以2，返回商和余数(2, 1)&gt;&gt;&gt; divmod(5,3)(1, 2)&gt;&gt;&gt; divmod(5,2.0)(2.0, 1.0) 四舍五入使用内建函数round()来实现 1234&gt;&gt;&gt; round(1.2345,2)1.23&gt;&gt;&gt; round(1.2345,3) #有问题，应该是1.235，归根到底还是浮点数中的十进制转化为二进制惹的祸。1.234 math模块 导入模块 123456&gt;&gt;&gt; import math&gt;&gt;&gt; math.pi3.141592653589793&gt;&gt;&gt; dir(math) # 查看模块中包含的工具['__doc__', '__name__', '__package__', 'acos', 'acosh', 'asin', 'asinh', 'atan', 'atan2', 'atanh', 'ceil', 'copysign', 'cos', 'cosh', 'degrees', 'e', 'erf', 'erfc', 'exp', 'expm1', 'fabs', 'factorial', 'floor', 'fmod', 'frexp', 'fsum', 'gamma', 'hypot', 'isinf', 'isnan', 'ldexp', 'lgamma', 'log', 'log10', 'log1p', 'modf', 'pi', 'pow', 'radians', 'sin', 'sinh', 'sqrt', 'tan', 'tanh', 'trunc']&gt;&gt;&gt; help(math.pow) #查看每个函数的使用说明 常用的几个math函数： 1234567891011121314&gt;&gt;&gt; math.sqrt(9)3.0&gt;&gt;&gt; math.floor(3.14)3.0&gt;&gt;&gt; math.floor(3.92)3.0&gt;&gt;&gt; math.fabs(-2) #等价于abs(-2)2.0&gt;&gt;&gt; abs(-2)2&gt;&gt;&gt; math.fmod(5,3) #等价于5%32.0&gt;&gt;&gt; 5%32","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python列表2","slug":"Python列表2","date":"2016-12-15T09:03:46.000Z","updated":"2016-12-15T09:04:36.000Z","comments":true,"path":"2016/12/15/Python列表2/","link":"","permalink":"http://yoursite.com/2016/12/15/Python列表2/","excerpt":"","text":"###列表的方法 12&gt;&gt;&gt; dir(list)['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__delslice__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getslice__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__setslice__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort'] 除去带有双下划线的，主要有以下几个方法： 1'append', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort' 可以通过 help 来查看各个方法的使用方法。 12345&gt;&gt;&gt; help(list.append)Help on method_descriptor:append(...) L.append(object) -- append object to end 下边对各个方法进行举例说明: append在队列末尾追加新的对象： 1234&gt;&gt;&gt; lst = [1,2,3]&gt;&gt;&gt; lst.append(4)&gt;&gt;&gt; lst[1, 2, 3, 4] count统计某个元素在列表中出现的次数 123&gt;&gt;&gt; lst = [1,2,3,4,5,6,7,8,2,3,4,5,6]&gt;&gt;&gt; lst.count(4)2 extend在列表的末尾一次性追加另一个序列。 12345&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; b = [4,5,6]&gt;&gt;&gt; a.extend(b)&gt;&gt;&gt; a[1, 2, 3, 4, 5, 6] 和连接操作+不同的是，extend会直接在原队列上修改，+连接操作会生成新的列表 index从列表中找出某个值第一个匹配项的索引位置 123&gt;&gt;&gt; lst = [3,3,3,4,5,6,4]&gt;&gt;&gt; lst.index(4)3 insert将对象插入到列表中 1234&gt;&gt;&gt; lst = [3,3,3,4,5,6,4]&gt;&gt;&gt; lst.insert(3,\"hi\")&gt;&gt;&gt; lst[3, 3, 3, 'hi', 4, 5, 6, 4] pop移除列表中的一个元素（默认是最后一个），并返回该元素的值 12345678910&gt;&gt;&gt; lst[3, 3, 3, 4, 5, 6, 4]&gt;&gt;&gt; lst.pop()4&gt;&gt;&gt; lst[3, 3, 3, 4, 5, 6]&gt;&gt;&gt; lst.pop(4)5&gt;&gt;&gt; lst[3, 3, 3, 4, 6] remove移除列表中某个值得第一个匹配项 1234&gt;&gt;&gt; lst = [\"a\",\"a\",\"b\",\"b\"]&gt;&gt;&gt; lst.remove(\"a\")&gt;&gt;&gt; lst['a', 'b', 'b'] reverse将列表中的元素反向存放 12345&gt;&gt;&gt; lst['a', 'b', 'b']&gt;&gt;&gt; lst.reverse()&gt;&gt;&gt; lst['b', 'b', 'a'] 可以使用lst[::-1]来实现反转 sort在原位置对列表进行排序，意味着直接改变原来的列表。 12345&gt;&gt;&gt; lst['b', 'b', 'a']&gt;&gt;&gt; lst.sort()&gt;&gt;&gt; lst['a', 'b', 'b'] 如果我们需要一个排序一个列表，但是保留原有列表时，就要注意了，下边这种方式是有问题的 1234&gt;&gt;&gt; x = [1,2,3,4]&gt;&gt;&gt; y = x.sort()&gt;&gt;&gt; print yNone 正确的方法是： 1234567&gt;&gt;&gt; x = [4,3,2,1]&gt;&gt;&gt; y = x[:]&gt;&gt;&gt; y.sort()&gt;&gt;&gt; x[4, 3, 2, 1]&gt;&gt;&gt; y[1, 2, 3, 4] 还可以使用sorted()来实现,不会改变原有列表 123456&gt;&gt;&gt; x = [4,3,2,1]&gt;&gt;&gt; y = sorted(x)&gt;&gt;&gt; x[4, 3, 2, 1]&gt;&gt;&gt; y[1, 2, 3, 4]","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python列表1","slug":"Python列表1","date":"2016-12-15T09:01:34.000Z","updated":"2016-12-15T09:03:40.000Z","comments":true,"path":"2016/12/15/Python列表1/","link":"","permalink":"http://yoursite.com/2016/12/15/Python列表1/","excerpt":"","text":"用[]来表示一个列表，列表中的元素可以是任意类型，如 int,str, 可以是另一个 list，也可以是一个字典。所以说 list 是 python 的苦力，什么活都可干。 123&gt;&gt;&gt; list = [\"string\",86,[1,2,3],&#123;\"a\":3,\"b\":4,\"c\":\"hi\"&#125;]&gt;&gt;&gt; type(list)&lt;type 'list'&gt; 索引和切片和之前字符串使用的方法一致，不过因为列表中可能什么都有，所以可以对元素进行二次切片 123456&gt;&gt;&gt; list[0] 'string'&gt;&gt;&gt; list[0][2:5] #对列表中第一个字符换进行了二次切分'rin'&gt;&gt;&gt; list[3][\"a\"] #对列表中第4个字典换进行了二次切分3 反转这个功能会经常用到,字符串也可以使用，并不会更改原值，会创建新值，原变量不变 123456789# 列表的反转&gt;&gt;&gt; list = [1,2,3,4,5]&gt;&gt;&gt; list[::-1][5, 4, 3, 2, 1]# 字符串的反转&gt;&gt;&gt; a = \"hello\"&gt;&gt;&gt; a[::-1]'olleh' 另一种方法,使用reversed函数 12345&gt;&gt;&gt; list(reversed(\"abcd\"))['d', 'c', 'b', 'a']&gt;&gt;&gt; ha = [1,2,3,4.5]&gt;&gt;&gt; list(reversed(ha))[4.5, 3, 2, 1] list 的基本操作和字符串的差不多 len() 判断长度 1234&gt;&gt;&gt; lst['python', 'java', 'c++']&gt;&gt;&gt; len(lst)3 +，连接两个序列 123456&gt;&gt;&gt; lst['python', 'java', 'c++']&gt;&gt;&gt; alst[1, 2, 3, 4, 5, 6]&gt;&gt;&gt; lst + alst['python', 'java', 'c++', 1, 2, 3, 4, 5, 6] *，重复元素 1234&gt;&gt;&gt; lst['python', 'java', 'c++']&gt;&gt;&gt; lst * 3['python', 'java', 'c++', 'python', 'java', 'c++', 'python', 'java', 'c++'] in, 成员资格判断 1234&gt;&gt;&gt; \"python\" in lstTrue&gt;&gt;&gt; \"c#\" in lstFalse max()和min()，取最大最小值 以int类型元素为例。如果不是，都是按照字符在ascii编码中所对应的数字进行比较的。 12345678910&gt;&gt;&gt; alst[1, 2, 3, 4, 5, 6]&gt;&gt;&gt; max(alst)6&gt;&gt;&gt; min(alst)1&gt;&gt;&gt; max(lst)'python'&gt;&gt;&gt; min(lst)'c++' cmp()，比较 12345678910&gt;&gt;&gt; lsta = [2,3]&gt;&gt;&gt; lstb = [2,4]&gt;&gt;&gt; cmp(lsta,lstb)-1&gt;&gt;&gt; lstc = [2]&gt;&gt;&gt; cmp(lsta,lstc)1&gt;&gt;&gt; lstd = ['2','3']&gt;&gt;&gt; cmp(lsta,lstd)-1 append(), 追加元素 123456789&gt;&gt;&gt; a = [\"good\",\"python\",\"I\"] &gt;&gt;&gt; a['good', 'python', 'I']&gt;&gt;&gt; a.append(\"like\") #向list中添加str类型\"like\"&gt;&gt;&gt; a['good', 'python', 'I', 'like']&gt;&gt;&gt; a.append(100) #向list中添加int类型100&gt;&gt;&gt; a['good', 'python', 'I', 'like', 100] 另一种方法： list.append(x)等效于：a[len(a):]=[x] 12345678910&gt;&gt;&gt; a['good', 'python', 'I', 'like', 100]&gt;&gt;&gt; a[len(a):]=[3] #len(a),即得到list的长度，这个长度是指list中的元素个数。&gt;&gt;&gt; a['good', 'python', 'I', 'like', 100, 3]&gt;&gt;&gt; len(a)6&gt;&gt;&gt; a[6:]=['xxoo']&gt;&gt;&gt; a['good', 'python', 'I', 'like', 100, 3, 'xxoo']","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Python序列","slug":"Python序列","date":"2016-12-15T08:48:36.000Z","updated":"2016-12-15T09:08:21.000Z","comments":true,"path":"2016/12/15/Python序列/","link":"","permalink":"http://yoursite.com/2016/12/15/Python序列/","excerpt":"","text":"数据结构：通过某种方式组织在一起的数据元素的集合，这些数据元素可以是数字或者字符，甚至是其他的数据结构。Python中最基本的数据结构是序列。 序列概述Python包含六种内建序列：列表、元祖、字符串、Unicode字符串、buffer对象和xrange对象。列表和元祖的主要区别是列表可以修改，而元祖不能。 通用序列操作所有序列类型都可以进行某些特定的操作。如：索引，分片，加，乘，检查某个元素是否属于序列成员。python还有计算序列长度、找出最大元素和最小元素的内建函数。 索引序列中所有元素都是有编号的，从0开始递增，并可以通过编号访问。 123456例&gt;&gt;&gt; test='hello'&gt;&gt;&gt; test[0]'h'&gt;&gt;&gt; test[2]'l' 亦可以使用负编号，python从右边（最后一个元素）开始计数，从-1开始。 123456例&gt;&gt;&gt; test='hello'&gt;&gt;&gt; test[-1]'o'&gt;&gt;&gt; test[-2]'l' 字符串字面值能够直接使用索引，而不需要一个变量。 12&gt;&gt;&gt; 'hello'[1]'e' 如果一个函数调用 返回一个序列，可以直接对返回结果进行索引操作。 12345例：只对用户输入年份的第4个数字感兴趣&gt;&gt;&gt; want=raw_input('Year: ')[3]Year: 2015&gt;&gt;&gt; want'5' 分片分片操作可以访问一定范围内的元素。用过冒号分隔两个索引来实现。 12345&gt;&gt;&gt; tag = '&lt;a href=\"http://www.python.org\"&gt;Python web site&lt;/a&gt;'&gt;&gt;&gt; tag[9:30]'http://www.python.org'&gt;&gt;&gt; tag[32:-4]'Python web site' 分片操作需要提供两个索引的边界，第一个索引的元素是包含在分片内的，而第二个是不在分片内的。如下： 123&gt;&gt;&gt; num=[0,1,2,3,4,5,6,7,8,9]&gt;&gt;&gt; num[0:5][0, 1, 2, 3, 4] 捷径：如果分片部分包含序列结尾（或开始）的元素，只需置空最后（最前）一个索引即可。两个都置空则是整个序列。 123456789&gt;&gt;&gt; num = [0,1,2,3,4,5,6,7,8,9]&gt;&gt;&gt; num[:3][0, 1, 2]&gt;&gt;&gt; num[3:][3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; num[-3:][7, 8, 9]&gt;&gt;&gt; num[:][0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 步长：默认步长为1。分片操作就是按照这个步长来遍历序列的元素。 123456789&gt;&gt;&gt; num = [0,1,2,3,4,5,6,7,8,9]默认步长为1&gt;&gt;&gt; num[0:10:1][0, 1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; num[0:10:2][0, 2, 4, 6, 8]步长也可以为负数，既从右往左取值。并且必须让开始点大于结束点。&gt;&gt;&gt; num[::-2][9, 7, 5, 3, 1] 序列相加加运算符+可以连接序列。但两种相同类型的序列才能进行连接操作。 1234567&gt;&gt;&gt; num1 = [1,2,3]&gt;&gt;&gt; num2 = [4,5,6]&gt;&gt;&gt; num1 + num2[1, 2, 3, 4, 5, 6]&gt;&gt;&gt; num3 = ['a','b','c']&gt;&gt;&gt; num1 + num2 + num3[1, 2, 3, 4, 5, 6, 'a', 'b', 'c'] 乘法数字N乘以一个序列会变成一个新的序列，将原序列重复N倍 12345&gt;&gt;&gt; num = [1,2,3]&gt;&gt;&gt; num * 3[1, 2, 3, 1, 2, 3, 1, 2, 3]&gt;&gt;&gt; 'hello ' * 5'hello hello hello hello hello ' 空列表：空列表可以使用[]来表示。None：None是Python的一个内建值，代表空值。 1234例如：初始化一个长度为10的列表。&gt;&gt;&gt; nu = [None] * 10&gt;&gt;&gt; nu[None, None, None, None, None, None, None, None, None, None] 成员资格 inin运算符：检测一个值是否在序列中。条件为真返回True，假则False。 是个布尔运算符。 12345&gt;&gt;&gt; name = 'tom'&gt;&gt;&gt; 't' in nameTrue&gt;&gt;&gt; 'n' in nameFalse 1234567&gt;&gt;&gt; users = ['tom','jin','jon']&gt;&gt;&gt; raw_input('Enter your name: ') in users;Enter your name: zwxFalse&gt;&gt;&gt; raw_input('Enter your name: ') in users;Enter your name: tomTrue 最大值、最小值和长度对应内建函数max，min和len。 1234567&gt;&gt;&gt; num = [23,34,12,56]&gt;&gt;&gt; len(num)4&gt;&gt;&gt; max(num)56&gt;&gt;&gt; min(num)12","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"}]},{"title":"Zabbix监控Mysql","slug":"Zabbix监控Mysql","date":"2016-12-15T08:19:21.000Z","updated":"2016-12-15T08:19:50.000Z","comments":true,"path":"2016/12/15/Zabbix监控Mysql/","link":"","permalink":"http://yoursite.com/2016/12/15/Zabbix监控Mysql/","excerpt":"","text":"在zabbix中有官方提供的关于mysql的监控模版，但是该模板需要在zabbix的客户端添加自定义的key来取值。 1. check_mysql.sh编写脚本来获取mysql的各个状态值，放置在/alidata/zabbix-agentd/scripts/chk_mysql.sh。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#!/bin/bash# -------------------------------------------------------------------------------# FileName: check_mysql.sh# Revision: 1.0# Date: 2015/06/09# Author: DengYun# Email: dengyun@ttlsa.com# Website: www.ttlsa.com# Description: # Notes: ~# -------------------------------------------------------------------------------# Copyright: 2015 (c) DengYun# License: GPL # 用户名MYSQL_USER='zabbix' # 密码MYSQL_PWD='123123' # 主机地址/IPMYSQL_HOST='127.0.0.1' # 端口MYSQL_PORT='3306' # 数据连接MYSQL_CONN=\"/alidata/server/mysql/bin/mysqladmin -u$&#123;MYSQL_USER&#125; -p$&#123;MYSQL_PWD&#125; -h$&#123;MYSQL_HOST&#125; -P$&#123;MYSQL_PORT&#125;\" # 参数是否正确if [ $# -ne \"1\" ];then echo \"arg error!\" fi # 获取数据case $1 in Uptime) result=`$&#123;MYSQL_CONN&#125; status|cut -f2 -d\":\"|cut -f1 -d\"T\"` echo $result ;; Com_update) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Com_update\"|cut -d\"|\" -f3` echo $result ;; Slow_queries) result=`$&#123;MYSQL_CONN&#125; status |cut -f5 -d\":\"|cut -f1 -d\"O\"` echo $result ;; Com_select) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Com_select\"|cut -d\"|\" -f3` echo $result ;; Com_rollback) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Com_rollback\"|cut -d\"|\" -f3` echo $result ;; Questions) result=`$&#123;MYSQL_CONN&#125; status|cut -f4 -d\":\"|cut -f1 -d\"S\"` echo $result ;; Com_insert) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Com_insert\"|cut -d\"|\" -f3` echo $result ;; Com_delete) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Com_delete\"|cut -d\"|\" -f3` echo $result ;; Com_commit) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Com_commit\"|cut -d\"|\" -f3` echo $result ;; Bytes_sent) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Bytes_sent\" |cut -d\"|\" -f3` echo $result ;; Bytes_received) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Bytes_received\" |cut -d\"|\" -f3` echo $result ;; Com_begin) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Com_begin\"|cut -d\"|\" -f3` echo $result ;; *) echo \"Usage:$0(Uptime|Com_update|Slow_queries|Com_select|Com_rollback|Questions|Com_insert|Com_delete|Com_commit|Bytes_sent|Bytes_received|Com_begin)\" ;; esac 2. 修改配置文件zabbix_agentd.conf增加自定义的key，在配置文件的最后一行写入,如下代码行并重启zabbix客户端。 123456# 获取mysql版本UserParameter=mysql.version,mysql -V# # 获取mysql性能指标,这个是上面定义好的脚本UserParameter=mysql.status[*],bash /alidata/zabbix-agentd/scripts/chk_mysql.sh $1# # 获取mysql运行状态UserParameter=mysql.ping,mysqladmin -uzabbix -p123123 -P3306 -h127.0.0.1 ping | grep -c alive ###3. 在监控项目中加入Template App MySQL模版 ###在项目中加入模版后，查看Monitoring-&gt;Graphs中是否有数据图形产生。","categories":[{"name":"Zabbix","slug":"Zabbix","permalink":"http://yoursite.com/categories/Zabbix/"}],"tags":[{"name":"Zabbix","slug":"Zabbix","permalink":"http://yoursite.com/tags/Zabbix/"}]},{"title":"SVN的搭建和使用","slug":"SVN的搭建和使用","date":"2016-12-15T08:16:33.000Z","updated":"2016-12-15T08:18:07.000Z","comments":true,"path":"2016/12/15/SVN的搭建和使用/","link":"","permalink":"http://yoursite.com/2016/12/15/SVN的搭建和使用/","excerpt":"","text":"安装1[root@node1 ~]# yum install subversion 配置1. 新建目录，并做成资源仓库 123456789$ mkdir mkdir /svn$ svnadmin create /svn/$ ls /svn/conf db format hooks locks README.txt# 目录说明：hooks目录：放置hook脚本文件的目录locks目录：用来放置subversion的db锁文件和db_logs锁文件的目录，用来追踪存取文件库的客户端format文件：是一个文本文件，里面只放了一个整数，表示当前文件库配置的版本号conf目录：是这个仓库的配置文件（仓库的用户访问账号、权限等） 2. 配置svn服务的配置文件svnserver.conf文件 1234567$ vim /svn/conf/svnserve.conf[general]anon-access = noneauth-access = writepassword-db = /svn/conf/passwdauthz-db = /svn/conf/authzrealm = My Test Repository 3. 添加两个访问用户及口令 1234$ vim /svn/conf/passwd[users]zwx = 123123test1 = 123123 注： 对用户配置文件的修改立即生效，不必重启svn服务。 4. 配置新用户的授权文件 12345678$ vim /svn/conf/authz[groups]admin = zwxuser = test1[/]@admin = rw@user = r* = 格式说明 : 1234567891011121314151617181920[&lt;版本库&gt;:/项目/目录]@&lt;用户组名&gt; = &lt;权限&gt;&lt;用户名&gt; = &lt;权限&gt;/ 表示对根目录（即/svn目录）下的所有子目录范围设置权限；[/abc] 表示对资料库中abc项目设置权限；创建一个admin组，组成员包括zwx;创建一个user组，成员只有test1;admin组对目录有读写权限；单个用户test1有读写权限；*=表示除了上面设置的权限用户组以外，其他所有用户都设置空权限，空权限表示禁止访问本目录，这很重要一定要加上。注意：对权限配置文件的修改立即生效，不必重启svn。 5. 启动SVN svn 启动可以使用两种方法： 一： 指定项目启动 1234$ svnserve -d -r /svn/# 指定项目启动时，在客户端checkout的时候，使用命令如下：$ svn cheackout svn://192.168.174.128# 会同步svn目录，并且命名为192.168.174.128 二： /etc/init.d/svnserve 启动 1234$ /etc/init.d/svnserve start# 使用启动命令启动$ svn cheackout svn://192.168.174.128/svn# 会同步svn目录，并且命名为svn 基本使用1、将文件checkout到本地目录 123svn checkout path（path是服务器上的目录）例如：svn checkout svn://192.168.1.1/pro/domain简写：svn co 2、往版本库中添加新的文件 123svn add file例如：svn add test.php(添加test.php)svn add *.php(添加当前目录下所有的php文件) 3、将改动的文件提交到版本库 123svn commit -m \"LogMessage\" [-N] [--no-unlock] PATH(如果选择了保持锁，就使用--no-unlock开关)例如：svn commit -m \"add test file for my test\" test.php简写：svn ci 4、加锁/解锁 123svn lock -m \"LockMessage\" [--force] PATH例如：svn lock -m \"lock test file\" test.phpsvn unlock PATH 5、更新到某个版本 123456svn update -r m path例如：svn update如果后面没有目录，默认将当前目录以及子目录下的所有文件都更新到最新版本。svn update -r 200 test.php(将版本库中的文件test.php还原到版本200)svn update test.php(更新，于版本库同步。如果在提交的时候提示过期的话，是因为冲突，需要先update，修改文件，然后清除svn resolved，最后再提交commit)简写：svn up 6、查看文件或者目录状态 1234561）svn status path（目录下的文件和子目录的状态，正常状态不显示）【?：不在svn的控制中；M：内容被修改；C：发生冲突；A：预定加入到版本库；K：被锁定】2）svn status -v path(显示文件和子目录状态)第一列保持相同，第二列显示工作版本号，第三和第四列显示最后一次修改的版本号和修改人。注：svn status、svn diff和 svn revert这三条命令在没有网络的情况下也可以执行的，原因是svn在本地的.svn中保留了本地版本的原始拷贝。简写：svn st 7、删除文件 1234svn delete path -m \"delete test fle\"例如：svn delete svn://192.168.1.1/pro/domain/test.php -m \"delete test file\"或者直接svn delete test.php 然后再svn ci -m 'delete test file‘，推荐使用这种简写：svn (del, remove, rm) 8、查看日志 12svn log path例如：svn log test.php 显示这个文件的所有修改记录，及其版本号的变化 9、查看文件详细信息 12svn info path例如：svn info test.php 10、比较差异 12345svn diff path(将修改的文件与基础版本比较)例如：svn diff test.phpsvn diff -r m:n path(对版本m和版本n比较差异)例如：svn diff -r 200:201 test.php简写：svn di 11、将两个版本之间的差异合并到当前文件 12svn merge -r m:n path例如：svn merge -r 200:205 test.php（将版本200与205之间的差异合并到当前文件，但是一般都会产生冲突，需要处理一下） 12、SVN 帮助 12svn helpsvn help ci 13、版本库下的文件和目录列表 123svn list path显示path目录下的所有属于版本库的文件和目录简写：svn ls 14、创建纳入版本控制下的新目录 12345678svn mkdir: 创建纳入版本控制下的新目录。用法: 1、mkdir PATH...2、mkdir URL...创建版本控制的目录。1、每一个以工作副本 PATH 指定的目录，都会创建在本地端，并且加入新增调度，以待下一次的提交。2、每个以URL指定的目录，都会透过立即提交于仓库中创建。在这两个情况下，所有的中间目录都必须事先存在。 15、恢复本地修改 1234svn revert: 恢复原始未改变的工作副本文件 (恢复大部份的本地修改)。revert:用法: revert PATH...注意: 本子命令不会存取网络，并且会解除冲突的状况。但是它不会恢复被删除的目录 16、代码库URL变更 123456789svn switch (sw): 更新工作副本至不同的URL。用法: 1、switch URL [PATH]2、switch --relocate FROM TO [PATH...]1、更新你的工作副本，映射到一个新的URL，其行为跟“svn update”很像，也会将服务器上文件与本地文件合并。这是将工作副本对应到同一仓库中某个分支或者标记的方法。2、改写工作副本的URL元数据，以反映单纯的URL上的改变。当仓库的根URL变动 (比如方案名或是主机名称变动)，但是工作副本仍旧对映到同一仓库的同一目录时使用这个命令更新工作副本与仓库的对应关系。 17、解决冲突 1234svn resolved: 移除工作副本的目录或文件的“冲突”状态。用法: resolved PATH...注意: 本子命令不会依语法来解决冲突或是移除冲突标记；它只是移除冲突的相关文件，然后让 PATH 可以再次提交。 18、输出指定文件或URL的内容。 12svn cat 目标[@版本]...如果指定了版本，将从指定的版本开始查找。svn cat -r PREV filename &gt; filename (PREV 是上一版本,也可以写具体版本号,这样输出结果是可以提交的）","categories":[{"name":"SVN","slug":"SVN","permalink":"http://yoursite.com/categories/SVN/"}],"tags":[{"name":"SVN","slug":"SVN","permalink":"http://yoursite.com/tags/SVN/"}]},{"title":"Nginx中root和alias的区别","slug":"Nginx中root和alias的区别","date":"2016-12-15T08:14:56.000Z","updated":"2016-12-15T08:21:54.000Z","comments":true,"path":"2016/12/15/Nginx中root和alias的区别/","link":"","permalink":"http://yoursite.com/2016/12/15/Nginx中root和alias的区别/","excerpt":"","text":"nginx指定文件路径有两种方式 root 和 alias。 root 与 alias 主要区别在于 nginx 如何解释 location 后面的 uri，这会使两者分别以不同的方式将请求映射到服务器文件上。 12345678[root]语法： root path默认值： root html配置段： http、 server、 location、 if[alias]语法： alias path配置段： location 示例：nginx的location配置如下： 123456location /xing/ &#123; root /alidata/www/phpwind/;&#125;#当访问http://192.168.3.14/xing/zheng/index.html时，调用的文件是/alidata/www/phpwind/xing/zheng/index.html。 #既 root路径 + url请求地址。 1234567891011location /xing/ &#123; alias /alidata/www/phpwind/;&#125;#当访问http://192.168.3.14/xing/zheng/index.html时，调用的文件是/alidata/www/phpwind/zheng/index.html。#既 省略location后边匹配的路径。注：1. 使用 alias 时，目录名后面一定要加” /”2. alias 可以指定任何名称3. alias 在使用正则匹配时，必须捕捉要匹配的内容并在指定的内容处使用。4. alias 只能位于 location 块中。","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"Nginx隐藏版本号","slug":"Nginx隐藏版本号","date":"2016-12-15T08:11:59.000Z","updated":"2016-12-15T08:12:27.000Z","comments":true,"path":"2016/12/15/Nginx隐藏版本号/","link":"","permalink":"http://yoursite.com/2016/12/15/Nginx隐藏版本号/","excerpt":"","text":"修改nginx.conf文件 12345678vim /../../nginx.conf # 在http&#123;&#125;加入 server_tokens off;http &#123;……省略keepalive_timeout 60;server_tokens off;…….省略&#125; 修改fastcgi.conf 123fastcgi_param SERVER_SOFTWARE nginx/$nginx_version;改为：fastcgi_param SERVER_SOFTWARE nginx; 重启nginx服务","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"Nginx的日志切割","slug":"Nginx的日志切割","date":"2016-12-15T08:11:15.000Z","updated":"2016-12-15T08:11:37.000Z","comments":true,"path":"2016/12/15/Nginx的日志切割/","link":"","permalink":"http://yoursite.com/2016/12/15/Nginx的日志切割/","excerpt":"","text":"nginx的切割日志的方法记录一下两种方式：logrotate和脚本。 logrotate切割日志 安装logrotate 1yum -y install logrotate 配置文件 123456789101112131415vim /etc/logrotate.d/nginx-log 写入：/var/log/nginx/*.log &#123; #根据实际路径修改nocompressdailycopytruncatecreatenotifemptyrotate 7olddir /data/weblogs/old_logmissingokdateextpostrotate/bin/kill -HUP `cat /var/run/nginx.pid 2&gt; /dev/null` 2&gt; /dev/null || trueendscript&#125; 注：/data/weblogs/*.log 使用通配符时， /data/weblogs/目录下的所有匹配到的日志文件都将切割。如果要切割特定日志文件，就指定到该文件 设置计划任务 12# vim /etc/crontab59 23 * * * root ( /usr/sbin/logrotate -f /etc/logrotate.d/nginx-log) 脚本切割 使用shell脚本来分割访问日志和错误日志。 1234567891011vim /opt/logcut.sh 写入：#!/bin/bashlogs_path=\"/var/log/nginx/\"date=`date +%Y%m%d`log_name1=\"access.log\" log_name2=\"error.log\"pid_path=\"/var/run/nginx.pid\"mv $&#123;logs_path&#125;$&#123;log_name1&#125; $&#123;logs_path&#125;$&#123;log_name1&#125;_$date.logmv $&#123;logs_path&#125;$&#123;log_name2&#125; $&#123;logs_path&#125;$&#123;log_name2&#125;_$date.logkill -USR1 `cat $&#123;pid_path&#125;` 设置计划任务 12# vim /etc/crontab59 23 * * * root /bin/bash /opt/logcut.sh","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"Nginx的realip配置","slug":"Nginx的realip配置","date":"2016-12-15T08:04:48.000Z","updated":"2016-12-15T08:05:38.000Z","comments":true,"path":"2016/12/15/Nginx的realip配置/","link":"","permalink":"http://yoursite.com/2016/12/15/Nginx的realip配置/","excerpt":"","text":"当前端有nginx进行反向代理时，后端的机器获得的访问日志中记录的IP是前端nginx的，用一下方法来记录真实IP。 实验环境12node1：192.168.174.129 前端代理（nginx-proxy） centos 6.5node2：192.168.174.128 后端服务（nginx） centos 6.5 实验过程 nginx安装realip_module模块（两个nginx都要安装） 12345678910111213141516#检查nginx是否安装了realip_modulenginx -V[root@node1 ~]# nginx -Vnginx version: nginx/1.4.4built by gcc 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC) TLS SNI support enabledconfigure arguments: --user=www --group=www --prefix=/alidata/server/nginx --with-http_stub_status_module --without-http-cache --with-http_ssl_module --with-http_gzip_static_module #增加realip_module，找到nginx的源码，重新编译，在编译参数中加入--with-http_realip_module[root@node1 nginx-1.4.4]# ./configure --user=www --group=www --prefix=/alidata/server/nginx --with-http_stub_status_module --without-http-cache --with-http_ssl_module --with-http_gzip_static_module --with-http_realip_module#之后，只需make即可，不要make install[root@node1 nginx-1.4.4]# make#将新的nginx替换老的nginx sbin文件（可能需要停止nginx服务）。重启nginx服务[root@node1 nginx-1.4.4]# cp objs/nginx /alidata/server/nginx/sbin/ 在nginx代理机器修改配置文件 （192.168.174.129） 12345678910111213#在server段的配置中：server &#123; listen 80; server_name _; location ^~ /xing/ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://192.168.174.128/; &#125; access_log /alidata/log/nginx/access/test.log;&#125; 修改后端nginx的日志格式。（192.168.174.128） 1234567#在nginx.conf中：log_format test '$http_x_real_ip - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"';#在server段配置log access_log /alidata/log/nginx/access/zabbix.log test; 测试访问http://192.168.174.129/xing/ ，观察node2机器的日志。 1192.168.174.1 - - [24/Sep/2015:22:52:38 +0800] \"GET /images/general/zabbix.ico HTTP/1.0\" 200 1150 \"http://192.168.174.129/xing/\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.93 Safari/537.36\" \"192.168.174.1\"","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"Nginx的location配置","slug":"Nginx的location配置","date":"2016-12-15T08:03:17.000Z","updated":"2016-12-15T08:03:58.000Z","comments":true,"path":"2016/12/15/Nginx的location配置/","link":"","permalink":"http://yoursite.com/2016/12/15/Nginx的location配置/","excerpt":"","text":"规则location [=|~|~*|^~] /uri/ { … } = 严格匹配。如果这个查询匹配，那么将停止搜索并立即处理此请求。 ~ 为区分大小写匹配(可用正则表达式) ~* 为不区分大小写匹配(可用正则表达式) !~和!~*分别为区分大小写不匹配及不区分大小写不匹配 ^~ 开头表示uri以某个常规字符串开头，理解为匹配 url路径即可。nginx不对url做编码，因此请求为/static/20%/aa，可以被规则^~ /static/ /aa匹配到（注意是空格）。 首先匹配 =，其次匹配^~, 其次是按文件中顺序的正则匹配，最后是交给 / 通用匹配。当有匹配成功时候，停止匹配，按当前匹配规则处理请求。 示例匹配任何查询，因为所有请求都以 / 开头。但是正则表达式规则将被优先和查询匹配。 1location / &#123;&#125; 仅仅匹配 /，访问根目录 12location =/ &#123;&#125;#访问http://localhost/ 不区分大小写匹配任何以gif，jpg，jpeg结尾的文件 123location ~* .(gif|jpg|jpeg)$ ｛rewrite .(gif|jpg)$ /logo.png;｝ 匹配任何已 /images/ 开头的任何查询并且停止搜索。任何正则表达式将不会被测试。 12location ^~ /images/ &#123;&#125;#访问http://localhost/images/a.html 不区分大小写匹配任何以 gif、jpg 或 jpeg 结尾的请求。 1location ~* .(gif|jpg|jpeg)$ &#123;&#125; 实际中，常用的三个匹配规则定义。直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。这里是直接转发给后端应用服务器了，也可以是一个静态首页 1234# 第一个必选规则location = / &#123; proxy_pass http://tomcat:8080/index&#125; 第二个必选规则是处理静态文件请求，这是nginx作为http服务器的强项 1234567# 有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用location ^~ /static/ &#123; root /webroot/static/;&#125;location ~* \\.(gif|jpg|jpeg|png|css|js|ico)$ &#123; root /webroot/res/;&#125; 第三个规则就是通用规则，用来转发动态请求到后端应用服务器，非静态文件请求就默认是动态请求，自己根据实际把握，毕竟目前的一些框架的流行，带.php,.jsp后缀的情况很少了 123location / &#123; proxy_pass http://tomcat:8080/&#125; 场景一： nginx对指定目录做代理（出自运维生存时间http://www.ttlsa.com/nginx/nginx-proxy-spec-dir/） web1，作为前端端服务器，访问地址是http://192.168.1.1, 要将http://192.168.1.1/bbs 的请求交给web2。在web1的网站根目录下并没有bbs目录.web2，作为后端web服务器，访问地址是http://192.168.1.2 12345#方式一location /bbs/ &#123;proxy_pass http://192.168.1.2/; #有“/”&#125;效果：通过 http://192.168.1.1/bbs 可以访问到web2网站根目录下的内容 12345#方式二（未验证通过）location /bbs/ &#123;proxy_pass http://192.168.1.2; #无“/”&#125;效果：要通过web1反问web2网站根目录的内容则需要输入：http://192.168.1.1/bbs/bbs","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"Gitlab变更为https访问","slug":"Gitlab变更为https访问","date":"2016-12-15T07:54:39.000Z","updated":"2016-12-15T07:55:50.000Z","comments":true,"path":"2016/12/15/Gitlab变更为https访问/","link":"","permalink":"http://yoursite.com/2016/12/15/Gitlab变更为https访问/","excerpt":"","text":"（源码方式安装） 方法来自 gitlab 的 help 文档 1、/home/git/gitlab/config/gitlab.yml 文件 将port改为443，https改为true 12345gitlab: ## Web server settings (note: host is the FQDN, do not include http://) host: git.zhai.me port: 443 # Set to 443 if using HTTPS, see installation.md#using-https for additional HTTPS configuration details https: true # Set to true if using HTTPS, see installation.md#using-https for additional HTTPS configuration details 2、/home/git/gitlab-shell/config.yml 文件 将 gitlab_url 改为https的链接,设置认证使用ca_file或ca_path 123456789gitlab_url: \"https://git.zhai.me/\"# See installation.md#using-https for additional HTTPS configuration details.http_settings:# user: someone# password: somepass# ca_file: /etc/ssl/cert.pem ca_path: /etc/pki/tls/certs self_signed_cert: false 3、替换/home/git/gitlab/lib/support/nginx/gitlab-ssl到/etc/nginx/sites-enabled/gitlab 并修改其中的YOUR_SERVER_FQDN和ssl_certificate、ssl_certificate_key的位置","categories":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://yoursite.com/categories/Gitlab/"}],"tags":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://yoursite.com/tags/Gitlab/"},{"name":"Git","slug":"Git","permalink":"http://yoursite.com/tags/Git/"}]},{"title":"公司Gitlab升级记录","slug":"公司Gitlab升级记录","date":"2016-12-15T07:52:10.000Z","updated":"2016-12-15T07:54:03.000Z","comments":true,"path":"2016/12/15/公司Gitlab升级记录/","link":"","permalink":"http://yoursite.com/2016/12/15/公司Gitlab升级记录/","excerpt":"","text":"公司gitlab使用源码方式安装，版本为7.2，因为最近结合ldap来进行使用，但是ldap中的block_auto_created_users选项到7.10才支持。所以要升级。参考官方帮助文档：http://doc.gitlab.com/ce/update/patch_versions.htmlhttps://gitlab.com/gitlab-org/gitlab-ce/blob/master/doc/update/7.9-to-7.10.md 从7.2升级到7.9版本依赖包和软件升级因为版本的升级跨度大，这版本直接肯定有很多新的功能需要扩展包进行支持，所以根据目前最新版(7.12)的源码安装教程重新安装依赖包，并且升级redis服务(测试时出现问题，所以提前升级)。安装依赖包： 1sudo apt-get install -y build-essential zlib1g-dev libyaml-dev libssl-dev libgdbm-dev libreadline-dev libncurses5-dev libffi-dev curl openssh-server redis-server checkinstall libxml2-dev libxslt-dev libcurl4-openssl-dev libicu-dev logrotate python-docutils pkg-config cmake nodejs libkrb5-dev 升级redis： 12345678910111213wget http://download.redis.io/releases/redis-3.0.3.tar.gztar xvf redis-3.0.3.tar.gzcd redis-3.0.3/make make install#会在/usr/local/bin/下边生成相应的bin文件cp redis.conf /etc/redis/#修改redis.conf文件，对应/etc/init.d/redis-server中进行修改daemonize yes #使redis可以后台运行pidfile /var/run/redis/redis-server.pidbind 127.0.0.1logfile /var/log/redis/redis-server.logdir /var/lib/redis 注：升级后，因为redis的bin文件更换了地方，要修改/home/git/gitlab-shell/config.yml为：bin: &quot;/usr/local/bin/redis-cli&quot;。 备份并停止服务123cd /home/git/gitlabsudo -u git -H bundle exec rake gitlab:backup:create RAILS_ENV=production/etc/init.d/gitlab stop 下载最新的稳定版的代码1234567sudo -u git -H git fetch --allsudo -u git -H git checkout v7.9.3``` LATEST_TAG为想要升级到的版本号，国内的网络fetch的时候可能会有问题，需要连接vpn。#### 更新最新的gitlab-shell版本 #### cd /home/git/gitlab-shellsudo -u git -H git fetchsudo -u git -H git checkout vcat /home/git/gitlab/GITLAB_SHELL_VERSION123456#### Install libs, migrations, etc. ####断开VPN连接，并且**修改ruby源来提高速度和成功率**。&gt; 注意：下边的bundle install命令使用的默认源是`https://rubygems.org/`，国内很慢，可以更换成淘宝的源，更改方法为:vim /home/git/gitlab/Gemfile 修改 其中的`source \"https://rubygems.org\"` 为`source \"https://ruby.taobao.org\"` cd /home/git/gitlab #PostgreSQLsudo -u git -H bundle install –without development test mysql –deployment MySQLsudo -u git -H bundle install –without development test postgres –deployment sudo -u git -H bundle exec rake db:migrate RAILS_ENV=productionsudo -u git -H bundle exec rake assets:clean RAILS_ENV=productionsudo -u git -H bundle exec rake assets:precompile RAILS_ENV=productionsudo -u git -H bundle exec rake cache:clear RAILS_ENV=production1#### 开启服务 #### sudo service gitlab startsudo service nginx restart123#### 检测升级是否成功 ####- 检测环境 sudo -u git -H bundle exec rake gitlab:env:info RAILS_ENV=production1- 检测项目 sudo -u git -H bundle exec rake gitlab:check RAILS_ENV=production123### 从7.9升级到7.13版本 ### #### 备份 #### sudo service gitlab stopcd /home/git/gitlabsudo -u git -H bundle exec rake gitlab:backup:create RAILS_ENV=production12#### 更新gitlab #### sudo -u git -H git fetch –allsudo -u git -H git checkout – db/schema.rb # local changes will be restored automaticallysudo -u git -H git checkout 7-13-stable1#### 更新gitlab-shell #### cd /home/git/gitlab-shellsudo -u git -H git fetchsudo -u git -H git checkout v2.6.312### Install libs, migrations, etc ###注：更换/home/git/gitlab/Gemfile中的ruby源 cd /home/git/gitlab MySQL installations (note: the line below states ‘–without … postgres’)sudo -u git -H bundle install –without development test postgres –deployment PostgreSQL installations (note: the line below states ‘–without … mysql’)sudo -u git -H bundle install –without development test mysql –deployment Run database migrationssudo -u git -H bundle exec rake db:migrate RAILS_ENV=production Clean up assets and cachesudo -u git -H bundle exec rake assets:clean assets:precompile cache:clear RAILS_ENV=production Update init.d scriptsudo cp lib/support/init.d/gitlab /etc/init.d/gitlab123#### 更新配置文件 ####因为配置文件中ldap的语法是不同的，所以将老gitlab.yml备份，用gitlab.yml.example替换他，并更改其中必要的配置。 ldap部分的配置如下： ldap: enabled: true servers: ########################################################################## # # Since GitLab 7.4, LDAP servers get ID&apos;s (below the ID is &apos;main&apos;). GitLab # Enterprise Edition now supports connecting to multiple LDAP servers. # # If you are updating from the old (pre-7.4) syntax, you MUST give your # old server the ID &apos;main&apos;. # ########################################################################## main: # &apos;main&apos; is the GitLab &apos;provider ID&apos; of this LDAP server label: &apos;LDAP&apos; host: &apos;ldap-url/IP&apos; port: 389 uid: &apos;uid&apos; method: &apos;plain&apos; # &quot;tls&quot; or &quot;ssl&quot; or &quot;plain&quot; bind_dn: &apos;cn=admin,dc=****,dc=com&apos; password: &apos;admin-passwd&apos; active_directory: true block_auto_created_users: true base: &apos;dc=****,dc=com&apos; user_filter: &apos;&apos; 12#### 启动服务 #### sudo service gitlab startsudo service nginx restart1#### 检查状态 #### sudo -u git -H bundle exec rake gitlab:env:info RAILS_ENV=productionsudo -u git -H bundle exec rake gitlab:check RAILS_ENV=production12#### 修复 ####根据上边检查的结果进行修复 sudo -u git -H bundle exec rake gitlab:satellites:create RAILS_ENV=production```","categories":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://yoursite.com/categories/Gitlab/"}],"tags":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://yoursite.com/tags/Gitlab/"}]},{"title":"Gitlab、GitLab-CI Runner、karma安装记录","slug":"Gitlab-GitLab-CI-Runner-karma安装记录","date":"2016-12-15T07:46:37.000Z","updated":"2016-12-15T07:47:43.000Z","comments":true,"path":"2016/12/15/Gitlab-GitLab-CI-Runner-karma安装记录/","link":"","permalink":"http://yoursite.com/2016/12/15/Gitlab-GitLab-CI-Runner-karma安装记录/","excerpt":"","text":"##Gitlab的安装 使用源码安装，安装方法参照官方文档： 1http://docs.gitlab.com/ce/install/README.html ##GitLab-CI Runner安装 Gitlab-CI Server在Gitlab 8版本以上就集成在gitlab中，不需要单独安装，Runner可以参照官方安装文档： 1https://gitlab.com/gitlab-org/gitlab-ci-multi-runner 本次安装使用如下方法： 安装依赖包 1234apt-get install -y wget curl gcc libxml2-dev libxslt-dev \\libcurl4-openssl-dev libreadline6-dev libc6-dev libssl-dev make \\build-essential zlib1g-dev openssh-server git-core libyaml-dev \\libpq-dev libicu-dev sudo 安装ruby 此次gitlab-ci runner和gitlab安装在同一台服务器，ruby已经安装，过程忽略。安装好ruby可以将源改为国内的淘宝的镜像，如下： 12gem source -r https://rubygems.org/gem source -a https://ruby.taobao.org/ 安装Gitlab-CI Runner (1) 安装ruby bundler 1sudo gem install bundler (2) 建立用于安装 GitLab-CI Runner 的系统用户： 1sudo adduser --disabled-login --gecos 'GitLab CI Runner' gitlab_ci_runner (3) 获取GitLab-CI Runner 源代码： 1234sudo su gitlab_ci_runnercd ~/git clone https://gitlab.com/gitlab-org/gitlab-ci-runner.gitcd gitlab-ci-runner (4) 修改Gem源的镜像改为淘宝镜像： 123vim Gemfile改为：source \"https://ruby.taobao.org/\" (5) 配置完成后安装 Gitlab-CI Runner 的 Gem 包，换回root用户 12cd /home/gitlab_ci_runner/gitlab-ci-runnerbundle install (6) 修改hosts文件，填入gitlab服务器和GitLab-CI 服务器域名对应的 IP (7) 在gitlab服务器上找到ci的token和url 123sudo su gitlab_ci_runnercd ~/gitlab-ci-runnerCI_SERVER_URL=https://git.zhai.me/ci REGISTRATION_TOKEN=replaceme bundle exec ./bin/setup (8) 尝试用 SSH 方式访问 GitLab 服务器，并将服务器的 ssh key 添加到已知主机列表 1ssh git@git.zhai.me (9) 复制 GitLab-CI Runner 的自动启动脚本到系统目录 1234cd /home/gitlab_ci_runner/gitlab-ci-runnersudo cp ./lib/support/init.d/gitlab_ci_runner /etc/init.d/gitlab-ci-runnersudo chmod +x /etc/init.d/gitlab-ci-runnersudo update-rc.d gitlab-ci-runner defaults 21 (10) 启动GitLab-CI Runner 1sudo service gitlab-ci-runner start (11) 到gitlab中去验证。 配合karma进行工程自动化测试karma要配合浏览器使用，（chrome、chromium-browser或者firefox），这边使用firefox，因为chrome、chromium-browser没装成功。。 安装vnc和图形化界面安装桌面图形化的一些软件包 1sudo apt-get install x-window-system-core gdm ubuntu-desktop gnome-core xfce4 安装浏览器和vnc 1apt-get install vnc4server firefox 因为gitlab使用git用户，所以切换到git用户并使用开启vnc 123su - gitvncserver :1#第一次使用可能要设置密码 我们在客户端打开vnc viewer，连接该服务器。可能发现只有命令行，没有图形化界面，进行如下操作： 123456789101112131415vim /home/git/.vnc/xstartup改为：#!/bin/sh# Uncomment the following two lines for normal desktop:# unset SESSION_MANAGER# exec /etc/X11/xinit/xinitrc[ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresourcesxsetroot -solid greyvncconfig -iconic &amp;x-terminal-emulator -geometry 80x24+10+10 -ls -title \"$VNCDESKTOP Desktop\" &amp;#x-window-manager &amp;gnome-session &amp; 重启vncserve，并重新连接。 123su - gitvncserver -kill:1vncserver :1 在服务器上运行firfox，或者在vnc图形化界面中打开firefox，没有报错，则正常。但是我发现肯定会报错。。。报错信息如下： 12root@git:~# firefoxError: cannot open display: :0 这个坑是因为一个叫DISPLAY的变量，坑了好久。。解决办法如下： 如果我们在git用户上使用vncserver :1来开启vnc，则在git用户中要设置变量DISPLAY为:1，如果使用vncserver :2来开启vnc，则在git用户中要设置变量DISPLAY为:2，如下： 12345vim /home/git/.bashrc写入：export DISPLAY=:1source /home/git/.bashrc 重启vncserver，然后进行测试，之后在gitlab中的runner中进行测试。 问题小记1、公司项目编译的时候使用npm，建议改为cnpm或者更改为淘宝的源。 2、如下报错，因为node 4以上版本升级为v8引擎，编译时需要gcc4.8以上版本，而系统默认安装gcc4.6。 1This version of node/NAN/v8 requires a C++11 compiler 升级gcc和g++，方法： 12345678首先添加ppa到库：sudo add-apt-repository ppa:ubuntu-toolchain-r/testsudo apt-get update安装高版本gcc、g++sudo apt-get install gcc-5 g++-5验证(可能需要改一下软连接)gcc -vg++ -v","categories":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://yoursite.com/categories/Gitlab/"}],"tags":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://yoursite.com/tags/Gitlab/"},{"name":"Git","slug":"Git","permalink":"http://yoursite.com/tags/Git/"}]},{"title":"Gitlab迁移小记","slug":"Gitlab迁移小记","date":"2016-12-15T07:43:50.000Z","updated":"2016-12-15T07:44:51.000Z","comments":true,"path":"2016/12/15/Gitlab迁移小记/","link":"","permalink":"http://yoursite.com/2016/12/15/Gitlab迁移小记/","excerpt":"","text":"情况一：A机器和B机器 使用Omnibus package（rpm）安装，且版本相同 12345678910111213备份：gitlab-rake gitlab:backup:create恢复：# 停止相关数据连接服务gitlab-ctl stop unicorngitlab-ctl stop sidekiq# 从Timestamp编号备份中恢复gitlab-rake gitlab:backup:restore BACKUP= Timestamp# 启动Gitlabsudo gitlab-ctl start 情况二：使用源码安装，且版本相同 12345全量备份：sudo -u git -H bundle exec rake gitlab:backup:create RAILS_ENV=production恢复：sudo -u git -H bundle exec rake gitlab:backup:restore RAILS_ENV=production BACKUP=Timestamp 情况三：使用源码安装，版本不完全相同 1234567891011备份：打包/home/git/repositories、备份pgsql或者mysql数据（如果版本一样，可以直接打包数据目录）、/home/git/.ssh/authorized_keys.恢复：1、 将上边备份的文件放到指定位置2、 bundle exec rake gitlab:import:repos RAILS_ENV=production检测：sudo -u git -H bundle exec rake gitlab:env:info RAILS_ENV=production（环境检测）sudo -u git -H bundle exec rake gitlab:check RAILS_ENV=production（项目检测）根据检测结果提示修复不正确的地方","categories":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://yoursite.com/categories/Gitlab/"}],"tags":[{"name":"Gitlab，Git","slug":"Gitlab，Git","permalink":"http://yoursite.com/tags/Gitlab，Git/"}]},{"title":"ELK + filebeat 日志分析工具的部署和简单应用","slug":"ELK和filebeat的部署和简单应用","date":"2016-12-15T07:41:58.000Z","updated":"2016-12-15T07:42:41.000Z","comments":true,"path":"2016/12/15/ELK和filebeat的部署和简单应用/","link":"","permalink":"http://yoursite.com/2016/12/15/ELK和filebeat的部署和简单应用/","excerpt":"","text":"参考文章：https://www.ibm.com/developerworks/cn/opensource/os-cn-elk/ 123456789101112131415环境： - 两台 CentOS 6.5 - elasticsearch-2.4.1 - kibana-4.6.1 - logstash-2.4.0 - filebeat-1.3.1过程： - 安装 JDK - 安装 Elasticsearch - 安装 Kibana - 安装 Nginx - 安装 Logstash - 配置 Logstash - 安装 filebeat - 访问 ELK 服务器中： 安装 Java 环境 https://www.java.com/zh_CN/download/manual.jsp中下载java安装包 解压到/usr/local/jdk 目录下 在/etc/profile文件中追加： 123export JAVA_HOME=/usr/local/jdkexport CLASS_PATH=$JAVA_HOME/libexport PATH=$JAVA_HOME/bin:$PATH 使设置的环境变量生效。 source /etc/profile 安装 Elasticsearch 在https://www.elastic.co/downloads中下载Elasticsearch的安装包。 解压，并移动到/usr/local/elasticsearch目录下。 12$ tar xvf elasticsearch-2.4.1.zip$ mv elasticsearch-2.4.1 /usr/local/elasticsearch 修改/usr/local/elasticsearch/config/elasticsearch.yml，来更改监听端口，监听127.0.0.1，提高安全性。 12# 如下更改network.host: 127.0.0.1 启动（会有报错） 1234$ cd /usr/local/elasticsearch/$ bash bin/elasticsearch -d# 会有报错，信息如下：Exception in thread \"main\" java.lang.RuntimeException: don't run elasticsearch as root. -d是让es保持后台运行。报错信息提示我们es无法用root用户启动，所以可以创建elk用户，来启动es 安装 kibana 在https://www.elastic.co/downloads中下载kibana的安装包。 解压，并移动到/usr/local/kibana目录下。 修改/usr/local/kibana/config/kibana.yml，来更改监听端口，监听127.0.0.1 12# 修改如下server.host: \"127.0.0.1\" 启动，观察/usr/local/kibana/nohup.out是否有报错信息 12$ cd /usr/local/kibana$ nohup bin/kibana &amp; 安装 Nginx 直接yum安装 1$ yum install nginx 修改/etc/nginx/conf.d/default.conf文件，如下： 12345678910111213141516171819server &#123; listen 80; server_name _; location / &#123; proxy_pass http://127.0.0.1:5601/; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection 'upgrade'; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade;&#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125;&#125; 启动nginx 1234# 测试配置是否正常$ nginx -t# 启动$ /etc/init.d/nginx start 安装 Logstash 在https://www.elastic.co/downloads中下载Logstash的安装包。 解压，并移动到/usr/local/logstash目录下。 验证服务可用性 12345678$ cd /usr/local/logstash$ bin/logstash -e 'input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;'Settings: Default pipeline workers: 2Pipeline main started# 任意输入，看输出是否正常，如下：hello2016-10-13T10:07:01.502Z satezheng hello# CTRL-D 退出 配置 Logstash我们需要配置 Logstash 以指明从哪里读取数据，向哪里输出数据。这个过程我们称之为定义 Logstash 管道（Logstash Pipeline）。通常一个管道需要包括必须的输入（input），输出（output），和一个可选项目 Filter 配置 ssl客户端和服务器之间通信使用ssl来认证身份，更加安全。 修改/etc/pki/tls/openssl.cnf文件 12# 找到 [v3_ca] 段，添加下面一行，保存退出。subjectAltName = IP: logstash_server_ip 生成srt文件 12$ cd /etc/pki/tls$ openssl req -config openssl.cnf -x509 -days 2650 -batch -nodes -newkey rsa:2048 -keyout private/logstash-forwarder.key -out certs/logstash-forwarder.crt 发送srt文件到客户端 12$ cd /etc/pki/tls$ scp certs/logstash-forwarder.crt 客户端IP:/etc/pki/tls/certs 配置 Logstash 管道文件 创建filebeat-input.conf文件 12345678910111213$ mkdir /usr/local/logstash/conf$ cd /usr/local/logstash/conf$ vim filebeat-input.conf# 写入：input &#123; beats &#123; port =&gt; 5044 type =&gt; \"logs\" ssl =&gt; true ssl_certificate =&gt; \"/etc/pki/tls/certs/logstash-forwarder.crt\" ssl_key =&gt; \"/etc/pki/tls/private/logstash-forwarder.key\" &#125;&#125; 创建filebeat-output.conf文件 123456$ vim filebeat-input.conf# 写入：output &#123; elasticsearch &#123; hosts =&gt; [\"127.0.0.1:9200\"] &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; 启动12$ cd /usr/local/logstash$ nohup bin/logstash -f conf/ &amp; 客户端安装 filebeatfilebeat代替之前的ogstash-forwarder 在https://www.elastic.co/downloads/beats/filebeat下载 解压并放到/usr/local/filebeat目录下 修改filebeat.yml 12$ cd /usr/local/filebeat$ vim filebeat.yml 写入： 1234567891011121314151617181920filebeat: prospectors: - paths: - /var/log/* input_type: log document_type: log registry_file: /var/lib/filebeat/registryoutput: logstash: hosts: [\"服务端IP:5044\"] tls: certificate_authorities: [\"/etc/pki/tls/certs/logstash-forwarder.crt\"]shipper:logging: files: rotateeverybytes: 10485760 # = 10MB 启动 12$ cd /usr/local/filebeat$ nohup ./filebeat -e -c filebeat.yml &amp; 访问服务端IP来验证是否成功，有问题可以根据输出日志来解决。","categories":[{"name":"ELK","slug":"ELK","permalink":"http://yoursite.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://yoursite.com/tags/ELK/"}]},{"title":"Docker基本命令","slug":"Docker命令","date":"2016-12-15T07:40:23.000Z","updated":"2016-12-15T07:41:04.000Z","comments":true,"path":"2016/12/15/Docker命令/","link":"","permalink":"http://yoursite.com/2016/12/15/Docker命令/","excerpt":"","text":"docker version ：查看docker的版本号，包括客户端、服务端、依赖的Go等 123456789101112131415161718[root@centos7 ~]# docker versionClient: Version: 1.8.2-el7.centos API version: 1.20 Package Version: docker-1.8.2-10.el7.centos.x86_64 Go version: go1.4.2 Git commit: a01dc02/1.8.2 Built: OS/Arch: linux/amd64Server: Version: 1.8.2-el7.centos API version: 1.20 Package Version: Go version: go1.4.2 Git commit: a01dc02/1.8.2 Built: OS/Arch: linux/amd64 docker info:查看系统(docker)层面信息，包括管理的images, containers数等 123456789101112131415161718192021222324252627282930[root@centos7 ~]# docker infoContainers: 1Images: 4Storage Driver: devicemapper Pool Name: docker-8:3-36786088-pool Pool Blocksize: 65.54 kB Backing Filesystem: xfs Data file: /dev/loop0 Metadata file: /dev/loop1 Data Space Used: 2.059 GB Data Space Total: 107.4 GB Data Space Available: 12.93 GB Metadata Space Used: 1.765 MB Metadata Space Total: 2.147 GB Metadata Space Available: 2.146 GB Udev Sync Supported: true Deferred Removal Enabled: false Data loop file: /var/lib/docker/devicemapper/devicemapper/data Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata Library Version: 1.02.107-RHEL7 (2015-10-14)Execution Driver: native-0.2Logging Driver: json-fileKernel Version: 3.10.0-327.el7.x86_64Operating System: CentOS Linux 7 (Core)CPUs: 1Total Memory: 977.9 MiBName: centos7ID: BUKD:MUW2:5X2D:G7BF:6Y7G:SKIH:LD6K:VUAC:3QA4:JY5C:S3DG:LFT2WARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled search 搜索镜像： 1234567[root@centos7 ~]# docker search ubuntu12.10INDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATEDdocker.io docker.io/chug/ubuntu12.10x32 Ubuntu Quantal Quetzal 12.10 32bit base i... 0 docker.io docker.io/chug/ubuntu12.10x64 Ubuntu Quantal Quetzal 12.10 64bit base i... 0 docker.io docker.io/marcgibbons/ubuntu12.10 0 docker.io docker.io/mirolin/ubuntu12.10 0 docker.io docker.io/mirolin/ubuntu12.10_redis 0 pull 下载镜像： 1[root@centos7 ~]# docker pull ubuntu run 使用镜像创建容器： 1[root@centos7 ~]# docker run ubuntu /bin/echo hello world run 创建容器，并交互式的运行：这里会创建一个新的容器。 1234[root@centos7 ~]# docker run -i -t ubuntu /bin/bashroot@c43c7d102baa:/# cat /etc/issueUbuntu 14.04.3 LTS \\n \\l# -t 选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i 则让容器的标准输入保持打开 当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 run -d 守护态运行：更多的时候，需要让 Docker 容器在后台以守护态（Daemonized）形式运行。此时，可以通过添加 -d 参数来实现。例如下面的命令会在后台运行容器。 1[root@centos7 ~]# docker run -d ubuntu /bin/bash -c \"while true;do echo hello world;sleep 1;done\" logs 查看容器的运行： 以上个例子为前导。12345678[root@centos7 ~]# docker logs 4f34f95b6abchello worldhello worldhello worldhello worldhello worldhello worldhello world ps 查看容器： 123456789101112131415161718[root@centos7 ~]# docker ps -hUsage: docker ps [OPTIONS]List containers -a, --all=false Show all containers (default shows just running) --before= Show only container created before Id or Name -f, --filter=[] Filter output based on conditions provided --format= Pretty-print containers using a Go template --help=false Print usage -l, --latest=false Show the latest created container, include non-running -n=-1 Show n last created containers, include non-running --no-trunc=false Don't truncate output -q, --quiet=false Only numeric IDs -s, --size=false Display total file sizes --since= Show created since Id or Name, include non-running attach 连接已经启动的容器 / start -i 启动并连接容器： 12345[root@centos7 ~]# docker ps -a #查看容器ID[root@centos7 ~]# docker start &lt;CONTAINER ID&gt; #启动容器[root@centos7 ~]# docker attach &lt;CONTAINER ID&gt; #连接容器，该容器必须是启动状态或者[root@centos7 ~]# docker start -i &lt;CONTAINER ID&gt; #启动并连接容器 注：但是使用 attach 命令有时候并不方便。当多个窗口同时 attach 到同一个容器的时候，所有窗口都会同步显示。当某个窗口因命令阻塞时,其他窗口也无法执行操作了。 commit 将容器的状态保存为镜像： 123456789[root@centos7 ~]# docker commit c43c7d102baa ubhttpd47bbf8e50bace073de2b256b0360cfab029c11881f0d361fce7ae7464aa40ff[root@centos7 ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEubhttp latest d47bbf8e50ba 54 seconds ago 248 MBdocker.io/ubuntu latest 8693db7e8a00 7 days ago 187.9 MB## 更为标准点的如下：$ sudo docker commit -m \"Added json gem\" -a \"Docker Newbee\" 0b2616b0e5a8 ouruser/sinatra:v2其中，-m 来指定提交的说明信息，跟我们使用的版本控制工具一样；-a 可以指定更新的用户信息；之后是用来创建镜像的容器的 ID；最后指定目标镜像的仓库名和 tag 信息。创建成功后会返回这个镜像的 ID 信息。 diff 命令查看容器内的文件变化： 它可以列出容器内发生变化的文件和目录。这些变化包括添加（A-add）、删除（D-delete）、修改（C-change） 1[root@centos7 ~]# docker diff c43c7d102baa cp 命令拷贝文件： 1234567891011#从docker中往本地拷贝文件[root@centos7 ~]# docker cp c43c7d102baa:/var/www/html/index.html /opt/ [root@centos7 ~]# ls /opt/index.html rh# 从本地往docker中拷贝文件[root@centos7 ~]# docker cp aa c43c7d102baa:/var[root@centos7 ~]# docker start -i c43c7d102baaroot@c43c7d102baa:/# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr varroot@c43c7d102baa:/# ls var/aa backups cache lib local lock log mail opt run spool tmp www inspect 收集有关容器和镜像的底层信息： Docker inspect命令可以收集有关容器和镜像的底层信息。这些信息包括： 容器实例的IP地址 端口绑定列表 特定端口映射的搜索 收集配置的详细信息 语法： 1docker inspect container/image kill 命令发送sigkill信号停止容器的主进程： 语法： 1docker kill [options] &lt;container_id&gt; rmi 移除一个或多个镜像： 12docker rmi &lt;image_id&gt;#注意：在删除镜像之前要先用 docker rm 删掉依赖于这个镜像的所有容器 wait 阻塞对指定容器的其它调用方法，直到容器停止后退出阻塞 1docker wait &lt;container_id&gt; tag 修改镜像的标签 123456789[root@centos7 ~]# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE&lt;none&gt; &lt;none&gt; f59c7e5b1817 18 hours ago 192 MBdocker.io/ubuntu latest 8693db7e8a00 7 days ago 187.9 MB[root@centos7 ~]# docker tag f59c7e5b1817 zwx/ub_mv:127 [root@centos7 ~]# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEzwx/ub_mv 127 f59c7e5b1817 18 hours ago 192 MBdocker.io/ubuntu latest 8693db7e8a00 7 days ago 187.9 MB docker的导入导出操作save 保存镜像为tar文件并发送到STDOUT: 123456[root@node2 ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEzwx_ub latest f59c7e5b1817 7 seconds ago 192 MBubuntu latest 8693db7e8a00 6 days ago 187.9 MB[root@node2 ~]# docker save f59c7e5b1817 &gt;zwx_ub.tar# 我将zwx_ub这个镜像导出成tar包，并拷贝到centos7的测试机中导入，导入过程在下边。 load 从tar文件中载入镜像或仓库到STDIN: 123456789101112[root@centos7 ~]# docker load -i zwx_ub.tar [root@centos7 ~]# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEubhttp latest d47bbf8e50ba About an hour ago 248 MB&lt;none&gt; &lt;none&gt; f59c7e5b1817 16 hours ago 192 MBdocker.io/ubuntu latest 8693db7e8a00 7 days ago 187.9 MB[root@centos7 ~]# docker run -it f59c7e5b1817root@e17558664f8d:/# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr varroot@e17558664f8d:/# ls /mnt/zwx# 可以看出，我导入zwx_ub这个镜像后，镜像ID并没有变化，我创建个容器并进入，发现打包前我创建的文件都在。 import 从本地文件系统导入一个镜像 比如，先下载了一个 ubuntu-14.04 的镜像，之后使用以下命令导入tar.gz的镜像可以在http://openvz.org/Download/template/precreated下载。 12345[root@centos7 ~]# cat ubuntu-14.04-x86_64-minimal.tar.gz |docker import - ubuntu:zwx23997a971195cdd826f16a50573e480e1be1679729636178146425cdd46d1b52[root@centos7 ~]# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEubuntu zwx 23997a971195 28 seconds ago 214.9 MB export 容器的导出 1234[root@centos7 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES16f568766019 ubuntu \"/bin/bash\" 52 minutes ago Up 45 minutes elegant_mcclintock[root@centos7 ~]# docker export 16f568766019 &gt;ubuntu.tar import 容器的导入： 可以将容器的tar文件再导入为镜像 1234$ cat ubuntu.tar | sudo docker import - test/ubuntu:v1.0$ sudo docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEtest/ubuntu v1.0 9d37a6082e97 About a minute ago 171.3 MB 此外，也可以通过指定 URL 或者某个目录来导入，例如 1$sudo docker import http://example.com/exampleimage.tgz example/imagerepo 注：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以使用 docker import 来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"Docker私有仓库","slug":"Docker私有仓库","date":"2016-12-15T07:39:33.000Z","updated":"2016-12-15T07:40:03.000Z","comments":true,"path":"2016/12/15/Docker私有仓库/","link":"","permalink":"http://yoursite.com/2016/12/15/Docker私有仓库/","excerpt":"","text":"安装私有仓库默认情况下，仓库会被创建在容器的 /tmp/registry 下。可以通过 -v 参数来将镜像文件存放在本地的指定路径。 例如下面的例子将上传的镜像放到 /opt/data/registry 目录。 1sudo docker run -d -p 5000:5000 -v /opt/data/registry:/tmp/registry registry 上传镜像创建好私有仓库之后，就可以使用 docker tag 来标记一个镜像，然后推送它到仓库，别的机器上就可以下载下来了。例如私有仓库地址为 192.168.0.1:5000。 1234$ sudo docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEsate/centos 6.7 976079dcc3f5 3 days ago 190.6 MBcentos 6.7 130db9a2a215 2 weeks ago 190.6 MB 使用docker tag 将 976079dcc3f5 这个镜像标记为 192.168.0.1:5000/sate-centos（格式为 docker tag IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG]）。 1234567$ docker tag 976079dcc3f5 192.168.0.1:5000/sate-centos:test$ docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE192.168.0.1:5000/sate-centos test 976079dcc3f5 3 days ago 190.6 MBsate/centos 6.7 976079dcc3f5 3 days ago 190.6 MBcentos 6.7 130db9a2a215 2 weeks ago 190.6 MB 使用 docker push 上传标记的镜像。 12345$ docker push 192.168.0.1:5000/sate-centosThe push refers to a repository [192.168.0.1:5000/sate-centos] (len: 1)unable to ping registry endpoint https://192.168.0.1:5000/v0/v2 ping attempt failed with error: Get https://192.168.0.1:5000/v2/: EOF v1 ping attempt failed with error: Get https://192.168.0.1:5000/v1/_ping: EOF 注：报错是因为 docker 默认使用https的方式，解决办法如下： 办法： 修改配置文件，使用 http 方式 centos系统： 修改docker的配置文件/etc/sysconfig/docker 1234# 加入：INSECURE_REGISTRY='--insecure-registry 192.168.0.1:5000'# 重启服务systemctl restart docker ubuntu系统： 修改docker的配置文件/etc/default/docker 1234# 加入：DOCKER_OPTS='--insecure-registry 192.168.0.1:5000'# 重启服务service docker start 再次尝试 push 镜像，如下： 1234567891011$ sudo docker push 192.168.0.1:5000/testThe push refers to a repository [192.168.0.1:5000/test] (len: 1)Sending image listPushing repository 192.168.0.1:5000/test (1 tags)Image 511136ea3c5a already pushed, skippingImage 9bad880da3d2 already pushed, skippingImage 25f11f5fb0cb already pushed, skippingImage ebc34468f71d already pushed, skippingImage 2318d26665ef already pushed, skippingImage ba5877dc9bec already pushed, skippingPushing tag for rev [ba5877dc9bec] on &#123;http://192.168.0.1:5000/v1/repositories/test/tags/latest&#125; 当push成功后，查看本地目录/opt/data/registry: 12root@sate-z:/opt/data/registry# lsimages repositories 测试通过私仓的链接地址查看我们刚上传的镜像： 12$ curl http://192.168.0.1:5000/v1/search&#123;\"num_results\": 1, \"query\": \"\", \"results\": [&#123;\"description\": \"\", \"name\": \"library/sate-centos\"&#125;]&#125; 下载镜像用pull命令来拉取我们的镜像： 1$ docker pull 192.168.0.1:5000/sate-centos:test","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"Docker使用Dockerfile","slug":"Docker使用Dockerfile","date":"2016-12-15T07:38:36.000Z","updated":"2016-12-15T08:21:33.000Z","comments":true,"path":"2016/12/15/Docker使用Dockerfile/","link":"","permalink":"http://yoursite.com/2016/12/15/Docker使用Dockerfile/","excerpt":"","text":"使用 docker commit 来扩展一个镜像比较简单，但是不方便在一个团队中分享。我们可以使用 docker build 来创建一个新的镜像。为此，首先需要创建一个 Dockerfile，包含一些如何创建镜像的指令。 创建新的目录和dockerfile 123$ mkdir sinatra$ cd sinatra$ touch Dockerfile Dockerfile 中每一条指令都创建镜像的一层，例如： 123456# This is a comment # 使用#来注释FROM ubuntu:14.04 # FROM 指令告诉 Docker 使用哪个镜像作为基础MAINTAINER Docker Newbee &lt;newbee@docker.com&gt; # 接着是维护者的信息RUN apt-get -qq update # RUN开头的指令会在创建中运行，比如安装一个软件包，在这里使用 apt-get 来安装了一些软件RUN apt-get -qqy install ruby ruby-devRUN gem install sinatra 创建完成dockerfile后可以使用docker bulid 来生成镜像。 12345678910111213141516171819202122232425262728293031323334$ sudo docker build -t=\"ouruser/sinatra:v2\" .Uploading context 2.56 kBUploading contextStep 0 : FROM ubuntu:14.04 ---&gt; 99ec81b80c55Step 1 : MAINTAINER Newbee &lt;newbee@docker.com&gt; ---&gt; Running in 7c5664a8a0c1 ---&gt; 2fa8ca4e2a13Removing intermediate container 7c5664a8a0c1Step 2 : RUN apt-get -qq update ---&gt; Running in b07cc3fb4256 ---&gt; 50d21070ec0cRemoving intermediate container b07cc3fb4256Step 3 : RUN apt-get -qqy install ruby ruby-dev ---&gt; Running in a5b038dd127eSelecting previously unselected package libasan0:amd64.(Reading database ... 11518 files and directories currently installed.)Preparing to unpack .../libasan0_4.8.2-19ubuntu1_amd64.deb ...Setting up ruby (1:1.9.3.4) ...Setting up ruby1.9.1 (1.9.3.484-2ubuntu1) ...Processing triggers for libc-bin (2.19-0ubuntu6) ... ---&gt; 2acb20f17878Removing intermediate container a5b038dd127eStep 4 : RUN gem install sinatra ---&gt; Running in 5e9d0065c1f7. . .Successfully installed rack-protection-1.5.3Successfully installed sinatra-1.4.54 gems installed ---&gt; 324104cde6adRemoving intermediate container 5e9d0065c1f7Successfully built 324104cde6ad# 其中 -t 标记来添加 tag，指定新的镜像的用户信息。 “.” 是 Dockerfile 所在的路径（当前目录），也可以替换为一个具体的 Dockerfile 的路径。# dockerfile命名是固定的。 此外，还可以利用 ADD 命令复制本地文件到镜像；用 EXPOSE 命令来向外部开放端口；用 CMD 命令来描述容器启动后运行的程序等。例如 123456# put my local web site in myApp folder to /var/wwwADD myApp /var/www# expose httpd portEXPOSE 80# the command to runCMD [\"/usr/sbin/apachectl\", \"-D\", \"FOREGROUND\"]","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"Docker练习","slug":"Docker练习","date":"2016-12-15T07:36:00.000Z","updated":"2016-12-15T07:37:34.000Z","comments":true,"path":"2016/12/15/Docker练习/","link":"","permalink":"http://yoursite.com/2016/12/15/Docker练习/","excerpt":"","text":"安装系统：ubuntu 14.04 12345678910# 升级内核$ apt-get update$ apt-get install linux-headers-3.13.0-88-generic# 安装新版本的 docker$ sudo apt-get install apt-transport-https$ sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 36A1D7869245C8950F966E92D8576A8BA88D21E9$ deb https://get.docker.io/ubuntu docker main &gt; /etc/apt/sources.list.d/docker.list\"$ sudo bash -c \"echo deb https://get.docker.io/ubuntu docker main &gt; /etc/apt/sources.list.d/docker.list\"$ apt-get update$ apt-get install lxc-docker 下载 ubuntu 镜像1234$ docker pull ubuntu$ docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEubuntu latest 594b6e305389 3 weeks ago 122 MB 启动容器，并安装 nginx12$ docker run -i -t ubuntu /bin/bash在该 docker 容器中安装 nginx 将安装 nginx 的容器保存为镜像123456$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ecstatic_thompsonb5138a3e3352 ubuntu \"/bin/bash\" 2 hours ago Exited (0) 2 hours ago hopeful_perlmanroot@sate-z:~#$ docker commit -m \"nginx/ubuntu\" -a \"sate\" b5138a3e3352 ubuntu-nginx:v1-m 备注 -a 用户名 ubuntu-nginx:v1 镜像名称和TAG 名称 用新创建的镜像，开一个新的容器，并映射端口12$ docker run -i -t -p 90:80 ubuntu-nginx:v1 /bin/bash# 在该 docker 中启动 nginx 。可能需要自己写 nginx 的conf文件，访问宿主机的 ip:90，就可以访问到 docker 中的网站 问题现在有个问题就是如何让 docker 容器在后台运行。 还有就是 ansible 如何控制 docker。 有一个可以后台运行的方法是安装 sshd 服务，然后以-D方式启动，但感觉应该还有更好的办法 12$ apt-get install openssh-server openssh-client$ docker run -d -p 50001:22 ubuntu/ruby:v2 /usr/sbin/sshd -D","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"Docker的安装","slug":"Docker的安装","date":"2016-12-15T07:34:30.000Z","updated":"2016-12-15T07:35:24.000Z","comments":true,"path":"2016/12/15/Docker的安装/","link":"","permalink":"http://yoursite.com/2016/12/15/Docker的安装/","excerpt":"","text":"centos 6.5 中docker的安装 yum 源安装 1$ yum install docker-io 启动 1$ /etc/init.d/docker start 日志中报错 123time=\"2016-01-19T14:21:25.993968299+08:00\" level=warning msg=\"You are running linux kernel version 2.6.32-431.el6.x86_64, which might be unstable running docker. Please upgrade your kernel to 3.10.0.\" time=\"2016-01-19T14:21:25.997212022+08:00\" level=info msg=\"Listening for HTTP on unix (/var/run/docker.sock)\" /usr/bin/docker: relocation error: /usr/bin/docker: symbol dm_task_get_info_with_deferred_remove, version Base not defined in file libdevmapper.so.1.02 with link time reference 日志可以看出，一个warning和一个error。 warning中指出我的kernel版本可能运行docker不稳定，建议我升级到3.10版本。 error的报错可以通过升级device-mapper-libs解决。1yum upgrade device-mapper-libs centos 7 中docker的安装 yum 源安装 1$ yum install docker","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"Docker容器的连接","slug":"Docker容器的连接","date":"2016-12-15T07:32:33.000Z","updated":"2016-12-15T07:34:08.000Z","comments":true,"path":"2016/12/15/Docker容器的连接/","link":"","permalink":"http://yoursite.com/2016/12/15/Docker容器的连接/","excerpt":"","text":"连接docker容器的三种方式attach 参数12345[root@centos7 ~]# docker ps -a #查看容器ID[root@centos7 ~]# docker start &lt;CONTAINER ID&gt; #启动容器[root@centos7 ~]# docker attach &lt;CONTAINER ID&gt; #连接容器，该容器必须是启动状态或者[root@centos7 ~]# docker start -i &lt;CONTAINER ID&gt; #启动并连接容器 注：但是使用 attach 命令有时候并不方便。当多个窗口同时 attach 到同一个容器的时候，所有窗口都会同步显示。当某个窗口因命令阻塞时,其他窗口也无法执行操作了。 nsenter 命令安装 nsenter 工具在 util-linux 包2.23版本后包含。 如果系统中 util-linux 包没有该命令，可以按照下面的方法从源码安装。 123$ cd /tmp; curl https://www.kernel.org/pub/linux/utils/util-linux/v2.24/util-linux-2.24.tar.gz | tar -zxf-; cd util-linux-2.24;$ ./configure --without-ncurses$ make nsenter &amp;&amp; sudo cp nsenter /usr/local/bin 使用 为了连接到容器，你还需要找到容器的第一个进程的 PID，可以通过下面的命令获取。 1PID=$(docker inspect --format \"&#123;&#123; .State.Pid &#125;&#125;\" &lt;container&gt;) 通过这个 PID，就可以连接到这个容器： 1$ nsenter --target $PID --mount --uts --ipc --net --pid 实例 1234567[root@centos7 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES16f568766019 ubuntu \"/bin/bash\" 34 minutes ago Up 28 minutes elegant_mcclintock[root@centos7 ~]# docker inspect --format \"&#123;&#123; .State.Pid &#125;&#125;\" 16f56876601919803[root@centos7 ~]# nsenter --target 19803 --mount --uts --ipc --net --pidroot@16f568766019:/# .bashrc_docker 脚本其实就是从docker inspect中取相关的数据，具体的脚本代码在最后贴出。 12$ wget -P ~ https://github.com/yeasy/docker_practice/raw/master/_local/.bashrc_docker;$ echo \"[ -f ~/.bashrc_docker ] &amp;&amp; . ~/.bashrc_docker\" &gt;&gt; ~/.bashrc; source ~/.bashrc 这个文件中定义了很多方便使用 Docker 的命令，例如 docker-pid 可以获取某个容器的 PID；而 docker-enter 可以进入容器或直接在容器内执行命令。 123456[root@centos7 ~]# docker-pid 16f56876601919803 [root@centos7 ~]# docker-ip 16f568766019172.17.0.8[root@centos7 ~]# docker-enter 16f568766019 unameLinux 脚本内容： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# Some useful commands to use docker.# Author: yeasy@github# Created:2014-09-25alias docker-pid=\"sudo docker inspect --format '&#123;&#123;.State.Pid&#125;&#125;'\"alias docker-ip=\"sudo docker inspect --format '&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;'\"#the implementation refs from https://github.com/jpetazzo/nsenter/blob/master/docker-enterfunction docker-enter() &#123; #if [ -e $(dirname \"$0\")/nsenter ]; then #Change for centos bash running if [ -e $(dirname '$0')/nsenter ]; then # with boot2docker, nsenter is not in the PATH but it is in the same folder NSENTER=$(dirname \"$0\")/nsenter else # if nsenter has already been installed with path notified, here will be clarified NSENTER=$(which nsenter) #NSENTER=nsenter fi [ -z \"$NSENTER\" ] &amp;&amp; echo \"WARN Cannot find nsenter\" &amp;&amp; return if [ -z \"$1\" ]; then echo \"Usage: `basename \"$0\"` CONTAINER [COMMAND [ARG]...]\" echo \"\" echo \"Enters the Docker CONTAINER and executes the specified COMMAND.\" echo \"If COMMAND is not specified, runs an interactive shell in CONTAINER.\" else PID=$(sudo docker inspect --format \"&#123;&#123;.State.Pid&#125;&#125;\" \"$1\") if [ -z \"$PID\" ]; then echo \"WARN Cannot find the given container\" return fi shift OPTS=\"--target $PID --mount --uts --ipc --net --pid\" if [ -z \"$1\" ]; then # No command given. # Use su to clear all host environment variables except for TERM, # initialize the environment variables HOME, SHELL, USER, LOGNAME, PATH, # and start a login shell. #sudo $NSENTER \"$OPTS\" su - root sudo $NSENTER --target $PID --mount --uts --ipc --net --pid su - root else # Use env to clear all host environment variables. sudo $NSENTER --target $PID --mount --uts --ipc --net --pid env -i $@ fi fi&#125;","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"Ansible的Ad-Hoc","slug":"Ansible的Ad-Hoc","date":"2016-12-15T07:29:10.000Z","updated":"2016-12-15T07:29:42.000Z","comments":true,"path":"2016/12/15/Ansible的Ad-Hoc/","link":"","permalink":"http://yoursite.com/2016/12/15/Ansible的Ad-Hoc/","excerpt":"","text":"我们经常会通过命令行形式来使用 ansible， ansible 会自带很多模块. 查看 ansible 自带模块和模块介绍的方法如下： 12$ ansible-doc -l #列出所有模块$ ansible-doc shell #查看 shell 模块的详细信息 复制文件12345678910111213141516# 文件的变化是通过 md5值来判断的。$ ansible sate -m copy -a \"src=./mysql_back.py dest=/mnt/ owner=root group=root mode=644 backup=yes\"120.26.45.230 | SUCCESS =&gt; &#123; \"changed\": true, \"checksum\": \"1c332293fa02633b42ffcd10faddafc2d44083c0\", \"dest\": \"/mnt/mysql_back.py\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"46959dcafe35d9b727075237fbb8a3a0\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 1589, \"src\": \"/root/.ansible/tmp/ansible-tmp-1465968433.17-146914892008272/source\", \"state\": \"file\", \"uid\": 0&#125; 包和服务管理1234567891011121314151617# 安装 nginx 服务$ ansible sate -m apt -a \"name=nginx state=latest\"# 服务的启动与关闭$ ansible sate -m service -a \"name=nginx state=started\"120.26.45.230 | SUCCESS =&gt; &#123; \"changed\": false, \"name\": \"nginx\", \"state\": \"started\"&#125;$ ansible sate -m service -a \"name=nginx state=stopped\"120.26.45.230 | SUCCESS =&gt; &#123; \"changed\": true, \"name\": \"nginx\", \"state\": \"stopped\"&#125; 用户管理1234567891011121314151617181920212223# 先将要设置的账户密码进行加密$ echo sate | openssl passwd -1 -stdin$1$xZGhHuDC$7yx6FmawND4yEKLkr35o20# 通过 ansible 创建新的用户$ ansible sate -m user -a 'name=sate password=\"$1$xZGhHuDC$7yx6FmawND4yEKLkr35o20\"'120.26.45.230 | SUCCESS =&gt; &#123; \"changed\": true, \"comment\": \"\", \"createhome\": true, \"group\": 1000, \"home\": \"/home/sate\", \"name\": \"sate\", \"password\": \"NOT_LOGGING_PASSWORD\", \"shell\": \"\", \"state\": \"present\", \"stderr\": \"useradd: warning: the home directory already exists.\\nNot copying any file from skel directory into it.\\n\", \"system\": false, \"uid\": 1000&#125;# 测试$ ssh sate@120.26.45.230","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/tags/Ansible/"}]},{"title":"Ansible的facts","slug":"Ansible的facts","date":"2016-12-15T07:27:34.000Z","updated":"2016-12-15T07:28:14.000Z","comments":true,"path":"2016/12/15/Ansible的facts/","link":"","permalink":"http://yoursite.com/2016/12/15/Ansible的facts/","excerpt":"","text":"facts 组件是 ansible 用于采集被管理机器信息的一个功能，我们可以使用setup模块查询机器所有的 facts 信息，也可以使用filter来查询指定信息。输出的是 JSON 格式。 12345678910111213141516171819202122232425262728293031323334353637383940414243root@sate-z:~# ansible sate -m setup10.117.214.178 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"ansible_all_ipv4_addresses\": [ \"10.117.214.178\", \"120.26.45.230\" ], \"ansible_all_ipv6_addresses\": [], \"ansible_architecture\": \"x86_64\", \"ansible_bios_date\": \"12/16/2014\", \"ansible_bios_version\": \"4.0.1\", \"ansible_cmdline\": &#123; \"BOOT_IMAGE\": \"/boot/vmlinuz-3.13.0-65-generic\", \"quiet\": true, \"ro\": true, \"root\": \"UUID=af414ad8-9936-46cd-b074-528854656fcd\", \"splash\": true &#125;, \"ansible_date_time\": &#123; \"date\": \"2016-06-16\", \"day\": \"16\", \"epoch\": \"1466049222\", \"hour\": \"11\", \"iso8601\": \"2016-06-16T03:53:42Z\", \"iso8601_basic\": \"20160616T115342839628\", \"iso8601_basic_short\": \"20160616T115342\", \"iso8601_micro\": \"2016-06-16T03:53:42.839785Z\", \"minute\": \"53\", \"month\": \"06\", \"second\": \"42\", \"time\": \"11:53:42\", \"tz\": \"CST\", \"tz_offset\": \"+0800\", \"weekday\": \"Thursday\", \"weekday_number\": \"4\", \"weeknumber\": \"24\", \"year\": \"2016\" &#125;, \"ansible_default_ipv4\": &#123; \"address\": \"120.26.45.230\", ..... ..... .....(省略 N 行) 使用filter查看指定信息： 1234567891011121314151617181920212223242526root@sate-z:~# ansible sate -m setup -a \"filter=ansible_date_time\"10.117.214.178 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"ansible_date_time\": &#123; \"date\": \"2016-06-16\", \"day\": \"16\", \"epoch\": \"1466049323\", \"hour\": \"11\", \"iso8601\": \"2016-06-16T03:55:23Z\", \"iso8601_basic\": \"20160616T115523414703\", \"iso8601_basic_short\": \"20160616T115523\", \"iso8601_micro\": \"2016-06-16T03:55:23.414901Z\", \"minute\": \"55\", \"month\": \"06\", \"second\": \"23\", \"time\": \"11:55:23\", \"tz\": \"CST\", \"tz_offset\": \"+0800\", \"weekday\": \"Thursday\", \"weekday_number\": \"4\", \"weeknumber\": \"24\", \"year\": \"2016\" &#125; &#125;, \"changed\": false&#125; facts 默认收集了很多的设备基础信息，这些信息可以在做配置管理的时候引用。可以直接把 facts 信息直接当做 playbook 变量信息引用。比如后边的 nginx的 playbook 的练习中，nginx.conf.j2这个模板配置文件中的worker_processes这个参数的取值就是用该方法获得的。 1234$ cat nginx.conf.j2| head -n 3user www-data;worker_processes &#123;&#123; ansible_processor_cores &#125;&#125;;pid /run/nginx.pid;","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/tags/Ansible/"}]},{"title":"Ansible的Inventory","slug":"Ansible的Inventory","date":"2016-12-15T07:25:42.000Z","updated":"2016-12-15T07:27:03.000Z","comments":true,"path":"2016/12/15/Ansible的Inventory/","link":"","permalink":"http://yoursite.com/2016/12/15/Ansible的Inventory/","excerpt":"","text":"单个Inventory文件的使用： 我们用 ansible 来管理的机器信息都放在 Inventory 文件中，默认的 Inventory 是一个静态的 INI 格式的文件 /etc/ansible/hosts。 我们可以通过 ANSIBLE_HOSTS 环境变量来制定该文件，或者在运行 ansible 和 ansible-playbook 的时候用-i参数临时设置。 常用的定义主机和主机组的方式： 123456789101112131415# 定义了两个主机，使用 Inventory 内置变量定义了 SSH 登录时的密码192.168.0.1 ansible_ssh_pass='123456'192.168.0.2 ansible_ssh_pass='123456'# 定义了一个 sate 组，并且组中 IP 为192.168.0.101-192.168.0.103 三台机器[sate]192.168.0.10[1:3]# 对上边的 sate 组使用 Inventory 内置变量定义了 SSH 登录密码[sate:vars]ansible_ssh_pass='123456'# 定义了一个 ansible 组，这个组下面包含 docker 组。[ansible:children]sate 多个Inventory文件： Ansible 支持多个 Inventory 文件，我们可以修改ansible.cfg文件，如下，或者使用ANSIBLE_HOSTS环境变量定义。 12# 修改 ansible.cfg 中 inventory 的值inventory = /etc/inventory/ 这样我们可以在/etc/inventory/目录下放入多个 Inventory 文件 动态Inventory文件： 可能在实际情况下会有大量的主机列表，手动维护比较困难。动态 Inventory 就是 Ansible 所有的 Inventory 文件里边的主机列表和变量信息都支持从外部拉取,比如 CMDB 系统或者 zabbix 系统。配置的时候我们需要将ansible.cfg文件中的inventory的定义值改成一个执行脚本。 执行脚本没有编程语言上种类的限制，但是脚本必须支持两个参数，如下： --list或者-l,这个参数运行后会显示所有的主机以及主机组的信息 --host或者-H，这个参数后面需要指定一个 host，运行结果会返回这台主机的所有信息（包括认证信息、主机变量等），也是 JSON 格式。 常用的 Inventory 内置参数参数 | 解释 | 例子 —————- |—————–|———————————–|ansible_ssh_host| 定义 host ssh 地址 |ansible_ssh_host=192.168.0.1 |ansible_ssh_port| 定义 hosts ssh 端口| ~ =5000ansible_ssh_user| 定义 ssh 认证用户 | ~ =sateansible_ssh_pass| 定义 ssh 认证密码 | ~ =’password’ansible_sudo | 定义 sudo 用户 | ~ =sateansible_sudo_pass| 定义 sudo 密码| ~ =’password’ansible_sudo_exe|定义 sudo 路径| ~ =/usr/bin/sudoansible_connection|定义 hosts 连接方式| ~ =localansible_ssh_private_key_file|定义 hosts 私钥|~ =/root/keyansible_shell_type|定义 shell 类型|~ =zshansible_pythoninterpreter| 定义 执行 python 路径|~ =/usr/bin/python2.7ansible\\*_interpreter|定义其他语言解析器路径|~ =/usr/bin/ruby","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/tags/Ansible/"}]},{"title":"Ansible的playbook","slug":"Ansible的playbook","date":"2016-12-15T07:22:15.000Z","updated":"2016-12-16T03:27:13.000Z","comments":true,"path":"2016/12/15/Ansible的playbook/","link":"","permalink":"http://yoursite.com/2016/12/15/Ansible的playbook/","excerpt":"","text":"案例： 部署 nginx 服务。 Inventory hosts 文件 1234[sate]192.168.0.1[sate:vars]ansible_python_interpreter=/usr/bin/python2.7 nginx.conf.j2 模板文件 1234$ cat nginx.conf.j2| head -n 3user www-data;worker_processes &#123;&#123; ansible_processor_cores &#125;&#125;;pid /run/nginx.pid; 部署nignx的 playbook 1234567891011121314---- hosts: sate tasks: - name: install nginx apt: name=nginx state=present - name: copy nginx.conf template: src=./nginx.conf.j2 dest=/etc/nginx/nginx.conf owner=root group=root mode=0644 validate='nginx -t -c %s' notify: - restart nginx handlers: - name : restart nginx service: name=nginx state=restarted 检查语法 1$ ansible-playbook nginx.yaml --syntax-check","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/categories/Ansible/"}],"tags":[{"name":"Anisble","slug":"Anisble","permalink":"http://yoursite.com/tags/Anisble/"}]},{"title":"Ansible简单使用","slug":"Ansible简单使用","date":"2016-12-15T07:20:43.000Z","updated":"2016-12-15T07:21:42.000Z","comments":true,"path":"2016/12/15/Ansible简单使用/","link":"","permalink":"http://yoursite.com/2016/12/15/Ansible简单使用/","excerpt":"","text":"介绍Ansible是新出现的运维工具是基于Python研发的，糅合了众多老牌运维工具的优点实现了批量操作系统配置、批量程序的部署、批量运行命令等功能。 安装实验环境： 12 系统：centos 6.5 机器：node1（192.168.174.128），node2（192.168.174.129） 安装： 1[root@node1 ~]# yum -y install ansible 基本使用定义Host Inventory ： 123[root@node1 ~]# cat /etc/ansible/hosts[node]192.168.174.129 操作实例： 12345[root@node1 ~]# ansible -i /etc/ansible/hosts nodetest -m command -a 'date'192.168.174.129 | success | rc=0 &gt;&gt;Mon Oct 12 13:23:56 CST 2015注：-i 使用默认hosts，该参数可以省略该命令执行成功的前提是先通过ssh-copy-id同步ssh key认证。如果没有，则需要加-k参数（需要安装sshpass）。 命令常用参数 123456789101112-m 导入模块-i 指定host-u 指定远程用户-s 使用sudo-k 询问密码例：$ ansible -i /xx/hosts wx-test -m ping -u zyadmin -s -kSSH password:xxx.xxx.xxx.x | success &gt;&gt; &#123;\"changed\": false,\"ping\": \"pong\"&#125; 如果客户端服务器的端口和用户名不为默认的22和root，也可以在hosts这样写： 12345[group name]wx-sate1 ansible_ssh_host=xxx.xx.xxx.x ansible_ssh_port=3544 ansible_ssh_user=satewx-sate2 ansible_ssh_host=xx.xxx.xx.xx ansible_ssh_port=4002 ansible_ssh_user=zyadmin例：$ ansible -i /xx/hosts wx-sate1 -m ping","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/tags/Ansible/"}]},{"title":"Ansible安装","slug":"Ansible安装","date":"2016-12-15T07:18:57.000Z","updated":"2016-12-15T07:20:10.000Z","comments":true,"path":"2016/12/15/Ansible安装/","link":"","permalink":"http://yoursite.com/2016/12/15/Ansible安装/","excerpt":"","text":"分两大类，源码安装和用包管理安装 源码安装一、 从GitHub 源码库安装 1、提取 ansible 源码 123$ git clone git@github.com:ansible/ansible.git --recursive$ cd ./ansible$ source ./hacking/env-setup -q #-q 参数可以减少安装过程中的告警/错误信息输出 2、安装对应python版本的pip 1$ sudo easy_install pip 3、安装ansible 控制主机需要的Python模板 1$ sudo pip install paramiko PyYAML Jinja2 httplib2 six 4、当更新Ansible 版本时，不但要更新git源码树，还要更新git中指向ansible 自身的模块，称为 submodules 12$ git pull --rebase$ git submodule update --init --recursive 5、一旦运行env-setup 脚本，就意味着ansible从源码中运行起来了。 二、Tar 包安装方式 可以在Http://release.ansible.com/ansible 中下载 Tar 包，安装过程和上边源码安装方式一样。 三、制作RPM 包安装 在 github 中提取代码或者直接下载 tar 包，使用 make rpm 命令创建 RPM 软件包。不过确保已经安装了 rpm-bulid、make、python2-devel 组件。 1234$ git clone git@github.com:ansible/ansible.git$ cd ./ansible$ make rpm$ sudo rpm -Uvh ~ /rpmbulid/ansible-*.noarch.rpm 用包管理工具安装（方便）一、yum 方式安装 对于 RHEL、CentOS 的官方 yum 源中没有 ansible 包，或者比较老旧,所以先安装支持第三方的 yum 仓库组件，最常用的有 EPEL、Remi、RPMForge 等。 下面安装 EPEL 作为部署 ansible 的默认 yum 源。 12345678910# RHEL(CentOS)5rpm -Uvh http://mirrors.zju.edu.cn/epel/5/i386/epel-release-5-4.noarch.rpmrpm -Uvh http://mirrors.zju.edu.cn/epel/5/x86_64/epel-release-5-4.noarch.rpm# RHEL(CentOS)6rpm -Uvh http://mirrors.zju.edu.cn/epel/6/i386/epel-release-6-8.noarch.rpmrpm -Uvh http://mirrors.zju.edu.cn/epel/6/x86_64/epel-release-6-8.noarch.rpm# RHEL(CentOS)7rpm -Uvh http://mirrors.zju.edu.cn/epel/7/x86_64/e/epel-release-7-6.noarch.rpm 准备好 yum 源后，直接 yum 安装 1$ yum install ansible 二、Apt（Ubuntu）方式安装 1234$ apt-get install software-properties-common$ apt-add-repository ppa:ansible/ansible$ apt-get update$ apt-get install ansible 三、Homebrew（Mac OSX）安装方式 在 MAC 系统确保安装 Homebrew，直接使用下面命令安装： 12$ brew update$ brew install Ansible 四、pip 方式安装 12$ sudo easy_install pip$ sudo pip install ansible","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/tags/Ansible/"}]},{"title":"Linux客户端连接(PPTP)VPN","slug":"PPTP客户端","date":"2016-12-15T06:58:37.000Z","updated":"2016-12-15T07:09:09.000Z","comments":true,"path":"2016/12/15/PPTP客户端/","link":"","permalink":"http://yoursite.com/2016/12/15/PPTP客户端/","excerpt":"","text":"环境 Ubuntu 12.04.4pptp version 1.7.2 安装1apt-get install pptp-linux 创建连接帐号1sudo pptpsetup --create myvpn --server xxx.xxx.xxx.xxx --username xxx --password xxxxx --encrypt 连接VPN12345678#打开vpnpon myvpn#查看当前路由规则route#删除老的defaultroute del default#创建新的路由规则route add default gw 192.168.250.1 pon myvpn成功时会生成ppp0： 关闭VPN12345678#关闭vpnpoff myvpn#查看当前路由规则route#删除刚加的default规则（关闭vpn时，刚加的默认路由已经删除，此步可忽略）route del default#还原以前的路由规则route add default gw 121.197.7.254","categories":[{"name":"Linux工具","slug":"Linux工具","permalink":"http://yoursite.com/categories/Linux工具/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"VPN","slug":"VPN","permalink":"http://yoursite.com/tags/VPN/"}]},{"title":"Tcpdump命令使用","slug":"Tcpdump命令使用","date":"2016-12-15T06:55:55.000Z","updated":"2016-12-15T07:11:41.000Z","comments":true,"path":"2016/12/15/Tcpdump命令使用/","link":"","permalink":"http://yoursite.com/2016/12/15/Tcpdump命令使用/","excerpt":"","text":"tcpdump命令是一款sniffer工具，它可以打印所有经过网络接口的数据包的头信息，也可以使用-w选项将数据包保存到文件中，方便以后分析。 语法1tcpdump(选项) 选项12345678910111213141516171819202122232425-a：尝试将网络和广播地址转换成名称；-c&lt;数据包数目&gt;：收到指定的数据包数目后，就停止进行倾倒操作；-d：把编译过的数据包编码转换成可阅读的格式，并倾倒到标准输出；-dd：把编译过的数据包编码转换成C语言的格式，并倾倒到标准输出；-ddd：把编译过的数据包编码转换成十进制数字的格式，并倾倒到标准输出；-e：在每列倾倒资料上显示连接层级的文件头；-f：用数字显示网际网络地址；-F&lt;表达文件&gt;：指定内含表达方式的文件；-i&lt;网络界面&gt;：使用指定的网络截面送出数据包；-l：使用标准输出列的缓冲区；-n：不把主机的网络地址转换成名字；-N：不列出域名；-O：不将数据包编码最佳化；-p：不让网络界面进入混杂模式；-q ：快速输出，仅列出少数的传输协议信息；-r&lt;数据包文件&gt;：从指定的文件读取数据包数据；-s&lt;数据包大小&gt;：设置每个数据包的大小；-S：用绝对而非相对数值列出TCP关联数；-t：在每列倾倒资料上不显示时间戳记；-tt： 在每列倾倒资料上显示未经格式化的时间戳记；-T&lt;数据包类型&gt;：强制将表达方式所指定的数据包转译成设置的数据包类型；-v：详细显示指令执行过程；-vv：更详细显示指令执行过程；-x：用十六进制字码列出数据包资料；-w&lt;数据包文件&gt;：把数据包数据写入指定的文件。 实例直接启动tcpdump将监视第一个网络接口上所有流过的数据包 1tcpdump 监视指定网络接口的数据包 1tcpdump -i eth1 如果不指定网卡，默认tcpdump只会监视第一个网络接口，一般是eth0，下面的例子都没有指定网络接口。 监视指定主机的数据包 打印所有进入或离开sundown的数据包。 1tcpdump host sundown 也可以指定ip,例如截获所有210.27.48.1 的主机收到的和发出的所有的数据包 1tcpdump host 210.27.48.1 打印helios 与 hot 或者与 ace 之间通信的数据包 123tcpdump host helios and \\( hot or ace \\)``` - 截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信 tcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 )1- 打印ace与任何其他主机之间通信的IP 数据包, 但不包括与helios之间的数据包. tcpdump ip host ace and not helios1- 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令： tcpdump ip host 210.27.48.1 and ! 210.27.48.21- 截获主机hostname发送的所有数据 tcpdump -i eth0 src host hostname1- 监视所有送到主机hostname的数据包 tcpdump -i eth0 dst host hostname123** 监视指定主机和端口的数据包**- 如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令 tcpdump tcp port 23 host 210.27.48.11- 对本机的udp 123 端口进行监视 123 为ntp的服务端口 tcpdump udp port 123123** 监视指定网络的数据包**- 打印本地主机与Berkeley网络上的主机之间的所有通信数据包 tcpdump net ucb-ether123 ucb-ether此处可理解为“Berkeley网络”的网络地址，此表达式最原始的含义可表达为：打印网络地址为ucb-ether的所有数据包- 打印所有通过网关snup的ftp数据包 tcpdump ‘gateway snup and (port ftp or ftp-data)’123 注意：表达式被单引号括起来了，这可以防止shell对其中的括号进行错误解析- 打印所有源地址或目标地址是本地主机的IP数据包 tcpdump ip and not net localnet``` 如果本地网络通过网关连到了另一网络，则另一网络并不能算作本地网络。","categories":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://yoursite.com/categories/Linux命令/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"Tcpdump","slug":"Tcpdump","permalink":"http://yoursite.com/tags/Tcpdump/"}]},{"title":"Strace命令分析","slug":"Strace命令分析","date":"2016-12-15T06:52:07.000Z","updated":"2016-12-15T07:11:17.000Z","comments":true,"path":"2016/12/15/Strace命令分析/","link":"","permalink":"http://yoursite.com/2016/12/15/Strace命令分析/","excerpt":"","text":"strace是个很好用的诊断手段，该文章整合了自己查找的比较好的网络资料和一些自己的理解，作为记录和学习。借鉴网址：http://man.linuxde.net/strace Strace命令是个集诊断、调试、统计与一体的工具，我们可以使用strace对应用的系统调用和信号传递的跟踪结果来对应用进行分析，以达到解决问题或者是了解应用工作过程的目的。语法&amp;释义： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@node2 ~]# strace -husage: strace [-dDffhiqrtttTvVxx] [-a column] [-e expr] ... [-o file] [-p pid] ... [-s strsize] [-u username] [-E var=val] ... [command [arg ...]] or: strace -c [-D] [-e expr] ... [-O overhead] [-S sortby] [-E var=val] ... [command [arg ...]]-c -- count time, calls, and errors for each syscall and report summary 统计每一系统调用的所执行的时间,次数和出错的次数等.-f -- follow forks, -ff -- with output into separate files -f 跟踪由fork产生的子进程 -ff 常与-o选项一起使用，不同进程(子进程)产生的系统调用输出到filename.PI,D文件如果提供-o filename,则所有进程的跟踪结果输出到相应的filename.pid中,pid是各进程的进程号.-F -- attempt to follow vforks, -h -- print help message 尝试跟踪vfork调用。在-f时，vfork不被跟踪-i -- print instruction pointer at time of syscall 输出系统调用的入口指针-q -- suppress messages about attaching, detaching, etc. 禁止输出关于脱离的消息-r -- print relative timestamp 打印每个系统调用的相对时间 -t -- absolute timestamp, -tt -- with usecs 在输出中的每一行前加上时间信息 -tt 时间确定到微秒级-T -- print time spent in each syscall, -V -- print version 显示每个调用的花费时间-v -- verbose mode: print unabbreviated argv, stat, termio[s], etc. args 输出所有的系统调用.一些调用关于环境变量,状态,输入输出等调用由于使用频繁,默认不输出.-x -- print non-ascii strings in hex, -xx -- print all strings in hex 以十六进制形式输出非标准字符串 -xx 所有字符串以十六进制形式输出-a column -- alignment COLUMN for printing syscall results (default 40) 设置返回值的输出位置.默认 为40.-e expr -- a qualifying expression: option=[!]all or option=[!]val1[,val2]... options: trace, abbrev, verbose, raw, signal, read, or write -e expr 指定一个表达式,用来控制如何跟踪.格式：[qualifier=][!]value1[,value2]... qualifier只能是 trace,abbrev,verbose,raw,signal,read,write其中之一.value是用来限定的符号或数字.默认的 qualifier是 trace.感叹号是否定符号.例如:-eopen等价于 -e trace=open,表示只跟踪open调用.而-etrace!=open 表示跟踪除了open以外的其他调用.有两个特殊的符号 all 和 none. 注意有些shell使用!来执行历史记录里的命令,所以要使用\\\\. -e trace=set 只跟踪指定的系统 调用.例如:-e trace=open,close,rean,write表示只跟踪这四个系统调用.默认的为set=all. -e trace=file 只跟踪有关文件操作的系统调用. -e trace=process 只跟踪有关进程控制的系统调用. -e trace=network 跟踪与网络有关的所有系统调用. -e strace=signal 跟踪所有与系统信号有关的 系统调用 -e trace=ipc 跟踪所有与进程通讯有关的系统调用 -e abbrev=set 设定strace输出的系统调用的结果集.-v 等与 abbrev=none.默认为abbrev=all. -e raw=set 将指定的系统调用的参数以十六进制显示. -e signal=set 指定跟踪的系统信号.默认为all.如 signal=!SIGIO(或者signal=!io),表示不跟踪SIGIO信号. -e read=set 输出从指定文件中读出 的数据.例如: -e read=3,5 -e write=set 输出写入到指定文件中的数据.-o file -- send trace output to FILE instead of stderr 将strace的输出写入文件filename-O overhead -- set overhead for tracing syscalls to OVERHEAD usecs-p pid -- trace process with process id PID, may be repeated 跟踪指定的进程pid.-D -- run tracer process as a detached grandchild, not as parent-s strsize -- limit length of print strings to STRSIZE chars (default 32) 指定输出的字符串的最大长度.默认为32.文件名一直全部输出-S sortby -- sort syscall counts by: time, calls, name, nothing (default time)-u username -- run command as username handling setuid and/or setgid 以username的UID和GID执行被跟踪的命令-E var=val -- put var=val in the environment for command-E var -- remove var from the environment for command","categories":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://yoursite.com/categories/Linux命令/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"Strace","slug":"Strace","permalink":"http://yoursite.com/tags/Strace/"}]},{"title":"SSH代理登录服务器","slug":"SSH代理登录","date":"2016-12-15T06:47:59.000Z","updated":"2016-12-15T07:10:33.000Z","comments":true,"path":"2016/12/15/SSH代理登录/","link":"","permalink":"http://yoursite.com/2016/12/15/SSH代理登录/","excerpt":"","text":"ssh 代理登录服务器场景： 1234A机器：10.0.0.1B机器：10.0.0.2C机器：10.0.0.3D机器：10.0.0.4 现在我们在A机器上，要登陆D机器，必须要经过B、C两台跳板机，一台台的登陆太复杂，而且如果要传文件的话，那要一层层的传，我们现在要求是在A机器上直接登陆到D机器。 一：使用ProxyCommand编辑.ssh/config文件 12345678Host machineB HostName 10.0.0.2Host machineC ProxyCommand ssh -q machineB nc 10.0.0.3 22Host machineD ProxyCommand ssh -q machineC nc 10.0.0.4 22 登陆D机器时， 直接ssh machineD。注：登陆时，可能要输入BCD机器的密码，可以事先打通key。 二：使用ssh端口转发命令在B机器上 1ssh -CfgNL 2222:10.0.0.3:222 localhost 在C机器上 1ssh -CfgNL 222:10.0.0.4:22 localhost 连接D机器是，连接B机器的2222端口即可： 1ssh -p 2222 10.0.0.2","categories":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://yoursite.com/categories/Linux命令/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"ssh","slug":"ssh","permalink":"http://yoursite.com/tags/ssh/"}]},{"title":"Logrotate安装配置","slug":"Logrotate安装配置","date":"2016-12-15T06:35:43.000Z","updated":"2016-12-15T07:13:36.000Z","comments":true,"path":"2016/12/15/Logrotate安装配置/","link":"","permalink":"http://yoursite.com/2016/12/15/Logrotate安装配置/","excerpt":"","text":"原文链接：https://linux.cn/article-4126-1.html logrotate是个十分有用的工具，它可以自动对日志进行截断（或轮循）、压缩以及删除旧的日志文件。 安装logrotate安装非常简单。yum或apt-get安装即可。 1yum -y install logrotate 配置文件目录：/etc/logrotate.conf ，通常不需要对它进行修改。日志文件的轮循设置在独立的配置文件中，它（们）放在/etc/logrotate.d/目录下 配置以下给出三个配置文件的实例： 示例一创建一个log文件进行测试 123touch /var/log/test.loghead -c 20M &lt; /dev/urandom &gt; /var/log/test.log#填入一个20MB的随机比特流数据 创建配置文件/etc/logrotate.d/test.conf，并写入： 123456789101112131415161718192021/var/log/test.log&#123;monthlyrotate 5compressdelaycompressmissingoknotifemptycreate 644 root rootpostrotate /usr/bin/killall -HUP rsyslogdendscript&#125;#注释：#monthly: 日志文件将按月轮循。其它可用值为‘daily’，‘weekly’或者‘yearly’。#rotate 5: 一次将存储5个归档日志。对于第六个归档，时间最久的归档将被删除。#compress: 在轮循任务完成后，已轮循的归档将使用gzip进行压缩。#delaycompress: 总是与compress选项一起用，delaycompress选项指示logrotate不要将最近的归档压缩，压缩将在#下一次轮循周期进行。这在你或任何软件仍然需要读取最新归档时很有用。#missingok: 在日志轮循期间，任何错误将被忽略，例如“文件无法找到”之类的错误。#notifempty: 如果日志文件为空，轮循不会进行。#create 644 root root: 以指定的权限创建全新的日志文件，同时logrotate也会重命名原始日志文件。#postrotate/endscript: 在所有其它指令完成后，postrotate和endscript里面指定的命令将被执行。在这种情况下，#rsyslogd 进程将立即再次读取其配置并继续运行。 示例二我们只想要轮循一个日志文件，然而日志文件大小可以增长到50MB。 123456789#/etc/logrotate.d/test.conf 写入：/var/log/log-file &#123; size=50M rotate 5 create 644 root root postrotate /usr/bin/killall -HUP rsyslogd endscript&#125; 示例三我们想要让旧日志文件以创建日期命名，这可以通过添加dateext常熟实现。 12345678910#/etc/logrotate.d/test.conf 写入：/var/log/log-file &#123; monthly rotate 5 dateext create 644 root root postrotate /usr/bin/killall -HUP rsyslogd endscript&#125; 这将让归档文件在它们的文件名中包含日期信息。 测试logrotate可以在任何时候从命令行手动调用。要调用为/etc/lograte.d/下配置的所有日志调用logrotate： 123[root@node2 ~]# ls /etc/logrotate.d/dracut redis salt syslog test.conf vsftpd yum[root@node2 ~]# logrotate /etc/logrotate.conf 要为某个特定的配置调用logrotate： 1[root@node2 ~]# logrotate /etc/logrotate.d/test.conf 预演方式运行使用‘-d’选项以预演方式运行logrotate。要进行验证，不用实际轮循任何日志文件，可以模拟演练日志轮循并显示其输出。 1234567891011[root@node2 ~]# logrotate -d /etc/logrotate.d/test.conf reading config file /etc/logrotate.d/test.confreading config info for /var/log/test.logHandling 1 logsrotating pattern: /var/log/test.log monthly (5 rotations)empty log files are not rotated, old logs are removedconsidering log /var/log/test.log log does not need rotatingnot running postrotate script, since no logs were rotated 正如我们从上面的输出结果可以看到的，logrotate判断该轮循是不必要的。 强制方式运行 123456789101112131415161718[root@node2 bin]# logrotate -vf /etc/logrotate.d/test.conf reading config file /etc/logrotate.d/test.confreading config info for /var/log/test.logHandling 1 logsrotating pattern: /var/log/test.log forced from command line (5 rotations)empty log files are not rotated, old logs are removedconsidering log /var/log/test.log log needs rotatingrotating log /var/log/test.log, log-&gt;rotateCount is 5dateext suffix '-20150923'glob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'glob finding logs to compress failedglob finding old rotated logs failedrenaming /var/log/test.log to /var/log/test.log-20150923creating new /var/log/test.log mode = 0644 uid = 0 gid = 0running postrotate script 之后配置crontab进行定时处理。","categories":[{"name":"Linux工具","slug":"Linux工具","permalink":"http://yoursite.com/categories/Linux工具/"}],"tags":[{"name":"Logrotate","slug":"Logrotate","permalink":"http://yoursite.com/tags/Logrotate/"},{"name":"Log","slug":"Log","permalink":"http://yoursite.com/tags/Log/"}]},{"title":"Linux_inode_100%问题","slug":"Linux-inode-100-问题","date":"2016-12-15T06:31:02.000Z","updated":"2016-12-15T07:07:17.000Z","comments":true,"path":"2016/12/15/Linux-inode-100-问题/","link":"","permalink":"http://yoursite.com/2016/12/15/Linux-inode-100-问题/","excerpt":"","text":"查看系统的 innode 占用情况1df -ih 查找那个目录下文件最多12for i in /*; do echo $i; find $i | wc -l; done# find $i 会列出该目录下所有文件，然后wc -l 计算总和 删除那个目录的的所有文件一般情况下，如果这个目录下应该会有数以百万的文件，如果你直接用 rm -rf 目录名 的话效率会很低，可以用下面方法,最好开一个 screen 来处理 ```find 目录 -type f -name ‘*’ -print0 | xargs -0 rm","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"inode","slug":"inode","permalink":"http://yoursite.com/tags/inode/"}]},{"title":"Linux_inodes","slug":"Linux-inodes","date":"2016-12-15T06:18:23.000Z","updated":"2016-12-15T10:28:56.000Z","comments":true,"path":"2016/12/15/Linux-inodes/","link":"","permalink":"http://yoursite.com/2016/12/15/Linux-inodes/","excerpt":"","text":"一、inode是什么？理解inode，要从文件储存说起。 文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。 操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个sector组成一个 block。 文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。 每一个文件都有对应的inode，里面包含了与该文件有关的一些信息。 二、inode的内容inode包含文件的元信息，具体来说有以下内容： 1234567* 文件的字节数 * 文件拥有者的User ID * 文件的Group ID * 文件的读、写、执行权限 * 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。 * 链接数，即有多少文件名指向这个inode * 文件数据block的位置 可以用stat命令，查看某个文件的inode信息： 123456789$ stat sina.html File: ‘sina.html’ Size: 590188 Blocks: 1160 IO Block: 4096 regular fileDevice: ca01h/51713d Inode: 921437 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2016-08-03 18:08:50.961342023 +0800Modify: 2016-08-01 11:11:43.600409902 +0800Change: 2016-08-01 11:11:43.600409902 +0800 Birth: - 三、inode的大小inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。 每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。 查看每个硬盘分区的inode总数和已经使用的数量，可以使用df -i命令。 123456789$ df -iFilesystem Inodes IUsed IFree IUse% Mounted on/dev/xvda1 2621440 295029 2326411 12% /none 127041 11 127030 1% /sys/fs/cgroupudev 124329 424 123905 1% /devtmpfs 127041 338 126703 1% /runnone 127041 3 127038 1% /run/locknone 127041 1 127040 1% /run/shmnone 127041 2 127039 1% /run/user 查看每个inode节点的大小，可以用如下命令 123$ sudo dumpe2fs -h /dev/xvda1 | grep \"Inode size\"dumpe2fs 1.42.9 (4-Feb-2014)Inode size: 256 由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。 四、inode号码每个inode都有一个号码，操作系统用inode号码来识别不同的文件。 这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。 表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。使用ls -i命令，可以看到文件名对应的inode号码： 12$ ls -i sina.html921437 sina.html 五、目录文件Unix/Linux系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。 ls -i命令列出整个目录文件，即文件名和inode号码： 12$ ls -i /mnt/919572 a.py 919588 b.py 919592 kong1 919591 kong2 919546 passwd 理解了上面这些知识，就能理解目录的权限。目录文件的读权限（r）和写权限（w），都是针对目录文件本身。由于目录文件内只有文件名和inode号码，所以如果只有读权限，只能获取文件名，无法获取其他信息，因为其他信息都储存在inode节点中，而读取inode节点内的信息需要目录文件的执行权限（x）。 六、硬链接一般情况下，文件名和inode号码是”一一对应”关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。 这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为”硬链接”（hard link）。 ln命令可以创建硬链接： 12345678910111213141516171819ln 源文件 目标文件$ touch testa$ ln testa testb$ ll -i test*919070 -rw-r--r-- 2 root root 0 Aug 4 09:49 testa919070 -rw-r--r-- 2 root root 0 Aug 4 09:49 testb# 一些更改操作,更改操作会同时更改两个文件，删除其中一个，不会影响到另一个$ echo aa &gt; testa$ cat testbaa$ echo bb &gt; testb$ cat testabb$ rm -rf testa$ lsa.py b.py kong1 kong2 passwd testb testv$ cat testbbb 运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做”链接数”，记录指向该inode的文件名总数，这时就会增加1。 反过来，删除一个文件名，就会使得inode节点中的”链接数”减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。这里顺便说一下目录文件的”链接数”。创建目录时，默认会生成两个目录项：”.”和”..”。前者的inode号码就是当前目录的inode号码，等同于当前目录的”硬链接”；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的”硬链接”。所以，任何一个目录的”硬链接”总数，总是等于2加上它的子目录总数（含隐藏目录）。 七、软链接文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的”软链接”（soft link）或者”符号链接（symbolic link）。这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：&quot;No such file or directory&quot;。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode“链接数”不会因此发生变化。 1$ ln -s 源文文件或目录 目标文件或目录 八、inode的特殊作用由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。 1. 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。 2. 移动文件或重命名文件，只是改变文件名，不影响inode号码。 3. 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。 第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。","categories":[{"name":"Linux系统","slug":"Linux系统","permalink":"http://yoursite.com/categories/Linux系统/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"inode","slug":"inode","permalink":"http://yoursite.com/tags/inode/"}]},{"title":"Python_递归","slug":"Python-递归","date":"2016-12-15T03:10:37.000Z","updated":"2016-12-15T10:29:09.000Z","comments":true,"path":"2016/12/15/Python-递归/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-递归/","excerpt":"","text":"递归：函数对自身定义的引用。 每次函数调用时，针对这个调用的新命名空间会被创建，意味着当函数调用“自身”时，实际上运行的是两个不同的函数（或者说同一个函数具有两个不同的命名空间）。 阶乘计算数 n 的阶乘(n * (n-1) * (n-2) .. * 1)： 1234567891011121314# for 循环实现def fac(n): result = n for i in range(1, n): result *= i return result # 递归实现def fac(n):def rec_fac(n): if n == 1: return n else: return n * rec_fac(n - 1) 二分法12345678910111213def search(sequence, number, lower=0, upper=None): if upper is None: upper = len(sequence) - 1 if lower == upper: assert number == sequence[upper] return upper else: middle = (lower + upper)//2 if number &gt; sequence[middle]: return search(sequence, number, middle+1, upper) else: return search(sequence, number, lower, middle) 查找目录下的所有文件123456def Test(rootDir): for lists in os.listdir(rootDir): path = os.path.join(rootDir, lists) print path if os.path.isdir(path): Test(path)","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"},{"name":"递归","slug":"递归","permalink":"http://yoursite.com/tags/递归/"}]}]}