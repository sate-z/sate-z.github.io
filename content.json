{"meta":{"title":"SateZheng","subtitle":"多读书，多看报，少吃零食，多睡觉","description":null,"author":"SateZheng","url":"http://yoursite.com"},"pages":[{"title":"","date":"2016-12-15T05:18:23.000Z","updated":"2016-12-15T05:47:06.000Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"作者： SateZheng简书地址：传送"}],"posts":[{"title":"Linux客户端连接(PPTP)VPN","slug":"PPTP客户端","date":"2016-12-15T06:58:37.000Z","updated":"2016-12-15T07:09:09.000Z","comments":true,"path":"2016/12/15/PPTP客户端/","link":"","permalink":"http://yoursite.com/2016/12/15/PPTP客户端/","excerpt":"","text":"环境 Ubuntu 12.04.4pptp version 1.7.2 安装1apt-get install pptp-linux 创建连接帐号1sudo pptpsetup --create myvpn --server xxx.xxx.xxx.xxx --username xxx --password xxxxx --encrypt 连接VPN12345678#打开vpnpon myvpn#查看当前路由规则route#删除老的defaultroute del default#创建新的路由规则route add default gw 192.168.250.1 pon myvpn成功时会生成ppp0： 关闭VPN12345678#关闭vpnpoff myvpn#查看当前路由规则route#删除刚加的default规则（关闭vpn时，刚加的默认路由已经删除，此步可忽略）route del default#还原以前的路由规则route add default gw 121.197.7.254","categories":[{"name":"Linux工具","slug":"Linux工具","permalink":"http://yoursite.com/categories/Linux工具/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"VPN","slug":"VPN","permalink":"http://yoursite.com/tags/VPN/"}]},{"title":"Tcpdump命令使用","slug":"Tcpdump命令使用","date":"2016-12-15T06:55:55.000Z","updated":"2016-12-15T07:11:41.000Z","comments":true,"path":"2016/12/15/Tcpdump命令使用/","link":"","permalink":"http://yoursite.com/2016/12/15/Tcpdump命令使用/","excerpt":"","text":"tcpdump命令是一款sniffer工具，它可以打印所有经过网络接口的数据包的头信息，也可以使用-w选项将数据包保存到文件中，方便以后分析。 语法1tcpdump(选项) 选项12345678910111213141516171819202122232425-a：尝试将网络和广播地址转换成名称；-c&lt;数据包数目&gt;：收到指定的数据包数目后，就停止进行倾倒操作；-d：把编译过的数据包编码转换成可阅读的格式，并倾倒到标准输出；-dd：把编译过的数据包编码转换成C语言的格式，并倾倒到标准输出；-ddd：把编译过的数据包编码转换成十进制数字的格式，并倾倒到标准输出；-e：在每列倾倒资料上显示连接层级的文件头；-f：用数字显示网际网络地址；-F&lt;表达文件&gt;：指定内含表达方式的文件；-i&lt;网络界面&gt;：使用指定的网络截面送出数据包；-l：使用标准输出列的缓冲区；-n：不把主机的网络地址转换成名字；-N：不列出域名；-O：不将数据包编码最佳化；-p：不让网络界面进入混杂模式；-q ：快速输出，仅列出少数的传输协议信息；-r&lt;数据包文件&gt;：从指定的文件读取数据包数据；-s&lt;数据包大小&gt;：设置每个数据包的大小；-S：用绝对而非相对数值列出TCP关联数；-t：在每列倾倒资料上不显示时间戳记；-tt： 在每列倾倒资料上显示未经格式化的时间戳记；-T&lt;数据包类型&gt;：强制将表达方式所指定的数据包转译成设置的数据包类型；-v：详细显示指令执行过程；-vv：更详细显示指令执行过程；-x：用十六进制字码列出数据包资料；-w&lt;数据包文件&gt;：把数据包数据写入指定的文件。 实例直接启动tcpdump将监视第一个网络接口上所有流过的数据包 1tcpdump 监视指定网络接口的数据包 1tcpdump -i eth1 如果不指定网卡，默认tcpdump只会监视第一个网络接口，一般是eth0，下面的例子都没有指定网络接口。 监视指定主机的数据包 打印所有进入或离开sundown的数据包。 1tcpdump host sundown 也可以指定ip,例如截获所有210.27.48.1 的主机收到的和发出的所有的数据包 1tcpdump host 210.27.48.1 打印helios 与 hot 或者与 ace 之间通信的数据包 123tcpdump host helios and \\( hot or ace \\)``` - 截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信 tcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 )1- 打印ace与任何其他主机之间通信的IP 数据包, 但不包括与helios之间的数据包. tcpdump ip host ace and not helios1- 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令： tcpdump ip host 210.27.48.1 and ! 210.27.48.21- 截获主机hostname发送的所有数据 tcpdump -i eth0 src host hostname1- 监视所有送到主机hostname的数据包 tcpdump -i eth0 dst host hostname123** 监视指定主机和端口的数据包**- 如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令 tcpdump tcp port 23 host 210.27.48.11- 对本机的udp 123 端口进行监视 123 为ntp的服务端口 tcpdump udp port 123123** 监视指定网络的数据包**- 打印本地主机与Berkeley网络上的主机之间的所有通信数据包 tcpdump net ucb-ether123 ucb-ether此处可理解为“Berkeley网络”的网络地址，此表达式最原始的含义可表达为：打印网络地址为ucb-ether的所有数据包- 打印所有通过网关snup的ftp数据包 tcpdump ‘gateway snup and (port ftp or ftp-data)’123 注意：表达式被单引号括起来了，这可以防止shell对其中的括号进行错误解析- 打印所有源地址或目标地址是本地主机的IP数据包 tcpdump ip and not net localnet``` 如果本地网络通过网关连到了另一网络，则另一网络并不能算作本地网络。","categories":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://yoursite.com/categories/Linux命令/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"Tcpdump","slug":"Tcpdump","permalink":"http://yoursite.com/tags/Tcpdump/"}]},{"title":"Strace命令分析","slug":"Strace命令分析","date":"2016-12-15T06:52:07.000Z","updated":"2016-12-15T07:11:17.000Z","comments":true,"path":"2016/12/15/Strace命令分析/","link":"","permalink":"http://yoursite.com/2016/12/15/Strace命令分析/","excerpt":"","text":"strace是个很好用的诊断手段，该文章整合了自己查找的比较好的网络资料和一些自己的理解，作为记录和学习。借鉴网址：http://man.linuxde.net/strace Strace命令是个集诊断、调试、统计与一体的工具，我们可以使用strace对应用的系统调用和信号传递的跟踪结果来对应用进行分析，以达到解决问题或者是了解应用工作过程的目的。语法&amp;释义： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@node2 ~]# strace -husage: strace [-dDffhiqrtttTvVxx] [-a column] [-e expr] ... [-o file] [-p pid] ... [-s strsize] [-u username] [-E var=val] ... [command [arg ...]] or: strace -c [-D] [-e expr] ... [-O overhead] [-S sortby] [-E var=val] ... [command [arg ...]]-c -- count time, calls, and errors for each syscall and report summary 统计每一系统调用的所执行的时间,次数和出错的次数等.-f -- follow forks, -ff -- with output into separate files -f 跟踪由fork产生的子进程 -ff 常与-o选项一起使用，不同进程(子进程)产生的系统调用输出到filename.PI,D文件如果提供-o filename,则所有进程的跟踪结果输出到相应的filename.pid中,pid是各进程的进程号.-F -- attempt to follow vforks, -h -- print help message 尝试跟踪vfork调用。在-f时，vfork不被跟踪-i -- print instruction pointer at time of syscall 输出系统调用的入口指针-q -- suppress messages about attaching, detaching, etc. 禁止输出关于脱离的消息-r -- print relative timestamp 打印每个系统调用的相对时间 -t -- absolute timestamp, -tt -- with usecs 在输出中的每一行前加上时间信息 -tt 时间确定到微秒级-T -- print time spent in each syscall, -V -- print version 显示每个调用的花费时间-v -- verbose mode: print unabbreviated argv, stat, termio[s], etc. args 输出所有的系统调用.一些调用关于环境变量,状态,输入输出等调用由于使用频繁,默认不输出.-x -- print non-ascii strings in hex, -xx -- print all strings in hex 以十六进制形式输出非标准字符串 -xx 所有字符串以十六进制形式输出-a column -- alignment COLUMN for printing syscall results (default 40) 设置返回值的输出位置.默认 为40.-e expr -- a qualifying expression: option=[!]all or option=[!]val1[,val2]... options: trace, abbrev, verbose, raw, signal, read, or write -e expr 指定一个表达式,用来控制如何跟踪.格式：[qualifier=][!]value1[,value2]... qualifier只能是 trace,abbrev,verbose,raw,signal,read,write其中之一.value是用来限定的符号或数字.默认的 qualifier是 trace.感叹号是否定符号.例如:-eopen等价于 -e trace=open,表示只跟踪open调用.而-etrace!=open 表示跟踪除了open以外的其他调用.有两个特殊的符号 all 和 none. 注意有些shell使用!来执行历史记录里的命令,所以要使用\\\\. -e trace=set 只跟踪指定的系统 调用.例如:-e trace=open,close,rean,write表示只跟踪这四个系统调用.默认的为set=all. -e trace=file 只跟踪有关文件操作的系统调用. -e trace=process 只跟踪有关进程控制的系统调用. -e trace=network 跟踪与网络有关的所有系统调用. -e strace=signal 跟踪所有与系统信号有关的 系统调用 -e trace=ipc 跟踪所有与进程通讯有关的系统调用 -e abbrev=set 设定strace输出的系统调用的结果集.-v 等与 abbrev=none.默认为abbrev=all. -e raw=set 将指定的系统调用的参数以十六进制显示. -e signal=set 指定跟踪的系统信号.默认为all.如 signal=!SIGIO(或者signal=!io),表示不跟踪SIGIO信号. -e read=set 输出从指定文件中读出 的数据.例如: -e read=3,5 -e write=set 输出写入到指定文件中的数据.-o file -- send trace output to FILE instead of stderr 将strace的输出写入文件filename-O overhead -- set overhead for tracing syscalls to OVERHEAD usecs-p pid -- trace process with process id PID, may be repeated 跟踪指定的进程pid.-D -- run tracer process as a detached grandchild, not as parent-s strsize -- limit length of print strings to STRSIZE chars (default 32) 指定输出的字符串的最大长度.默认为32.文件名一直全部输出-S sortby -- sort syscall counts by: time, calls, name, nothing (default time)-u username -- run command as username handling setuid and/or setgid 以username的UID和GID执行被跟踪的命令-E var=val -- put var=val in the environment for command-E var -- remove var from the environment for command","categories":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://yoursite.com/categories/Linux命令/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"Strace","slug":"Strace","permalink":"http://yoursite.com/tags/Strace/"}]},{"title":"SSH代理登录服务器","slug":"SSH代理登录","date":"2016-12-15T06:47:59.000Z","updated":"2016-12-15T07:10:33.000Z","comments":true,"path":"2016/12/15/SSH代理登录/","link":"","permalink":"http://yoursite.com/2016/12/15/SSH代理登录/","excerpt":"","text":"ssh 代理登录服务器场景： 1234A机器：10.0.0.1B机器：10.0.0.2C机器：10.0.0.3D机器：10.0.0.4 现在我们在A机器上，要登陆D机器，必须要经过B、C两台跳板机，一台台的登陆太复杂，而且如果要传文件的话，那要一层层的传，我们现在要求是在A机器上直接登陆到D机器。 一：使用ProxyCommand编辑.ssh/config文件 12345678Host machineB HostName 10.0.0.2Host machineC ProxyCommand ssh -q machineB nc 10.0.0.3 22Host machineD ProxyCommand ssh -q machineC nc 10.0.0.4 22 登陆D机器时， 直接ssh machineD。注：登陆时，可能要输入BCD机器的密码，可以事先打通key。 二：使用ssh端口转发命令在B机器上 1ssh -CfgNL 2222:10.0.0.3:222 localhost 在C机器上 1ssh -CfgNL 222:10.0.0.4:22 localhost 连接D机器是，连接B机器的2222端口即可： 1ssh -p 2222 10.0.0.2","categories":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://yoursite.com/categories/Linux命令/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"ssh","slug":"ssh","permalink":"http://yoursite.com/tags/ssh/"}]},{"title":"Logrotate安装配置","slug":"Logrotate安装配置","date":"2016-12-15T06:35:43.000Z","updated":"2016-12-15T07:13:36.000Z","comments":true,"path":"2016/12/15/Logrotate安装配置/","link":"","permalink":"http://yoursite.com/2016/12/15/Logrotate安装配置/","excerpt":"","text":"原文链接：https://linux.cn/article-4126-1.html logrotate是个十分有用的工具，它可以自动对日志进行截断（或轮循）、压缩以及删除旧的日志文件。 安装logrotate安装非常简单。yum或apt-get安装即可。 1yum -y install logrotate 配置文件目录：/etc/logrotate.conf ，通常不需要对它进行修改。日志文件的轮循设置在独立的配置文件中，它（们）放在/etc/logrotate.d/目录下 配置以下给出三个配置文件的实例： 示例一创建一个log文件进行测试 123touch /var/log/test.loghead -c 20M &lt; /dev/urandom &gt; /var/log/test.log#填入一个20MB的随机比特流数据 创建配置文件/etc/logrotate.d/test.conf，并写入： 123456789101112131415161718192021/var/log/test.log&#123;monthlyrotate 5compressdelaycompressmissingoknotifemptycreate 644 root rootpostrotate /usr/bin/killall -HUP rsyslogdendscript&#125;#注释：#monthly: 日志文件将按月轮循。其它可用值为‘daily’，‘weekly’或者‘yearly’。#rotate 5: 一次将存储5个归档日志。对于第六个归档，时间最久的归档将被删除。#compress: 在轮循任务完成后，已轮循的归档将使用gzip进行压缩。#delaycompress: 总是与compress选项一起用，delaycompress选项指示logrotate不要将最近的归档压缩，压缩将在#下一次轮循周期进行。这在你或任何软件仍然需要读取最新归档时很有用。#missingok: 在日志轮循期间，任何错误将被忽略，例如“文件无法找到”之类的错误。#notifempty: 如果日志文件为空，轮循不会进行。#create 644 root root: 以指定的权限创建全新的日志文件，同时logrotate也会重命名原始日志文件。#postrotate/endscript: 在所有其它指令完成后，postrotate和endscript里面指定的命令将被执行。在这种情况下，#rsyslogd 进程将立即再次读取其配置并继续运行。 示例二我们只想要轮循一个日志文件，然而日志文件大小可以增长到50MB。 123456789#/etc/logrotate.d/test.conf 写入：/var/log/log-file &#123; size=50M rotate 5 create 644 root root postrotate /usr/bin/killall -HUP rsyslogd endscript&#125; 示例三我们想要让旧日志文件以创建日期命名，这可以通过添加dateext常熟实现。 12345678910#/etc/logrotate.d/test.conf 写入：/var/log/log-file &#123; monthly rotate 5 dateext create 644 root root postrotate /usr/bin/killall -HUP rsyslogd endscript&#125; 这将让归档文件在它们的文件名中包含日期信息。 测试logrotate可以在任何时候从命令行手动调用。要调用为/etc/lograte.d/下配置的所有日志调用logrotate： 123[root@node2 ~]# ls /etc/logrotate.d/dracut redis salt syslog test.conf vsftpd yum[root@node2 ~]# logrotate /etc/logrotate.conf 要为某个特定的配置调用logrotate： 1[root@node2 ~]# logrotate /etc/logrotate.d/test.conf 预演方式运行使用‘-d’选项以预演方式运行logrotate。要进行验证，不用实际轮循任何日志文件，可以模拟演练日志轮循并显示其输出。 1234567891011[root@node2 ~]# logrotate -d /etc/logrotate.d/test.conf reading config file /etc/logrotate.d/test.confreading config info for /var/log/test.logHandling 1 logsrotating pattern: /var/log/test.log monthly (5 rotations)empty log files are not rotated, old logs are removedconsidering log /var/log/test.log log does not need rotatingnot running postrotate script, since no logs were rotated 正如我们从上面的输出结果可以看到的，logrotate判断该轮循是不必要的。 强制方式运行 123456789101112131415161718[root@node2 bin]# logrotate -vf /etc/logrotate.d/test.conf reading config file /etc/logrotate.d/test.confreading config info for /var/log/test.logHandling 1 logsrotating pattern: /var/log/test.log forced from command line (5 rotations)empty log files are not rotated, old logs are removedconsidering log /var/log/test.log log needs rotatingrotating log /var/log/test.log, log-&gt;rotateCount is 5dateext suffix '-20150923'glob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'glob finding logs to compress failedglob finding old rotated logs failedrenaming /var/log/test.log to /var/log/test.log-20150923creating new /var/log/test.log mode = 0644 uid = 0 gid = 0running postrotate script 之后配置crontab进行定时处理。","categories":[{"name":"Linux工具","slug":"Linux工具","permalink":"http://yoursite.com/categories/Linux工具/"}],"tags":[{"name":"Logrotate","slug":"Logrotate","permalink":"http://yoursite.com/tags/Logrotate/"},{"name":"Log","slug":"Log","permalink":"http://yoursite.com/tags/Log/"}]},{"title":"Linux_inode_100%问题","slug":"Linux-inode-100-问题","date":"2016-12-15T06:31:02.000Z","updated":"2016-12-15T07:07:17.000Z","comments":true,"path":"2016/12/15/Linux-inode-100-问题/","link":"","permalink":"http://yoursite.com/2016/12/15/Linux-inode-100-问题/","excerpt":"","text":"查看系统的 innode 占用情况1df -ih 查找那个目录下文件最多12for i in /*; do echo $i; find $i | wc -l; done# find $i 会列出该目录下所有文件，然后wc -l 计算总和 删除那个目录的的所有文件一般情况下，如果这个目录下应该会有数以百万的文件，如果你直接用 rm -rf 目录名 的话效率会很低，可以用下面方法,最好开一个 screen 来处理 ```find 目录 -type f -name ‘*’ -print0 | xargs -0 rm","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"inode","slug":"inode","permalink":"http://yoursite.com/tags/inode/"}]},{"title":"Linux_inodes","slug":"Linux-inodes","date":"2016-12-15T06:18:23.000Z","updated":"2016-12-15T06:32:15.000Z","comments":true,"path":"2016/12/15/Linux-inodes/","link":"","permalink":"http://yoursite.com/2016/12/15/Linux-inodes/","excerpt":"","text":"一、inode是什么？理解inode，要从文件储存说起。 文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。 操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个sector组成一个 block。 文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。 每一个文件都有对应的inode，里面包含了与该文件有关的一些信息。 二、inode的内容inode包含文件的元信息，具体来说有以下内容： 1234567* 文件的字节数 * 文件拥有者的User ID * 文件的Group ID * 文件的读、写、执行权限 * 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。 * 链接数，即有多少文件名指向这个inode * 文件数据block的位置 可以用stat命令，查看某个文件的inode信息： 123456789$ stat sina.html File: ‘sina.html’ Size: 590188 Blocks: 1160 IO Block: 4096 regular fileDevice: ca01h/51713d Inode: 921437 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2016-08-03 18:08:50.961342023 +0800Modify: 2016-08-01 11:11:43.600409902 +0800Change: 2016-08-01 11:11:43.600409902 +0800 Birth: - 三、inode的大小inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。 每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。 查看每个硬盘分区的inode总数和已经使用的数量，可以使用df -i命令。 123456789$ df -iFilesystem Inodes IUsed IFree IUse% Mounted on/dev/xvda1 2621440 295029 2326411 12% /none 127041 11 127030 1% /sys/fs/cgroupudev 124329 424 123905 1% /devtmpfs 127041 338 126703 1% /runnone 127041 3 127038 1% /run/locknone 127041 1 127040 1% /run/shmnone 127041 2 127039 1% /run/user 查看每个inode节点的大小，可以用如下命令 123$ sudo dumpe2fs -h /dev/xvda1 | grep \"Inode size\"dumpe2fs 1.42.9 (4-Feb-2014)Inode size: 256 由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。 四、inode号码每个inode都有一个号码，操作系统用inode号码来识别不同的文件。 这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。 表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。使用ls -i命令，可以看到文件名对应的inode号码： 12$ ls -i sina.html921437 sina.html 五、目录文件Unix/Linux系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。 ls -i命令列出整个目录文件，即文件名和inode号码： 12$ ls -i /mnt/919572 a.py 919588 b.py 919592 kong1 919591 kong2 919546 passwd 理解了上面这些知识，就能理解目录的权限。目录文件的读权限（r）和写权限（w），都是针对目录文件本身。由于目录文件内只有文件名和inode号码，所以如果只有读权限，只能获取文件名，无法获取其他信息，因为其他信息都储存在inode节点中，而读取inode节点内的信息需要目录文件的执行权限（x）。 六、硬链接一般情况下，文件名和inode号码是”一一对应”关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。 这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为”硬链接”（hard link）。 ln命令可以创建硬链接： 12345678910111213141516171819ln 源文件 目标文件$ touch testa$ ln testa testb$ ll -i test*919070 -rw-r--r-- 2 root root 0 Aug 4 09:49 testa919070 -rw-r--r-- 2 root root 0 Aug 4 09:49 testb# 一些更改操作,更改操作会同时更改两个文件，删除其中一个，不会影响到另一个$ echo aa &gt; testa$ cat testbaa$ echo bb &gt; testb$ cat testabb$ rm -rf testa$ lsa.py b.py kong1 kong2 passwd testb testv$ cat testbbb 运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做”链接数”，记录指向该inode的文件名总数，这时就会增加1。 反过来，删除一个文件名，就会使得inode节点中的”链接数”减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。这里顺便说一下目录文件的”链接数”。创建目录时，默认会生成两个目录项：”.”和”..”。前者的inode号码就是当前目录的inode号码，等同于当前目录的”硬链接”；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的”硬链接”。所以，任何一个目录的”硬链接”总数，总是等于2加上它的子目录总数（含隐藏目录）。 七、软链接文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的”软链接”（soft link）或者”符号链接（symbolic link）。这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：&quot;No such file or directory&quot;。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode“链接数”不会因此发生变化。 1$ ln -s 源文文件或目录 目标文件或目录 八、inode的特殊作用由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。 1. 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。 2. 移动文件或重命名文件，只是改变文件名，不影响inode号码。 3. 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。 第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"inode","slug":"inode","permalink":"http://yoursite.com/tags/inode/"}]},{"title":"Python_递归","slug":"Python-递归","date":"2016-12-15T03:10:37.000Z","updated":"2016-12-15T06:16:50.000Z","comments":true,"path":"2016/12/15/Python-递归/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-递归/","excerpt":"","text":"递归：函数对自身定义的引用。 每次函数调用时，针对这个调用的新命名空间会被创建，意味着当函数调用“自身”时，实际上运行的是两个不同的函数（或者说同一个函数具有两个不同的命名空间）。 阶乘计算数 n 的阶乘(n * (n-1) * (n-2) .. * 1)： 1234567891011121314# for 循环实现def fac(n): result = n for i in range(1, n): result *= i return result # 递归实现def fac(n):def rec_fac(n): if n == 1: return n else: return n * rec_fac(n - 1) 二分法12345678910111213def search(sequence, number, lower=0, upper=None): if upper is None: upper = len(sequence) - 1 if lower == upper: assert number == sequence[upper] return upper else: middle = (lower + upper)//2 if number &gt; sequence[middle]: return search(sequence, number, middle+1, upper) else: return search(sequence, number, lower, middle) 查找目录下的所有文件123456def Test(rootDir): for lists in os.listdir(rootDir): path = os.path.join(rootDir, lists) print path if os.path.isdir(path): Test(path)","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"},{"name":"递归","slug":"递归","permalink":"http://yoursite.com/tags/递归/"}]}]}