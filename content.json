{"meta":{"title":"SateZheng","subtitle":"多读书，多看报，少吃零食，多睡觉","description":null,"author":"SateZheng","url":"http://yoursite.com"},"pages":[{"title":"","date":"2016-12-15T05:18:23.000Z","updated":"2016-12-15T05:47:06.000Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"作者： SateZheng简书地址：传送"}],"posts":[{"title":"Zabbix监控Mysql","slug":"Zabbix监控Mysql","date":"2016-12-15T08:19:21.000Z","updated":"2016-12-15T08:19:50.000Z","comments":true,"path":"2016/12/15/Zabbix监控Mysql/","link":"","permalink":"http://yoursite.com/2016/12/15/Zabbix监控Mysql/","excerpt":"","text":"在zabbix中有官方提供的关于mysql的监控模版，但是该模板需要在zabbix的客户端添加自定义的key来取值。 1. check_mysql.sh编写脚本来获取mysql的各个状态值，放置在/alidata/zabbix-agentd/scripts/chk_mysql.sh。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#!/bin/bash# -------------------------------------------------------------------------------# FileName: check_mysql.sh# Revision: 1.0# Date: 2015/06/09# Author: DengYun# Email: dengyun@ttlsa.com# Website: www.ttlsa.com# Description: # Notes: ~# -------------------------------------------------------------------------------# Copyright: 2015 (c) DengYun# License: GPL # 用户名MYSQL_USER='zabbix' # 密码MYSQL_PWD='123123' # 主机地址/IPMYSQL_HOST='127.0.0.1' # 端口MYSQL_PORT='3306' # 数据连接MYSQL_CONN=\"/alidata/server/mysql/bin/mysqladmin -u$&#123;MYSQL_USER&#125; -p$&#123;MYSQL_PWD&#125; -h$&#123;MYSQL_HOST&#125; -P$&#123;MYSQL_PORT&#125;\" # 参数是否正确if [ $# -ne \"1\" ];then echo \"arg error!\" fi # 获取数据case $1 in Uptime) result=`$&#123;MYSQL_CONN&#125; status|cut -f2 -d\":\"|cut -f1 -d\"T\"` echo $result ;; Com_update) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Com_update\"|cut -d\"|\" -f3` echo $result ;; Slow_queries) result=`$&#123;MYSQL_CONN&#125; status |cut -f5 -d\":\"|cut -f1 -d\"O\"` echo $result ;; Com_select) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Com_select\"|cut -d\"|\" -f3` echo $result ;; Com_rollback) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Com_rollback\"|cut -d\"|\" -f3` echo $result ;; Questions) result=`$&#123;MYSQL_CONN&#125; status|cut -f4 -d\":\"|cut -f1 -d\"S\"` echo $result ;; Com_insert) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Com_insert\"|cut -d\"|\" -f3` echo $result ;; Com_delete) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Com_delete\"|cut -d\"|\" -f3` echo $result ;; Com_commit) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Com_commit\"|cut -d\"|\" -f3` echo $result ;; Bytes_sent) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Bytes_sent\" |cut -d\"|\" -f3` echo $result ;; Bytes_received) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Bytes_received\" |cut -d\"|\" -f3` echo $result ;; Com_begin) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w \"Com_begin\"|cut -d\"|\" -f3` echo $result ;; *) echo \"Usage:$0(Uptime|Com_update|Slow_queries|Com_select|Com_rollback|Questions|Com_insert|Com_delete|Com_commit|Bytes_sent|Bytes_received|Com_begin)\" ;; esac 2. 修改配置文件zabbix_agentd.conf增加自定义的key，在配置文件的最后一行写入,如下代码行并重启zabbix客户端。 123456# 获取mysql版本UserParameter=mysql.version,mysql -V# # 获取mysql性能指标,这个是上面定义好的脚本UserParameter=mysql.status[*],bash /alidata/zabbix-agentd/scripts/chk_mysql.sh $1# # 获取mysql运行状态UserParameter=mysql.ping,mysqladmin -uzabbix -p123123 -P3306 -h127.0.0.1 ping | grep -c alive ###3. 在监控项目中加入Template App MySQL模版 ###在项目中加入模版后，查看Monitoring-&gt;Graphs中是否有数据图形产生。","categories":[{"name":"Zabbix","slug":"Zabbix","permalink":"http://yoursite.com/categories/Zabbix/"}],"tags":[{"name":"Zabbix","slug":"Zabbix","permalink":"http://yoursite.com/tags/Zabbix/"}]},{"title":"SVN的搭建和使用","slug":"SVN的搭建和使用","date":"2016-12-15T08:16:33.000Z","updated":"2016-12-15T08:18:07.000Z","comments":true,"path":"2016/12/15/SVN的搭建和使用/","link":"","permalink":"http://yoursite.com/2016/12/15/SVN的搭建和使用/","excerpt":"","text":"安装1[root@node1 ~]# yum install subversion 配置1. 新建目录，并做成资源仓库 123456789$ mkdir mkdir /svn$ svnadmin create /svn/$ ls /svn/conf db format hooks locks README.txt# 目录说明：hooks目录：放置hook脚本文件的目录locks目录：用来放置subversion的db锁文件和db_logs锁文件的目录，用来追踪存取文件库的客户端format文件：是一个文本文件，里面只放了一个整数，表示当前文件库配置的版本号conf目录：是这个仓库的配置文件（仓库的用户访问账号、权限等） 2. 配置svn服务的配置文件svnserver.conf文件 1234567$ vim /svn/conf/svnserve.conf[general]anon-access = noneauth-access = writepassword-db = /svn/conf/passwdauthz-db = /svn/conf/authzrealm = My Test Repository 3. 添加两个访问用户及口令 1234$ vim /svn/conf/passwd[users]zwx = 123123test1 = 123123 注： 对用户配置文件的修改立即生效，不必重启svn服务。 4. 配置新用户的授权文件 12345678$ vim /svn/conf/authz[groups]admin = zwxuser = test1[/]@admin = rw@user = r* = 格式说明 : 1234567891011121314151617181920[&lt;版本库&gt;:/项目/目录]@&lt;用户组名&gt; = &lt;权限&gt;&lt;用户名&gt; = &lt;权限&gt;/ 表示对根目录（即/svn目录）下的所有子目录范围设置权限；[/abc] 表示对资料库中abc项目设置权限；创建一个admin组，组成员包括zwx;创建一个user组，成员只有test1;admin组对目录有读写权限；单个用户test1有读写权限；*=表示除了上面设置的权限用户组以外，其他所有用户都设置空权限，空权限表示禁止访问本目录，这很重要一定要加上。注意：对权限配置文件的修改立即生效，不必重启svn。 5. 启动SVN svn 启动可以使用两种方法： 一： 指定项目启动 1234$ svnserve -d -r /svn/# 指定项目启动时，在客户端checkout的时候，使用命令如下：$ svn cheackout svn://192.168.174.128# 会同步svn目录，并且命名为192.168.174.128 二： /etc/init.d/svnserve 启动 1234$ /etc/init.d/svnserve start# 使用启动命令启动$ svn cheackout svn://192.168.174.128/svn# 会同步svn目录，并且命名为svn 基本使用1、将文件checkout到本地目录 123svn checkout path（path是服务器上的目录）例如：svn checkout svn://192.168.1.1/pro/domain简写：svn co 2、往版本库中添加新的文件 123svn add file例如：svn add test.php(添加test.php)svn add *.php(添加当前目录下所有的php文件) 3、将改动的文件提交到版本库 123svn commit -m \"LogMessage\" [-N] [--no-unlock] PATH(如果选择了保持锁，就使用--no-unlock开关)例如：svn commit -m \"add test file for my test\" test.php简写：svn ci 4、加锁/解锁 123svn lock -m \"LockMessage\" [--force] PATH例如：svn lock -m \"lock test file\" test.phpsvn unlock PATH 5、更新到某个版本 123456svn update -r m path例如：svn update如果后面没有目录，默认将当前目录以及子目录下的所有文件都更新到最新版本。svn update -r 200 test.php(将版本库中的文件test.php还原到版本200)svn update test.php(更新，于版本库同步。如果在提交的时候提示过期的话，是因为冲突，需要先update，修改文件，然后清除svn resolved，最后再提交commit)简写：svn up 6、查看文件或者目录状态 1234561）svn status path（目录下的文件和子目录的状态，正常状态不显示）【?：不在svn的控制中；M：内容被修改；C：发生冲突；A：预定加入到版本库；K：被锁定】2）svn status -v path(显示文件和子目录状态)第一列保持相同，第二列显示工作版本号，第三和第四列显示最后一次修改的版本号和修改人。注：svn status、svn diff和 svn revert这三条命令在没有网络的情况下也可以执行的，原因是svn在本地的.svn中保留了本地版本的原始拷贝。简写：svn st 7、删除文件 1234svn delete path -m \"delete test fle\"例如：svn delete svn://192.168.1.1/pro/domain/test.php -m \"delete test file\"或者直接svn delete test.php 然后再svn ci -m 'delete test file‘，推荐使用这种简写：svn (del, remove, rm) 8、查看日志 12svn log path例如：svn log test.php 显示这个文件的所有修改记录，及其版本号的变化 9、查看文件详细信息 12svn info path例如：svn info test.php 10、比较差异 12345svn diff path(将修改的文件与基础版本比较)例如：svn diff test.phpsvn diff -r m:n path(对版本m和版本n比较差异)例如：svn diff -r 200:201 test.php简写：svn di 11、将两个版本之间的差异合并到当前文件 12svn merge -r m:n path例如：svn merge -r 200:205 test.php（将版本200与205之间的差异合并到当前文件，但是一般都会产生冲突，需要处理一下） 12、SVN 帮助 12svn helpsvn help ci 13、版本库下的文件和目录列表 123svn list path显示path目录下的所有属于版本库的文件和目录简写：svn ls 14、创建纳入版本控制下的新目录 12345678svn mkdir: 创建纳入版本控制下的新目录。用法: 1、mkdir PATH...2、mkdir URL...创建版本控制的目录。1、每一个以工作副本 PATH 指定的目录，都会创建在本地端，并且加入新增调度，以待下一次的提交。2、每个以URL指定的目录，都会透过立即提交于仓库中创建。在这两个情况下，所有的中间目录都必须事先存在。 15、恢复本地修改 1234svn revert: 恢复原始未改变的工作副本文件 (恢复大部份的本地修改)。revert:用法: revert PATH...注意: 本子命令不会存取网络，并且会解除冲突的状况。但是它不会恢复被删除的目录 16、代码库URL变更 123456789svn switch (sw): 更新工作副本至不同的URL。用法: 1、switch URL [PATH]2、switch --relocate FROM TO [PATH...]1、更新你的工作副本，映射到一个新的URL，其行为跟“svn update”很像，也会将服务器上文件与本地文件合并。这是将工作副本对应到同一仓库中某个分支或者标记的方法。2、改写工作副本的URL元数据，以反映单纯的URL上的改变。当仓库的根URL变动 (比如方案名或是主机名称变动)，但是工作副本仍旧对映到同一仓库的同一目录时使用这个命令更新工作副本与仓库的对应关系。 17、解决冲突 1234svn resolved: 移除工作副本的目录或文件的“冲突”状态。用法: resolved PATH...注意: 本子命令不会依语法来解决冲突或是移除冲突标记；它只是移除冲突的相关文件，然后让 PATH 可以再次提交。 18、输出指定文件或URL的内容。 12svn cat 目标[@版本]...如果指定了版本，将从指定的版本开始查找。svn cat -r PREV filename &gt; filename (PREV 是上一版本,也可以写具体版本号,这样输出结果是可以提交的）","categories":[{"name":"SVN","slug":"SVN","permalink":"http://yoursite.com/categories/SVN/"}],"tags":[{"name":"SVN","slug":"SVN","permalink":"http://yoursite.com/tags/SVN/"}]},{"title":"Nginx中root和alias的区别","slug":"Nginx中root和alias的区别","date":"2016-12-15T08:14:56.000Z","updated":"2016-12-15T08:21:54.000Z","comments":true,"path":"2016/12/15/Nginx中root和alias的区别/","link":"","permalink":"http://yoursite.com/2016/12/15/Nginx中root和alias的区别/","excerpt":"","text":"nginx指定文件路径有两种方式 root 和 alias。 root 与 alias 主要区别在于 nginx 如何解释 location 后面的 uri，这会使两者分别以不同的方式将请求映射到服务器文件上。 12345678[root]语法： root path默认值： root html配置段： http、 server、 location、 if[alias]语法： alias path配置段： location 示例：nginx的location配置如下： 123456location /xing/ &#123; root /alidata/www/phpwind/;&#125;#当访问http://192.168.3.14/xing/zheng/index.html时，调用的文件是/alidata/www/phpwind/xing/zheng/index.html。 #既 root路径 + url请求地址。 1234567891011location /xing/ &#123; alias /alidata/www/phpwind/;&#125;#当访问http://192.168.3.14/xing/zheng/index.html时，调用的文件是/alidata/www/phpwind/zheng/index.html。#既 省略location后边匹配的路径。注：1. 使用 alias 时，目录名后面一定要加” /”2. alias 可以指定任何名称3. alias 在使用正则匹配时，必须捕捉要匹配的内容并在指定的内容处使用。4. alias 只能位于 location 块中。","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"Nginx隐藏版本号","slug":"Nginx隐藏版本号","date":"2016-12-15T08:11:59.000Z","updated":"2016-12-15T08:12:27.000Z","comments":true,"path":"2016/12/15/Nginx隐藏版本号/","link":"","permalink":"http://yoursite.com/2016/12/15/Nginx隐藏版本号/","excerpt":"","text":"修改nginx.conf文件 12345678vim /../../nginx.conf # 在http&#123;&#125;加入 server_tokens off;http &#123;……省略keepalive_timeout 60;server_tokens off;…….省略&#125; 修改fastcgi.conf 123fastcgi_param SERVER_SOFTWARE nginx/$nginx_version;改为：fastcgi_param SERVER_SOFTWARE nginx; 重启nginx服务","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"Nginx的日志切割","slug":"Nginx的日志切割","date":"2016-12-15T08:11:15.000Z","updated":"2016-12-15T08:11:37.000Z","comments":true,"path":"2016/12/15/Nginx的日志切割/","link":"","permalink":"http://yoursite.com/2016/12/15/Nginx的日志切割/","excerpt":"","text":"nginx的切割日志的方法记录一下两种方式：logrotate和脚本。 logrotate切割日志 安装logrotate 1yum -y install logrotate 配置文件 123456789101112131415vim /etc/logrotate.d/nginx-log 写入：/var/log/nginx/*.log &#123; #根据实际路径修改nocompressdailycopytruncatecreatenotifemptyrotate 7olddir /data/weblogs/old_logmissingokdateextpostrotate/bin/kill -HUP `cat /var/run/nginx.pid 2&gt; /dev/null` 2&gt; /dev/null || trueendscript&#125; 注：/data/weblogs/*.log 使用通配符时， /data/weblogs/目录下的所有匹配到的日志文件都将切割。如果要切割特定日志文件，就指定到该文件 设置计划任务 12# vim /etc/crontab59 23 * * * root ( /usr/sbin/logrotate -f /etc/logrotate.d/nginx-log) 脚本切割 使用shell脚本来分割访问日志和错误日志。 1234567891011vim /opt/logcut.sh 写入：#!/bin/bashlogs_path=\"/var/log/nginx/\"date=`date +%Y%m%d`log_name1=\"access.log\" log_name2=\"error.log\"pid_path=\"/var/run/nginx.pid\"mv $&#123;logs_path&#125;$&#123;log_name1&#125; $&#123;logs_path&#125;$&#123;log_name1&#125;_$date.logmv $&#123;logs_path&#125;$&#123;log_name2&#125; $&#123;logs_path&#125;$&#123;log_name2&#125;_$date.logkill -USR1 `cat $&#123;pid_path&#125;` 设置计划任务 12# vim /etc/crontab59 23 * * * root /bin/bash /opt/logcut.sh","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"Nginx的realip配置","slug":"Nginx的realip配置","date":"2016-12-15T08:04:48.000Z","updated":"2016-12-15T08:05:38.000Z","comments":true,"path":"2016/12/15/Nginx的realip配置/","link":"","permalink":"http://yoursite.com/2016/12/15/Nginx的realip配置/","excerpt":"","text":"当前端有nginx进行反向代理时，后端的机器获得的访问日志中记录的IP是前端nginx的，用一下方法来记录真实IP。 实验环境12node1：192.168.174.129 前端代理（nginx-proxy） centos 6.5node2：192.168.174.128 后端服务（nginx） centos 6.5 实验过程 nginx安装realip_module模块（两个nginx都要安装） 12345678910111213141516#检查nginx是否安装了realip_modulenginx -V[root@node1 ~]# nginx -Vnginx version: nginx/1.4.4built by gcc 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC) TLS SNI support enabledconfigure arguments: --user=www --group=www --prefix=/alidata/server/nginx --with-http_stub_status_module --without-http-cache --with-http_ssl_module --with-http_gzip_static_module #增加realip_module，找到nginx的源码，重新编译，在编译参数中加入--with-http_realip_module[root@node1 nginx-1.4.4]# ./configure --user=www --group=www --prefix=/alidata/server/nginx --with-http_stub_status_module --without-http-cache --with-http_ssl_module --with-http_gzip_static_module --with-http_realip_module#之后，只需make即可，不要make install[root@node1 nginx-1.4.4]# make#将新的nginx替换老的nginx sbin文件（可能需要停止nginx服务）。重启nginx服务[root@node1 nginx-1.4.4]# cp objs/nginx /alidata/server/nginx/sbin/ 在nginx代理机器修改配置文件 （192.168.174.129） 12345678910111213#在server段的配置中：server &#123; listen 80; server_name _; location ^~ /xing/ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://192.168.174.128/; &#125; access_log /alidata/log/nginx/access/test.log;&#125; 修改后端nginx的日志格式。（192.168.174.128） 1234567#在nginx.conf中：log_format test '$http_x_real_ip - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"';#在server段配置log access_log /alidata/log/nginx/access/zabbix.log test; 测试访问http://192.168.174.129/xing/ ，观察node2机器的日志。 1192.168.174.1 - - [24/Sep/2015:22:52:38 +0800] \"GET /images/general/zabbix.ico HTTP/1.0\" 200 1150 \"http://192.168.174.129/xing/\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.93 Safari/537.36\" \"192.168.174.1\"","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"Nginx的location配置","slug":"Nginx的location配置","date":"2016-12-15T08:03:17.000Z","updated":"2016-12-15T08:03:58.000Z","comments":true,"path":"2016/12/15/Nginx的location配置/","link":"","permalink":"http://yoursite.com/2016/12/15/Nginx的location配置/","excerpt":"","text":"规则location [=|~|~*|^~] /uri/ { … } = 严格匹配。如果这个查询匹配，那么将停止搜索并立即处理此请求。 ~ 为区分大小写匹配(可用正则表达式) ~* 为不区分大小写匹配(可用正则表达式) !~和!~*分别为区分大小写不匹配及不区分大小写不匹配 ^~ 开头表示uri以某个常规字符串开头，理解为匹配 url路径即可。nginx不对url做编码，因此请求为/static/20%/aa，可以被规则^~ /static/ /aa匹配到（注意是空格）。 首先匹配 =，其次匹配^~, 其次是按文件中顺序的正则匹配，最后是交给 / 通用匹配。当有匹配成功时候，停止匹配，按当前匹配规则处理请求。 示例匹配任何查询，因为所有请求都以 / 开头。但是正则表达式规则将被优先和查询匹配。 1location / &#123;&#125; 仅仅匹配 /，访问根目录 12location =/ &#123;&#125;#访问http://localhost/ 不区分大小写匹配任何以gif，jpg，jpeg结尾的文件 123location ~* .(gif|jpg|jpeg)$ ｛rewrite .(gif|jpg)$ /logo.png;｝ 匹配任何已 /images/ 开头的任何查询并且停止搜索。任何正则表达式将不会被测试。 12location ^~ /images/ &#123;&#125;#访问http://localhost/images/a.html 不区分大小写匹配任何以 gif、jpg 或 jpeg 结尾的请求。 1location ~* .(gif|jpg|jpeg)$ &#123;&#125; 实际中，常用的三个匹配规则定义。直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。这里是直接转发给后端应用服务器了，也可以是一个静态首页 1234# 第一个必选规则location = / &#123; proxy_pass http://tomcat:8080/index&#125; 第二个必选规则是处理静态文件请求，这是nginx作为http服务器的强项 1234567# 有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用location ^~ /static/ &#123; root /webroot/static/;&#125;location ~* \\.(gif|jpg|jpeg|png|css|js|ico)$ &#123; root /webroot/res/;&#125; 第三个规则就是通用规则，用来转发动态请求到后端应用服务器，非静态文件请求就默认是动态请求，自己根据实际把握，毕竟目前的一些框架的流行，带.php,.jsp后缀的情况很少了 123location / &#123; proxy_pass http://tomcat:8080/&#125; 场景一： nginx对指定目录做代理（出自运维生存时间http://www.ttlsa.com/nginx/nginx-proxy-spec-dir/） web1，作为前端端服务器，访问地址是http://192.168.1.1, 要将http://192.168.1.1/bbs 的请求交给web2。在web1的网站根目录下并没有bbs目录.web2，作为后端web服务器，访问地址是http://192.168.1.2 12345#方式一location /bbs/ &#123;proxy_pass http://192.168.1.2/; #有“/”&#125;效果：通过 http://192.168.1.1/bbs 可以访问到web2网站根目录下的内容 12345#方式二（未验证通过）location /bbs/ &#123;proxy_pass http://192.168.1.2; #无“/”&#125;效果：要通过web1反问web2网站根目录的内容则需要输入：http://192.168.1.1/bbs/bbs","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"Gitlab变更为https访问","slug":"Gitlab变更为https访问","date":"2016-12-15T07:54:39.000Z","updated":"2016-12-15T07:55:50.000Z","comments":true,"path":"2016/12/15/Gitlab变更为https访问/","link":"","permalink":"http://yoursite.com/2016/12/15/Gitlab变更为https访问/","excerpt":"","text":"（源码方式安装） 方法来自 gitlab 的 help 文档 1、/home/git/gitlab/config/gitlab.yml 文件 将port改为443，https改为true 12345gitlab: ## Web server settings (note: host is the FQDN, do not include http://) host: git.zhai.me port: 443 # Set to 443 if using HTTPS, see installation.md#using-https for additional HTTPS configuration details https: true # Set to true if using HTTPS, see installation.md#using-https for additional HTTPS configuration details 2、/home/git/gitlab-shell/config.yml 文件 将 gitlab_url 改为https的链接,设置认证使用ca_file或ca_path 123456789gitlab_url: \"https://git.zhai.me/\"# See installation.md#using-https for additional HTTPS configuration details.http_settings:# user: someone# password: somepass# ca_file: /etc/ssl/cert.pem ca_path: /etc/pki/tls/certs self_signed_cert: false 3、替换/home/git/gitlab/lib/support/nginx/gitlab-ssl到/etc/nginx/sites-enabled/gitlab 并修改其中的YOUR_SERVER_FQDN和ssl_certificate、ssl_certificate_key的位置","categories":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://yoursite.com/categories/Gitlab/"}],"tags":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://yoursite.com/tags/Gitlab/"},{"name":"Git","slug":"Git","permalink":"http://yoursite.com/tags/Git/"}]},{"title":"公司Gitlab升级记录","slug":"公司Gitlab升级记录","date":"2016-12-15T07:52:10.000Z","updated":"2016-12-15T07:54:03.000Z","comments":true,"path":"2016/12/15/公司Gitlab升级记录/","link":"","permalink":"http://yoursite.com/2016/12/15/公司Gitlab升级记录/","excerpt":"","text":"公司gitlab使用源码方式安装，版本为7.2，因为最近结合ldap来进行使用，但是ldap中的block_auto_created_users选项到7.10才支持。所以要升级。参考官方帮助文档：http://doc.gitlab.com/ce/update/patch_versions.htmlhttps://gitlab.com/gitlab-org/gitlab-ce/blob/master/doc/update/7.9-to-7.10.md 从7.2升级到7.9版本依赖包和软件升级因为版本的升级跨度大，这版本直接肯定有很多新的功能需要扩展包进行支持，所以根据目前最新版(7.12)的源码安装教程重新安装依赖包，并且升级redis服务(测试时出现问题，所以提前升级)。安装依赖包： 1sudo apt-get install -y build-essential zlib1g-dev libyaml-dev libssl-dev libgdbm-dev libreadline-dev libncurses5-dev libffi-dev curl openssh-server redis-server checkinstall libxml2-dev libxslt-dev libcurl4-openssl-dev libicu-dev logrotate python-docutils pkg-config cmake nodejs libkrb5-dev 升级redis： 12345678910111213wget http://download.redis.io/releases/redis-3.0.3.tar.gztar xvf redis-3.0.3.tar.gzcd redis-3.0.3/make make install#会在/usr/local/bin/下边生成相应的bin文件cp redis.conf /etc/redis/#修改redis.conf文件，对应/etc/init.d/redis-server中进行修改daemonize yes #使redis可以后台运行pidfile /var/run/redis/redis-server.pidbind 127.0.0.1logfile /var/log/redis/redis-server.logdir /var/lib/redis 注：升级后，因为redis的bin文件更换了地方，要修改/home/git/gitlab-shell/config.yml为：bin: &quot;/usr/local/bin/redis-cli&quot;。 备份并停止服务123cd /home/git/gitlabsudo -u git -H bundle exec rake gitlab:backup:create RAILS_ENV=production/etc/init.d/gitlab stop 下载最新的稳定版的代码1234567sudo -u git -H git fetch --allsudo -u git -H git checkout v7.9.3``` LATEST_TAG为想要升级到的版本号，国内的网络fetch的时候可能会有问题，需要连接vpn。#### 更新最新的gitlab-shell版本 #### cd /home/git/gitlab-shellsudo -u git -H git fetchsudo -u git -H git checkout vcat /home/git/gitlab/GITLAB_SHELL_VERSION123456#### Install libs, migrations, etc. ####断开VPN连接，并且**修改ruby源来提高速度和成功率**。&gt; 注意：下边的bundle install命令使用的默认源是`https://rubygems.org/`，国内很慢，可以更换成淘宝的源，更改方法为:vim /home/git/gitlab/Gemfile 修改 其中的`source \"https://rubygems.org\"` 为`source \"https://ruby.taobao.org\"` cd /home/git/gitlab #PostgreSQLsudo -u git -H bundle install –without development test mysql –deployment MySQLsudo -u git -H bundle install –without development test postgres –deployment sudo -u git -H bundle exec rake db:migrate RAILS_ENV=productionsudo -u git -H bundle exec rake assets:clean RAILS_ENV=productionsudo -u git -H bundle exec rake assets:precompile RAILS_ENV=productionsudo -u git -H bundle exec rake cache:clear RAILS_ENV=production1#### 开启服务 #### sudo service gitlab startsudo service nginx restart123#### 检测升级是否成功 ####- 检测环境 sudo -u git -H bundle exec rake gitlab:env:info RAILS_ENV=production1- 检测项目 sudo -u git -H bundle exec rake gitlab:check RAILS_ENV=production123### 从7.9升级到7.13版本 ### #### 备份 #### sudo service gitlab stopcd /home/git/gitlabsudo -u git -H bundle exec rake gitlab:backup:create RAILS_ENV=production12#### 更新gitlab #### sudo -u git -H git fetch –allsudo -u git -H git checkout – db/schema.rb # local changes will be restored automaticallysudo -u git -H git checkout 7-13-stable1#### 更新gitlab-shell #### cd /home/git/gitlab-shellsudo -u git -H git fetchsudo -u git -H git checkout v2.6.312### Install libs, migrations, etc ###注：更换/home/git/gitlab/Gemfile中的ruby源 cd /home/git/gitlab MySQL installations (note: the line below states ‘–without … postgres’)sudo -u git -H bundle install –without development test postgres –deployment PostgreSQL installations (note: the line below states ‘–without … mysql’)sudo -u git -H bundle install –without development test mysql –deployment Run database migrationssudo -u git -H bundle exec rake db:migrate RAILS_ENV=production Clean up assets and cachesudo -u git -H bundle exec rake assets:clean assets:precompile cache:clear RAILS_ENV=production Update init.d scriptsudo cp lib/support/init.d/gitlab /etc/init.d/gitlab123#### 更新配置文件 ####因为配置文件中ldap的语法是不同的，所以将老gitlab.yml备份，用gitlab.yml.example替换他，并更改其中必要的配置。 ldap部分的配置如下： ldap: enabled: true servers: ########################################################################## # # Since GitLab 7.4, LDAP servers get ID&apos;s (below the ID is &apos;main&apos;). GitLab # Enterprise Edition now supports connecting to multiple LDAP servers. # # If you are updating from the old (pre-7.4) syntax, you MUST give your # old server the ID &apos;main&apos;. # ########################################################################## main: # &apos;main&apos; is the GitLab &apos;provider ID&apos; of this LDAP server label: &apos;LDAP&apos; host: &apos;ldap-url/IP&apos; port: 389 uid: &apos;uid&apos; method: &apos;plain&apos; # &quot;tls&quot; or &quot;ssl&quot; or &quot;plain&quot; bind_dn: &apos;cn=admin,dc=****,dc=com&apos; password: &apos;admin-passwd&apos; active_directory: true block_auto_created_users: true base: &apos;dc=****,dc=com&apos; user_filter: &apos;&apos; 12#### 启动服务 #### sudo service gitlab startsudo service nginx restart1#### 检查状态 #### sudo -u git -H bundle exec rake gitlab:env:info RAILS_ENV=productionsudo -u git -H bundle exec rake gitlab:check RAILS_ENV=production12#### 修复 ####根据上边检查的结果进行修复 sudo -u git -H bundle exec rake gitlab:satellites:create RAILS_ENV=production```","categories":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://yoursite.com/categories/Gitlab/"}],"tags":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://yoursite.com/tags/Gitlab/"}]},{"title":"Gitlab、GitLab-CI Runner、karma安装记录","slug":"Gitlab-GitLab-CI-Runner-karma安装记录","date":"2016-12-15T07:46:37.000Z","updated":"2016-12-15T07:47:43.000Z","comments":true,"path":"2016/12/15/Gitlab-GitLab-CI-Runner-karma安装记录/","link":"","permalink":"http://yoursite.com/2016/12/15/Gitlab-GitLab-CI-Runner-karma安装记录/","excerpt":"","text":"##Gitlab的安装 使用源码安装，安装方法参照官方文档： 1http://docs.gitlab.com/ce/install/README.html ##GitLab-CI Runner安装 Gitlab-CI Server在Gitlab 8版本以上就集成在gitlab中，不需要单独安装，Runner可以参照官方安装文档： 1https://gitlab.com/gitlab-org/gitlab-ci-multi-runner 本次安装使用如下方法： 安装依赖包 1234apt-get install -y wget curl gcc libxml2-dev libxslt-dev \\libcurl4-openssl-dev libreadline6-dev libc6-dev libssl-dev make \\build-essential zlib1g-dev openssh-server git-core libyaml-dev \\libpq-dev libicu-dev sudo 安装ruby 此次gitlab-ci runner和gitlab安装在同一台服务器，ruby已经安装，过程忽略。安装好ruby可以将源改为国内的淘宝的镜像，如下： 12gem source -r https://rubygems.org/gem source -a https://ruby.taobao.org/ 安装Gitlab-CI Runner (1) 安装ruby bundler 1sudo gem install bundler (2) 建立用于安装 GitLab-CI Runner 的系统用户： 1sudo adduser --disabled-login --gecos 'GitLab CI Runner' gitlab_ci_runner (3) 获取GitLab-CI Runner 源代码： 1234sudo su gitlab_ci_runnercd ~/git clone https://gitlab.com/gitlab-org/gitlab-ci-runner.gitcd gitlab-ci-runner (4) 修改Gem源的镜像改为淘宝镜像： 123vim Gemfile改为：source \"https://ruby.taobao.org/\" (5) 配置完成后安装 Gitlab-CI Runner 的 Gem 包，换回root用户 12cd /home/gitlab_ci_runner/gitlab-ci-runnerbundle install (6) 修改hosts文件，填入gitlab服务器和GitLab-CI 服务器域名对应的 IP (7) 在gitlab服务器上找到ci的token和url 123sudo su gitlab_ci_runnercd ~/gitlab-ci-runnerCI_SERVER_URL=https://git.zhai.me/ci REGISTRATION_TOKEN=replaceme bundle exec ./bin/setup (8) 尝试用 SSH 方式访问 GitLab 服务器，并将服务器的 ssh key 添加到已知主机列表 1ssh git@git.zhai.me (9) 复制 GitLab-CI Runner 的自动启动脚本到系统目录 1234cd /home/gitlab_ci_runner/gitlab-ci-runnersudo cp ./lib/support/init.d/gitlab_ci_runner /etc/init.d/gitlab-ci-runnersudo chmod +x /etc/init.d/gitlab-ci-runnersudo update-rc.d gitlab-ci-runner defaults 21 (10) 启动GitLab-CI Runner 1sudo service gitlab-ci-runner start (11) 到gitlab中去验证。 配合karma进行工程自动化测试karma要配合浏览器使用，（chrome、chromium-browser或者firefox），这边使用firefox，因为chrome、chromium-browser没装成功。。 安装vnc和图形化界面安装桌面图形化的一些软件包 1sudo apt-get install x-window-system-core gdm ubuntu-desktop gnome-core xfce4 安装浏览器和vnc 1apt-get install vnc4server firefox 因为gitlab使用git用户，所以切换到git用户并使用开启vnc 123su - gitvncserver :1#第一次使用可能要设置密码 我们在客户端打开vnc viewer，连接该服务器。可能发现只有命令行，没有图形化界面，进行如下操作： 123456789101112131415vim /home/git/.vnc/xstartup改为：#!/bin/sh# Uncomment the following two lines for normal desktop:# unset SESSION_MANAGER# exec /etc/X11/xinit/xinitrc[ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresourcesxsetroot -solid greyvncconfig -iconic &amp;x-terminal-emulator -geometry 80x24+10+10 -ls -title \"$VNCDESKTOP Desktop\" &amp;#x-window-manager &amp;gnome-session &amp; 重启vncserve，并重新连接。 123su - gitvncserver -kill:1vncserver :1 在服务器上运行firfox，或者在vnc图形化界面中打开firefox，没有报错，则正常。但是我发现肯定会报错。。。报错信息如下： 12root@git:~# firefoxError: cannot open display: :0 这个坑是因为一个叫DISPLAY的变量，坑了好久。。解决办法如下： 如果我们在git用户上使用vncserver :1来开启vnc，则在git用户中要设置变量DISPLAY为:1，如果使用vncserver :2来开启vnc，则在git用户中要设置变量DISPLAY为:2，如下： 12345vim /home/git/.bashrc写入：export DISPLAY=:1source /home/git/.bashrc 重启vncserver，然后进行测试，之后在gitlab中的runner中进行测试。 问题小记1、公司项目编译的时候使用npm，建议改为cnpm或者更改为淘宝的源。 2、如下报错，因为node 4以上版本升级为v8引擎，编译时需要gcc4.8以上版本，而系统默认安装gcc4.6。 1This version of node/NAN/v8 requires a C++11 compiler 升级gcc和g++，方法： 12345678首先添加ppa到库：sudo add-apt-repository ppa:ubuntu-toolchain-r/testsudo apt-get update安装高版本gcc、g++sudo apt-get install gcc-5 g++-5验证(可能需要改一下软连接)gcc -vg++ -v","categories":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://yoursite.com/categories/Gitlab/"}],"tags":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://yoursite.com/tags/Gitlab/"},{"name":"Git","slug":"Git","permalink":"http://yoursite.com/tags/Git/"}]},{"title":"Gitlab迁移小记","slug":"Gitlab迁移小记","date":"2016-12-15T07:43:50.000Z","updated":"2016-12-15T07:44:51.000Z","comments":true,"path":"2016/12/15/Gitlab迁移小记/","link":"","permalink":"http://yoursite.com/2016/12/15/Gitlab迁移小记/","excerpt":"","text":"情况一：A机器和B机器 使用Omnibus package（rpm）安装，且版本相同 12345678910111213备份：gitlab-rake gitlab:backup:create恢复：# 停止相关数据连接服务gitlab-ctl stop unicorngitlab-ctl stop sidekiq# 从Timestamp编号备份中恢复gitlab-rake gitlab:backup:restore BACKUP= Timestamp# 启动Gitlabsudo gitlab-ctl start 情况二：使用源码安装，且版本相同 12345全量备份：sudo -u git -H bundle exec rake gitlab:backup:create RAILS_ENV=production恢复：sudo -u git -H bundle exec rake gitlab:backup:restore RAILS_ENV=production BACKUP=Timestamp 情况三：使用源码安装，版本不完全相同 1234567891011备份：打包/home/git/repositories、备份pgsql或者mysql数据（如果版本一样，可以直接打包数据目录）、/home/git/.ssh/authorized_keys.恢复：1、 将上边备份的文件放到指定位置2、 bundle exec rake gitlab:import:repos RAILS_ENV=production检测：sudo -u git -H bundle exec rake gitlab:env:info RAILS_ENV=production（环境检测）sudo -u git -H bundle exec rake gitlab:check RAILS_ENV=production（项目检测）根据检测结果提示修复不正确的地方","categories":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://yoursite.com/categories/Gitlab/"}],"tags":[{"name":"Gitlab，Git","slug":"Gitlab，Git","permalink":"http://yoursite.com/tags/Gitlab，Git/"}]},{"title":"ELK + filebeat 日志分析工具的部署和简单应用","slug":"ELK和filebeat的部署和简单应用","date":"2016-12-15T07:41:58.000Z","updated":"2016-12-15T07:42:41.000Z","comments":true,"path":"2016/12/15/ELK和filebeat的部署和简单应用/","link":"","permalink":"http://yoursite.com/2016/12/15/ELK和filebeat的部署和简单应用/","excerpt":"","text":"参考文章：https://www.ibm.com/developerworks/cn/opensource/os-cn-elk/ 123456789101112131415环境： - 两台 CentOS 6.5 - elasticsearch-2.4.1 - kibana-4.6.1 - logstash-2.4.0 - filebeat-1.3.1过程： - 安装 JDK - 安装 Elasticsearch - 安装 Kibana - 安装 Nginx - 安装 Logstash - 配置 Logstash - 安装 filebeat - 访问 ELK 服务器中： 安装 Java 环境 https://www.java.com/zh_CN/download/manual.jsp中下载java安装包 解压到/usr/local/jdk 目录下 在/etc/profile文件中追加： 123export JAVA_HOME=/usr/local/jdkexport CLASS_PATH=$JAVA_HOME/libexport PATH=$JAVA_HOME/bin:$PATH 使设置的环境变量生效。 source /etc/profile 安装 Elasticsearch 在https://www.elastic.co/downloads中下载Elasticsearch的安装包。 解压，并移动到/usr/local/elasticsearch目录下。 12$ tar xvf elasticsearch-2.4.1.zip$ mv elasticsearch-2.4.1 /usr/local/elasticsearch 修改/usr/local/elasticsearch/config/elasticsearch.yml，来更改监听端口，监听127.0.0.1，提高安全性。 12# 如下更改network.host: 127.0.0.1 启动（会有报错） 1234$ cd /usr/local/elasticsearch/$ bash bin/elasticsearch -d# 会有报错，信息如下：Exception in thread \"main\" java.lang.RuntimeException: don't run elasticsearch as root. -d是让es保持后台运行。报错信息提示我们es无法用root用户启动，所以可以创建elk用户，来启动es 安装 kibana 在https://www.elastic.co/downloads中下载kibana的安装包。 解压，并移动到/usr/local/kibana目录下。 修改/usr/local/kibana/config/kibana.yml，来更改监听端口，监听127.0.0.1 12# 修改如下server.host: \"127.0.0.1\" 启动，观察/usr/local/kibana/nohup.out是否有报错信息 12$ cd /usr/local/kibana$ nohup bin/kibana &amp; 安装 Nginx 直接yum安装 1$ yum install nginx 修改/etc/nginx/conf.d/default.conf文件，如下： 12345678910111213141516171819server &#123; listen 80; server_name _; location / &#123; proxy_pass http://127.0.0.1:5601/; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection 'upgrade'; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade;&#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125;&#125; 启动nginx 1234# 测试配置是否正常$ nginx -t# 启动$ /etc/init.d/nginx start 安装 Logstash 在https://www.elastic.co/downloads中下载Logstash的安装包。 解压，并移动到/usr/local/logstash目录下。 验证服务可用性 12345678$ cd /usr/local/logstash$ bin/logstash -e 'input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;'Settings: Default pipeline workers: 2Pipeline main started# 任意输入，看输出是否正常，如下：hello2016-10-13T10:07:01.502Z satezheng hello# CTRL-D 退出 配置 Logstash我们需要配置 Logstash 以指明从哪里读取数据，向哪里输出数据。这个过程我们称之为定义 Logstash 管道（Logstash Pipeline）。通常一个管道需要包括必须的输入（input），输出（output），和一个可选项目 Filter 配置 ssl客户端和服务器之间通信使用ssl来认证身份，更加安全。 修改/etc/pki/tls/openssl.cnf文件 12# 找到 [v3_ca] 段，添加下面一行，保存退出。subjectAltName = IP: logstash_server_ip 生成srt文件 12$ cd /etc/pki/tls$ openssl req -config openssl.cnf -x509 -days 2650 -batch -nodes -newkey rsa:2048 -keyout private/logstash-forwarder.key -out certs/logstash-forwarder.crt 发送srt文件到客户端 12$ cd /etc/pki/tls$ scp certs/logstash-forwarder.crt 客户端IP:/etc/pki/tls/certs 配置 Logstash 管道文件 创建filebeat-input.conf文件 12345678910111213$ mkdir /usr/local/logstash/conf$ cd /usr/local/logstash/conf$ vim filebeat-input.conf# 写入：input &#123; beats &#123; port =&gt; 5044 type =&gt; \"logs\" ssl =&gt; true ssl_certificate =&gt; \"/etc/pki/tls/certs/logstash-forwarder.crt\" ssl_key =&gt; \"/etc/pki/tls/private/logstash-forwarder.key\" &#125;&#125; 创建filebeat-output.conf文件 123456$ vim filebeat-input.conf# 写入：output &#123; elasticsearch &#123; hosts =&gt; [\"127.0.0.1:9200\"] &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; 启动12$ cd /usr/local/logstash$ nohup bin/logstash -f conf/ &amp; 客户端安装 filebeatfilebeat代替之前的ogstash-forwarder 在https://www.elastic.co/downloads/beats/filebeat下载 解压并放到/usr/local/filebeat目录下 修改filebeat.yml 12$ cd /usr/local/filebeat$ vim filebeat.yml 写入： 1234567891011121314151617181920filebeat: prospectors: - paths: - /var/log/* input_type: log document_type: log registry_file: /var/lib/filebeat/registryoutput: logstash: hosts: [\"服务端IP:5044\"] tls: certificate_authorities: [\"/etc/pki/tls/certs/logstash-forwarder.crt\"]shipper:logging: files: rotateeverybytes: 10485760 # = 10MB 启动 12$ cd /usr/local/filebeat$ nohup ./filebeat -e -c filebeat.yml &amp; 访问服务端IP来验证是否成功，有问题可以根据输出日志来解决。","categories":[{"name":"ELK","slug":"ELK","permalink":"http://yoursite.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://yoursite.com/tags/ELK/"}]},{"title":"Docker基本命令","slug":"Docker命令","date":"2016-12-15T07:40:23.000Z","updated":"2016-12-15T07:41:04.000Z","comments":true,"path":"2016/12/15/Docker命令/","link":"","permalink":"http://yoursite.com/2016/12/15/Docker命令/","excerpt":"","text":"docker version ：查看docker的版本号，包括客户端、服务端、依赖的Go等 123456789101112131415161718[root@centos7 ~]# docker versionClient: Version: 1.8.2-el7.centos API version: 1.20 Package Version: docker-1.8.2-10.el7.centos.x86_64 Go version: go1.4.2 Git commit: a01dc02/1.8.2 Built: OS/Arch: linux/amd64Server: Version: 1.8.2-el7.centos API version: 1.20 Package Version: Go version: go1.4.2 Git commit: a01dc02/1.8.2 Built: OS/Arch: linux/amd64 docker info:查看系统(docker)层面信息，包括管理的images, containers数等 123456789101112131415161718192021222324252627282930[root@centos7 ~]# docker infoContainers: 1Images: 4Storage Driver: devicemapper Pool Name: docker-8:3-36786088-pool Pool Blocksize: 65.54 kB Backing Filesystem: xfs Data file: /dev/loop0 Metadata file: /dev/loop1 Data Space Used: 2.059 GB Data Space Total: 107.4 GB Data Space Available: 12.93 GB Metadata Space Used: 1.765 MB Metadata Space Total: 2.147 GB Metadata Space Available: 2.146 GB Udev Sync Supported: true Deferred Removal Enabled: false Data loop file: /var/lib/docker/devicemapper/devicemapper/data Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata Library Version: 1.02.107-RHEL7 (2015-10-14)Execution Driver: native-0.2Logging Driver: json-fileKernel Version: 3.10.0-327.el7.x86_64Operating System: CentOS Linux 7 (Core)CPUs: 1Total Memory: 977.9 MiBName: centos7ID: BUKD:MUW2:5X2D:G7BF:6Y7G:SKIH:LD6K:VUAC:3QA4:JY5C:S3DG:LFT2WARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled search 搜索镜像： 1234567[root@centos7 ~]# docker search ubuntu12.10INDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATEDdocker.io docker.io/chug/ubuntu12.10x32 Ubuntu Quantal Quetzal 12.10 32bit base i... 0 docker.io docker.io/chug/ubuntu12.10x64 Ubuntu Quantal Quetzal 12.10 64bit base i... 0 docker.io docker.io/marcgibbons/ubuntu12.10 0 docker.io docker.io/mirolin/ubuntu12.10 0 docker.io docker.io/mirolin/ubuntu12.10_redis 0 pull 下载镜像： 1[root@centos7 ~]# docker pull ubuntu run 使用镜像创建容器： 1[root@centos7 ~]# docker run ubuntu /bin/echo hello world run 创建容器，并交互式的运行：这里会创建一个新的容器。 1234[root@centos7 ~]# docker run -i -t ubuntu /bin/bashroot@c43c7d102baa:/# cat /etc/issueUbuntu 14.04.3 LTS \\n \\l# -t 选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i 则让容器的标准输入保持打开 当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 run -d 守护态运行：更多的时候，需要让 Docker 容器在后台以守护态（Daemonized）形式运行。此时，可以通过添加 -d 参数来实现。例如下面的命令会在后台运行容器。 1[root@centos7 ~]# docker run -d ubuntu /bin/bash -c \"while true;do echo hello world;sleep 1;done\" logs 查看容器的运行： 以上个例子为前导。12345678[root@centos7 ~]# docker logs 4f34f95b6abchello worldhello worldhello worldhello worldhello worldhello worldhello world ps 查看容器： 123456789101112131415161718[root@centos7 ~]# docker ps -hUsage: docker ps [OPTIONS]List containers -a, --all=false Show all containers (default shows just running) --before= Show only container created before Id or Name -f, --filter=[] Filter output based on conditions provided --format= Pretty-print containers using a Go template --help=false Print usage -l, --latest=false Show the latest created container, include non-running -n=-1 Show n last created containers, include non-running --no-trunc=false Don't truncate output -q, --quiet=false Only numeric IDs -s, --size=false Display total file sizes --since= Show created since Id or Name, include non-running attach 连接已经启动的容器 / start -i 启动并连接容器： 12345[root@centos7 ~]# docker ps -a #查看容器ID[root@centos7 ~]# docker start &lt;CONTAINER ID&gt; #启动容器[root@centos7 ~]# docker attach &lt;CONTAINER ID&gt; #连接容器，该容器必须是启动状态或者[root@centos7 ~]# docker start -i &lt;CONTAINER ID&gt; #启动并连接容器 注：但是使用 attach 命令有时候并不方便。当多个窗口同时 attach 到同一个容器的时候，所有窗口都会同步显示。当某个窗口因命令阻塞时,其他窗口也无法执行操作了。 commit 将容器的状态保存为镜像： 123456789[root@centos7 ~]# docker commit c43c7d102baa ubhttpd47bbf8e50bace073de2b256b0360cfab029c11881f0d361fce7ae7464aa40ff[root@centos7 ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEubhttp latest d47bbf8e50ba 54 seconds ago 248 MBdocker.io/ubuntu latest 8693db7e8a00 7 days ago 187.9 MB## 更为标准点的如下：$ sudo docker commit -m \"Added json gem\" -a \"Docker Newbee\" 0b2616b0e5a8 ouruser/sinatra:v2其中，-m 来指定提交的说明信息，跟我们使用的版本控制工具一样；-a 可以指定更新的用户信息；之后是用来创建镜像的容器的 ID；最后指定目标镜像的仓库名和 tag 信息。创建成功后会返回这个镜像的 ID 信息。 diff 命令查看容器内的文件变化： 它可以列出容器内发生变化的文件和目录。这些变化包括添加（A-add）、删除（D-delete）、修改（C-change） 1[root@centos7 ~]# docker diff c43c7d102baa cp 命令拷贝文件： 1234567891011#从docker中往本地拷贝文件[root@centos7 ~]# docker cp c43c7d102baa:/var/www/html/index.html /opt/ [root@centos7 ~]# ls /opt/index.html rh# 从本地往docker中拷贝文件[root@centos7 ~]# docker cp aa c43c7d102baa:/var[root@centos7 ~]# docker start -i c43c7d102baaroot@c43c7d102baa:/# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr varroot@c43c7d102baa:/# ls var/aa backups cache lib local lock log mail opt run spool tmp www inspect 收集有关容器和镜像的底层信息： Docker inspect命令可以收集有关容器和镜像的底层信息。这些信息包括： 容器实例的IP地址 端口绑定列表 特定端口映射的搜索 收集配置的详细信息 语法： 1docker inspect container/image kill 命令发送sigkill信号停止容器的主进程： 语法： 1docker kill [options] &lt;container_id&gt; rmi 移除一个或多个镜像： 12docker rmi &lt;image_id&gt;#注意：在删除镜像之前要先用 docker rm 删掉依赖于这个镜像的所有容器 wait 阻塞对指定容器的其它调用方法，直到容器停止后退出阻塞 1docker wait &lt;container_id&gt; tag 修改镜像的标签 123456789[root@centos7 ~]# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE&lt;none&gt; &lt;none&gt; f59c7e5b1817 18 hours ago 192 MBdocker.io/ubuntu latest 8693db7e8a00 7 days ago 187.9 MB[root@centos7 ~]# docker tag f59c7e5b1817 zwx/ub_mv:127 [root@centos7 ~]# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEzwx/ub_mv 127 f59c7e5b1817 18 hours ago 192 MBdocker.io/ubuntu latest 8693db7e8a00 7 days ago 187.9 MB docker的导入导出操作save 保存镜像为tar文件并发送到STDOUT: 123456[root@node2 ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEzwx_ub latest f59c7e5b1817 7 seconds ago 192 MBubuntu latest 8693db7e8a00 6 days ago 187.9 MB[root@node2 ~]# docker save f59c7e5b1817 &gt;zwx_ub.tar# 我将zwx_ub这个镜像导出成tar包，并拷贝到centos7的测试机中导入，导入过程在下边。 load 从tar文件中载入镜像或仓库到STDIN: 123456789101112[root@centos7 ~]# docker load -i zwx_ub.tar [root@centos7 ~]# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEubhttp latest d47bbf8e50ba About an hour ago 248 MB&lt;none&gt; &lt;none&gt; f59c7e5b1817 16 hours ago 192 MBdocker.io/ubuntu latest 8693db7e8a00 7 days ago 187.9 MB[root@centos7 ~]# docker run -it f59c7e5b1817root@e17558664f8d:/# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr varroot@e17558664f8d:/# ls /mnt/zwx# 可以看出，我导入zwx_ub这个镜像后，镜像ID并没有变化，我创建个容器并进入，发现打包前我创建的文件都在。 import 从本地文件系统导入一个镜像 比如，先下载了一个 ubuntu-14.04 的镜像，之后使用以下命令导入tar.gz的镜像可以在http://openvz.org/Download/template/precreated下载。 12345[root@centos7 ~]# cat ubuntu-14.04-x86_64-minimal.tar.gz |docker import - ubuntu:zwx23997a971195cdd826f16a50573e480e1be1679729636178146425cdd46d1b52[root@centos7 ~]# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEubuntu zwx 23997a971195 28 seconds ago 214.9 MB export 容器的导出 1234[root@centos7 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES16f568766019 ubuntu \"/bin/bash\" 52 minutes ago Up 45 minutes elegant_mcclintock[root@centos7 ~]# docker export 16f568766019 &gt;ubuntu.tar import 容器的导入： 可以将容器的tar文件再导入为镜像 1234$ cat ubuntu.tar | sudo docker import - test/ubuntu:v1.0$ sudo docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEtest/ubuntu v1.0 9d37a6082e97 About a minute ago 171.3 MB 此外，也可以通过指定 URL 或者某个目录来导入，例如 1$sudo docker import http://example.com/exampleimage.tgz example/imagerepo 注：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以使用 docker import 来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"Docker私有仓库","slug":"Docker私有仓库","date":"2016-12-15T07:39:33.000Z","updated":"2016-12-15T07:40:03.000Z","comments":true,"path":"2016/12/15/Docker私有仓库/","link":"","permalink":"http://yoursite.com/2016/12/15/Docker私有仓库/","excerpt":"","text":"安装私有仓库默认情况下，仓库会被创建在容器的 /tmp/registry 下。可以通过 -v 参数来将镜像文件存放在本地的指定路径。 例如下面的例子将上传的镜像放到 /opt/data/registry 目录。 1sudo docker run -d -p 5000:5000 -v /opt/data/registry:/tmp/registry registry 上传镜像创建好私有仓库之后，就可以使用 docker tag 来标记一个镜像，然后推送它到仓库，别的机器上就可以下载下来了。例如私有仓库地址为 192.168.0.1:5000。 1234$ sudo docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEsate/centos 6.7 976079dcc3f5 3 days ago 190.6 MBcentos 6.7 130db9a2a215 2 weeks ago 190.6 MB 使用docker tag 将 976079dcc3f5 这个镜像标记为 192.168.0.1:5000/sate-centos（格式为 docker tag IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG]）。 1234567$ docker tag 976079dcc3f5 192.168.0.1:5000/sate-centos:test$ docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE192.168.0.1:5000/sate-centos test 976079dcc3f5 3 days ago 190.6 MBsate/centos 6.7 976079dcc3f5 3 days ago 190.6 MBcentos 6.7 130db9a2a215 2 weeks ago 190.6 MB 使用 docker push 上传标记的镜像。 12345$ docker push 192.168.0.1:5000/sate-centosThe push refers to a repository [192.168.0.1:5000/sate-centos] (len: 1)unable to ping registry endpoint https://192.168.0.1:5000/v0/v2 ping attempt failed with error: Get https://192.168.0.1:5000/v2/: EOF v1 ping attempt failed with error: Get https://192.168.0.1:5000/v1/_ping: EOF 注：报错是因为 docker 默认使用https的方式，解决办法如下： 办法： 修改配置文件，使用 http 方式 centos系统： 修改docker的配置文件/etc/sysconfig/docker 1234# 加入：INSECURE_REGISTRY='--insecure-registry 192.168.0.1:5000'# 重启服务systemctl restart docker ubuntu系统： 修改docker的配置文件/etc/default/docker 1234# 加入：DOCKER_OPTS='--insecure-registry 192.168.0.1:5000'# 重启服务service docker start 再次尝试 push 镜像，如下： 1234567891011$ sudo docker push 192.168.0.1:5000/testThe push refers to a repository [192.168.0.1:5000/test] (len: 1)Sending image listPushing repository 192.168.0.1:5000/test (1 tags)Image 511136ea3c5a already pushed, skippingImage 9bad880da3d2 already pushed, skippingImage 25f11f5fb0cb already pushed, skippingImage ebc34468f71d already pushed, skippingImage 2318d26665ef already pushed, skippingImage ba5877dc9bec already pushed, skippingPushing tag for rev [ba5877dc9bec] on &#123;http://192.168.0.1:5000/v1/repositories/test/tags/latest&#125; 当push成功后，查看本地目录/opt/data/registry: 12root@sate-z:/opt/data/registry# lsimages repositories 测试通过私仓的链接地址查看我们刚上传的镜像： 12$ curl http://192.168.0.1:5000/v1/search&#123;\"num_results\": 1, \"query\": \"\", \"results\": [&#123;\"description\": \"\", \"name\": \"library/sate-centos\"&#125;]&#125; 下载镜像用pull命令来拉取我们的镜像： 1$ docker pull 192.168.0.1:5000/sate-centos:test","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"Docker使用Dockerfile","slug":"Docker使用Dockerfile","date":"2016-12-15T07:38:36.000Z","updated":"2016-12-15T08:21:33.000Z","comments":true,"path":"2016/12/15/Docker使用Dockerfile/","link":"","permalink":"http://yoursite.com/2016/12/15/Docker使用Dockerfile/","excerpt":"","text":"使用 docker commit 来扩展一个镜像比较简单，但是不方便在一个团队中分享。我们可以使用 docker build 来创建一个新的镜像。为此，首先需要创建一个 Dockerfile，包含一些如何创建镜像的指令。 创建新的目录和dockerfile 123$ mkdir sinatra$ cd sinatra$ touch Dockerfile Dockerfile 中每一条指令都创建镜像的一层，例如： 123456# This is a comment # 使用#来注释FROM ubuntu:14.04 # FROM 指令告诉 Docker 使用哪个镜像作为基础MAINTAINER Docker Newbee &lt;newbee@docker.com&gt; # 接着是维护者的信息RUN apt-get -qq update # RUN开头的指令会在创建中运行，比如安装一个软件包，在这里使用 apt-get 来安装了一些软件RUN apt-get -qqy install ruby ruby-devRUN gem install sinatra 创建完成dockerfile后可以使用docker bulid 来生成镜像。 12345678910111213141516171819202122232425262728293031323334$ sudo docker build -t=\"ouruser/sinatra:v2\" .Uploading context 2.56 kBUploading contextStep 0 : FROM ubuntu:14.04 ---&gt; 99ec81b80c55Step 1 : MAINTAINER Newbee &lt;newbee@docker.com&gt; ---&gt; Running in 7c5664a8a0c1 ---&gt; 2fa8ca4e2a13Removing intermediate container 7c5664a8a0c1Step 2 : RUN apt-get -qq update ---&gt; Running in b07cc3fb4256 ---&gt; 50d21070ec0cRemoving intermediate container b07cc3fb4256Step 3 : RUN apt-get -qqy install ruby ruby-dev ---&gt; Running in a5b038dd127eSelecting previously unselected package libasan0:amd64.(Reading database ... 11518 files and directories currently installed.)Preparing to unpack .../libasan0_4.8.2-19ubuntu1_amd64.deb ...Setting up ruby (1:1.9.3.4) ...Setting up ruby1.9.1 (1.9.3.484-2ubuntu1) ...Processing triggers for libc-bin (2.19-0ubuntu6) ... ---&gt; 2acb20f17878Removing intermediate container a5b038dd127eStep 4 : RUN gem install sinatra ---&gt; Running in 5e9d0065c1f7. . .Successfully installed rack-protection-1.5.3Successfully installed sinatra-1.4.54 gems installed ---&gt; 324104cde6adRemoving intermediate container 5e9d0065c1f7Successfully built 324104cde6ad# 其中 -t 标记来添加 tag，指定新的镜像的用户信息。 “.” 是 Dockerfile 所在的路径（当前目录），也可以替换为一个具体的 Dockerfile 的路径。# dockerfile命名是固定的。 此外，还可以利用 ADD 命令复制本地文件到镜像；用 EXPOSE 命令来向外部开放端口；用 CMD 命令来描述容器启动后运行的程序等。例如 123456# put my local web site in myApp folder to /var/wwwADD myApp /var/www# expose httpd portEXPOSE 80# the command to runCMD [\"/usr/sbin/apachectl\", \"-D\", \"FOREGROUND\"]","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"Docker练习","slug":"Docker练习","date":"2016-12-15T07:36:00.000Z","updated":"2016-12-15T07:37:34.000Z","comments":true,"path":"2016/12/15/Docker练习/","link":"","permalink":"http://yoursite.com/2016/12/15/Docker练习/","excerpt":"","text":"安装系统：ubuntu 14.04 12345678910# 升级内核$ apt-get update$ apt-get install linux-headers-3.13.0-88-generic# 安装新版本的 docker$ sudo apt-get install apt-transport-https$ sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 36A1D7869245C8950F966E92D8576A8BA88D21E9$ deb https://get.docker.io/ubuntu docker main &gt; /etc/apt/sources.list.d/docker.list\"$ sudo bash -c \"echo deb https://get.docker.io/ubuntu docker main &gt; /etc/apt/sources.list.d/docker.list\"$ apt-get update$ apt-get install lxc-docker 下载 ubuntu 镜像1234$ docker pull ubuntu$ docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEubuntu latest 594b6e305389 3 weeks ago 122 MB 启动容器，并安装 nginx12$ docker run -i -t ubuntu /bin/bash在该 docker 容器中安装 nginx 将安装 nginx 的容器保存为镜像123456$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ecstatic_thompsonb5138a3e3352 ubuntu \"/bin/bash\" 2 hours ago Exited (0) 2 hours ago hopeful_perlmanroot@sate-z:~#$ docker commit -m \"nginx/ubuntu\" -a \"sate\" b5138a3e3352 ubuntu-nginx:v1-m 备注 -a 用户名 ubuntu-nginx:v1 镜像名称和TAG 名称 用新创建的镜像，开一个新的容器，并映射端口12$ docker run -i -t -p 90:80 ubuntu-nginx:v1 /bin/bash# 在该 docker 中启动 nginx 。可能需要自己写 nginx 的conf文件，访问宿主机的 ip:90，就可以访问到 docker 中的网站 问题现在有个问题就是如何让 docker 容器在后台运行。 还有就是 ansible 如何控制 docker。 有一个可以后台运行的方法是安装 sshd 服务，然后以-D方式启动，但感觉应该还有更好的办法 12$ apt-get install openssh-server openssh-client$ docker run -d -p 50001:22 ubuntu/ruby:v2 /usr/sbin/sshd -D","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"Docker的安装","slug":"Docker的安装","date":"2016-12-15T07:34:30.000Z","updated":"2016-12-15T07:35:24.000Z","comments":true,"path":"2016/12/15/Docker的安装/","link":"","permalink":"http://yoursite.com/2016/12/15/Docker的安装/","excerpt":"","text":"centos 6.5 中docker的安装 yum 源安装 1$ yum install docker-io 启动 1$ /etc/init.d/docker start 日志中报错 123time=\"2016-01-19T14:21:25.993968299+08:00\" level=warning msg=\"You are running linux kernel version 2.6.32-431.el6.x86_64, which might be unstable running docker. Please upgrade your kernel to 3.10.0.\" time=\"2016-01-19T14:21:25.997212022+08:00\" level=info msg=\"Listening for HTTP on unix (/var/run/docker.sock)\" /usr/bin/docker: relocation error: /usr/bin/docker: symbol dm_task_get_info_with_deferred_remove, version Base not defined in file libdevmapper.so.1.02 with link time reference 日志可以看出，一个warning和一个error。 warning中指出我的kernel版本可能运行docker不稳定，建议我升级到3.10版本。 error的报错可以通过升级device-mapper-libs解决。1yum upgrade device-mapper-libs centos 7 中docker的安装 yum 源安装 1$ yum install docker","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"Docker容器的连接","slug":"Docker容器的连接","date":"2016-12-15T07:32:33.000Z","updated":"2016-12-15T07:34:08.000Z","comments":true,"path":"2016/12/15/Docker容器的连接/","link":"","permalink":"http://yoursite.com/2016/12/15/Docker容器的连接/","excerpt":"","text":"连接docker容器的三种方式attach 参数12345[root@centos7 ~]# docker ps -a #查看容器ID[root@centos7 ~]# docker start &lt;CONTAINER ID&gt; #启动容器[root@centos7 ~]# docker attach &lt;CONTAINER ID&gt; #连接容器，该容器必须是启动状态或者[root@centos7 ~]# docker start -i &lt;CONTAINER ID&gt; #启动并连接容器 注：但是使用 attach 命令有时候并不方便。当多个窗口同时 attach 到同一个容器的时候，所有窗口都会同步显示。当某个窗口因命令阻塞时,其他窗口也无法执行操作了。 nsenter 命令安装 nsenter 工具在 util-linux 包2.23版本后包含。 如果系统中 util-linux 包没有该命令，可以按照下面的方法从源码安装。 123$ cd /tmp; curl https://www.kernel.org/pub/linux/utils/util-linux/v2.24/util-linux-2.24.tar.gz | tar -zxf-; cd util-linux-2.24;$ ./configure --without-ncurses$ make nsenter &amp;&amp; sudo cp nsenter /usr/local/bin 使用 为了连接到容器，你还需要找到容器的第一个进程的 PID，可以通过下面的命令获取。 1PID=$(docker inspect --format \"&#123;&#123; .State.Pid &#125;&#125;\" &lt;container&gt;) 通过这个 PID，就可以连接到这个容器： 1$ nsenter --target $PID --mount --uts --ipc --net --pid 实例 1234567[root@centos7 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES16f568766019 ubuntu \"/bin/bash\" 34 minutes ago Up 28 minutes elegant_mcclintock[root@centos7 ~]# docker inspect --format \"&#123;&#123; .State.Pid &#125;&#125;\" 16f56876601919803[root@centos7 ~]# nsenter --target 19803 --mount --uts --ipc --net --pidroot@16f568766019:/# .bashrc_docker 脚本其实就是从docker inspect中取相关的数据，具体的脚本代码在最后贴出。 12$ wget -P ~ https://github.com/yeasy/docker_practice/raw/master/_local/.bashrc_docker;$ echo \"[ -f ~/.bashrc_docker ] &amp;&amp; . ~/.bashrc_docker\" &gt;&gt; ~/.bashrc; source ~/.bashrc 这个文件中定义了很多方便使用 Docker 的命令，例如 docker-pid 可以获取某个容器的 PID；而 docker-enter 可以进入容器或直接在容器内执行命令。 123456[root@centos7 ~]# docker-pid 16f56876601919803 [root@centos7 ~]# docker-ip 16f568766019172.17.0.8[root@centos7 ~]# docker-enter 16f568766019 unameLinux 脚本内容： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# Some useful commands to use docker.# Author: yeasy@github# Created:2014-09-25alias docker-pid=\"sudo docker inspect --format '&#123;&#123;.State.Pid&#125;&#125;'\"alias docker-ip=\"sudo docker inspect --format '&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;'\"#the implementation refs from https://github.com/jpetazzo/nsenter/blob/master/docker-enterfunction docker-enter() &#123; #if [ -e $(dirname \"$0\")/nsenter ]; then #Change for centos bash running if [ -e $(dirname '$0')/nsenter ]; then # with boot2docker, nsenter is not in the PATH but it is in the same folder NSENTER=$(dirname \"$0\")/nsenter else # if nsenter has already been installed with path notified, here will be clarified NSENTER=$(which nsenter) #NSENTER=nsenter fi [ -z \"$NSENTER\" ] &amp;&amp; echo \"WARN Cannot find nsenter\" &amp;&amp; return if [ -z \"$1\" ]; then echo \"Usage: `basename \"$0\"` CONTAINER [COMMAND [ARG]...]\" echo \"\" echo \"Enters the Docker CONTAINER and executes the specified COMMAND.\" echo \"If COMMAND is not specified, runs an interactive shell in CONTAINER.\" else PID=$(sudo docker inspect --format \"&#123;&#123;.State.Pid&#125;&#125;\" \"$1\") if [ -z \"$PID\" ]; then echo \"WARN Cannot find the given container\" return fi shift OPTS=\"--target $PID --mount --uts --ipc --net --pid\" if [ -z \"$1\" ]; then # No command given. # Use su to clear all host environment variables except for TERM, # initialize the environment variables HOME, SHELL, USER, LOGNAME, PATH, # and start a login shell. #sudo $NSENTER \"$OPTS\" su - root sudo $NSENTER --target $PID --mount --uts --ipc --net --pid su - root else # Use env to clear all host environment variables. sudo $NSENTER --target $PID --mount --uts --ipc --net --pid env -i $@ fi fi&#125;","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"Ansible的Ad-Hoc","slug":"Ansible的Ad-Hoc","date":"2016-12-15T07:29:10.000Z","updated":"2016-12-15T07:29:42.000Z","comments":true,"path":"2016/12/15/Ansible的Ad-Hoc/","link":"","permalink":"http://yoursite.com/2016/12/15/Ansible的Ad-Hoc/","excerpt":"","text":"我们经常会通过命令行形式来使用 ansible， ansible 会自带很多模块. 查看 ansible 自带模块和模块介绍的方法如下： 12$ ansible-doc -l #列出所有模块$ ansible-doc shell #查看 shell 模块的详细信息 复制文件12345678910111213141516# 文件的变化是通过 md5值来判断的。$ ansible sate -m copy -a \"src=./mysql_back.py dest=/mnt/ owner=root group=root mode=644 backup=yes\"120.26.45.230 | SUCCESS =&gt; &#123; \"changed\": true, \"checksum\": \"1c332293fa02633b42ffcd10faddafc2d44083c0\", \"dest\": \"/mnt/mysql_back.py\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"46959dcafe35d9b727075237fbb8a3a0\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 1589, \"src\": \"/root/.ansible/tmp/ansible-tmp-1465968433.17-146914892008272/source\", \"state\": \"file\", \"uid\": 0&#125; 包和服务管理1234567891011121314151617# 安装 nginx 服务$ ansible sate -m apt -a \"name=nginx state=latest\"# 服务的启动与关闭$ ansible sate -m service -a \"name=nginx state=started\"120.26.45.230 | SUCCESS =&gt; &#123; \"changed\": false, \"name\": \"nginx\", \"state\": \"started\"&#125;$ ansible sate -m service -a \"name=nginx state=stopped\"120.26.45.230 | SUCCESS =&gt; &#123; \"changed\": true, \"name\": \"nginx\", \"state\": \"stopped\"&#125; 用户管理1234567891011121314151617181920212223# 先将要设置的账户密码进行加密$ echo sate | openssl passwd -1 -stdin$1$xZGhHuDC$7yx6FmawND4yEKLkr35o20# 通过 ansible 创建新的用户$ ansible sate -m user -a 'name=sate password=\"$1$xZGhHuDC$7yx6FmawND4yEKLkr35o20\"'120.26.45.230 | SUCCESS =&gt; &#123; \"changed\": true, \"comment\": \"\", \"createhome\": true, \"group\": 1000, \"home\": \"/home/sate\", \"name\": \"sate\", \"password\": \"NOT_LOGGING_PASSWORD\", \"shell\": \"\", \"state\": \"present\", \"stderr\": \"useradd: warning: the home directory already exists.\\nNot copying any file from skel directory into it.\\n\", \"system\": false, \"uid\": 1000&#125;# 测试$ ssh sate@120.26.45.230","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/tags/Ansible/"}]},{"title":"Ansible的facts","slug":"Ansible的facts","date":"2016-12-15T07:27:34.000Z","updated":"2016-12-15T07:28:14.000Z","comments":true,"path":"2016/12/15/Ansible的facts/","link":"","permalink":"http://yoursite.com/2016/12/15/Ansible的facts/","excerpt":"","text":"facts 组件是 ansible 用于采集被管理机器信息的一个功能，我们可以使用setup模块查询机器所有的 facts 信息，也可以使用filter来查询指定信息。输出的是 JSON 格式。 12345678910111213141516171819202122232425262728293031323334353637383940414243root@sate-z:~# ansible sate -m setup10.117.214.178 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"ansible_all_ipv4_addresses\": [ \"10.117.214.178\", \"120.26.45.230\" ], \"ansible_all_ipv6_addresses\": [], \"ansible_architecture\": \"x86_64\", \"ansible_bios_date\": \"12/16/2014\", \"ansible_bios_version\": \"4.0.1\", \"ansible_cmdline\": &#123; \"BOOT_IMAGE\": \"/boot/vmlinuz-3.13.0-65-generic\", \"quiet\": true, \"ro\": true, \"root\": \"UUID=af414ad8-9936-46cd-b074-528854656fcd\", \"splash\": true &#125;, \"ansible_date_time\": &#123; \"date\": \"2016-06-16\", \"day\": \"16\", \"epoch\": \"1466049222\", \"hour\": \"11\", \"iso8601\": \"2016-06-16T03:53:42Z\", \"iso8601_basic\": \"20160616T115342839628\", \"iso8601_basic_short\": \"20160616T115342\", \"iso8601_micro\": \"2016-06-16T03:53:42.839785Z\", \"minute\": \"53\", \"month\": \"06\", \"second\": \"42\", \"time\": \"11:53:42\", \"tz\": \"CST\", \"tz_offset\": \"+0800\", \"weekday\": \"Thursday\", \"weekday_number\": \"4\", \"weeknumber\": \"24\", \"year\": \"2016\" &#125;, \"ansible_default_ipv4\": &#123; \"address\": \"120.26.45.230\", ..... ..... .....(省略 N 行) 使用filter查看指定信息： 1234567891011121314151617181920212223242526root@sate-z:~# ansible sate -m setup -a \"filter=ansible_date_time\"10.117.214.178 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"ansible_date_time\": &#123; \"date\": \"2016-06-16\", \"day\": \"16\", \"epoch\": \"1466049323\", \"hour\": \"11\", \"iso8601\": \"2016-06-16T03:55:23Z\", \"iso8601_basic\": \"20160616T115523414703\", \"iso8601_basic_short\": \"20160616T115523\", \"iso8601_micro\": \"2016-06-16T03:55:23.414901Z\", \"minute\": \"55\", \"month\": \"06\", \"second\": \"23\", \"time\": \"11:55:23\", \"tz\": \"CST\", \"tz_offset\": \"+0800\", \"weekday\": \"Thursday\", \"weekday_number\": \"4\", \"weeknumber\": \"24\", \"year\": \"2016\" &#125; &#125;, \"changed\": false&#125; facts 默认收集了很多的设备基础信息，这些信息可以在做配置管理的时候引用。可以直接把 facts 信息直接当做 playbook 变量信息引用。比如后边的 nginx的 playbook 的练习中，nginx.conf.j2这个模板配置文件中的worker_processes这个参数的取值就是用该方法获得的。 1234$ cat nginx.conf.j2| head -n 3user www-data;worker_processes &#123;&#123; ansible_processor_cores &#125;&#125;;pid /run/nginx.pid;","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/tags/Ansible/"}]},{"title":"Ansible的Inventory","slug":"Ansible的Inventory","date":"2016-12-15T07:25:42.000Z","updated":"2016-12-15T07:27:03.000Z","comments":true,"path":"2016/12/15/Ansible的Inventory/","link":"","permalink":"http://yoursite.com/2016/12/15/Ansible的Inventory/","excerpt":"","text":"单个Inventory文件的使用： 我们用 ansible 来管理的机器信息都放在 Inventory 文件中，默认的 Inventory 是一个静态的 INI 格式的文件 /etc/ansible/hosts。 我们可以通过 ANSIBLE_HOSTS 环境变量来制定该文件，或者在运行 ansible 和 ansible-playbook 的时候用-i参数临时设置。 常用的定义主机和主机组的方式： 123456789101112131415# 定义了两个主机，使用 Inventory 内置变量定义了 SSH 登录时的密码192.168.0.1 ansible_ssh_pass='123456'192.168.0.2 ansible_ssh_pass='123456'# 定义了一个 sate 组，并且组中 IP 为192.168.0.101-192.168.0.103 三台机器[sate]192.168.0.10[1:3]# 对上边的 sate 组使用 Inventory 内置变量定义了 SSH 登录密码[sate:vars]ansible_ssh_pass='123456'# 定义了一个 ansible 组，这个组下面包含 docker 组。[ansible:children]sate 多个Inventory文件： Ansible 支持多个 Inventory 文件，我们可以修改ansible.cfg文件，如下，或者使用ANSIBLE_HOSTS环境变量定义。 12# 修改 ansible.cfg 中 inventory 的值inventory = /etc/inventory/ 这样我们可以在/etc/inventory/目录下放入多个 Inventory 文件 动态Inventory文件： 可能在实际情况下会有大量的主机列表，手动维护比较困难。动态 Inventory 就是 Ansible 所有的 Inventory 文件里边的主机列表和变量信息都支持从外部拉取,比如 CMDB 系统或者 zabbix 系统。配置的时候我们需要将ansible.cfg文件中的inventory的定义值改成一个执行脚本。 执行脚本没有编程语言上种类的限制，但是脚本必须支持两个参数，如下： --list或者-l,这个参数运行后会显示所有的主机以及主机组的信息 --host或者-H，这个参数后面需要指定一个 host，运行结果会返回这台主机的所有信息（包括认证信息、主机变量等），也是 JSON 格式。 常用的 Inventory 内置参数参数 | 解释 | 例子 —————- |—————–|———————————–|ansible_ssh_host| 定义 host ssh 地址 |ansible_ssh_host=192.168.0.1 |ansible_ssh_port| 定义 hosts ssh 端口| ~ =5000ansible_ssh_user| 定义 ssh 认证用户 | ~ =sateansible_ssh_pass| 定义 ssh 认证密码 | ~ =’password’ansible_sudo | 定义 sudo 用户 | ~ =sateansible_sudo_pass| 定义 sudo 密码| ~ =’password’ansible_sudo_exe|定义 sudo 路径| ~ =/usr/bin/sudoansible_connection|定义 hosts 连接方式| ~ =localansible_ssh_private_key_file|定义 hosts 私钥|~ =/root/keyansible_shell_type|定义 shell 类型|~ =zshansible_pythoninterpreter| 定义 执行 python 路径|~ =/usr/bin/python2.7ansible\\*_interpreter|定义其他语言解析器路径|~ =/usr/bin/ruby","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/tags/Ansible/"}]},{"title":"Ansible的playbook","slug":"Ansible的playbook","date":"2016-12-15T07:22:15.000Z","updated":"2016-12-15T07:24:48.000Z","comments":true,"path":"2016/12/15/Ansible的playbook/","link":"","permalink":"http://yoursite.com/2016/12/15/Ansible的playbook/","excerpt":"","text":"案例： 部署 nginx 服务。 Inventory hosts 文件 1234[sate]192.168.0.1[sate:vars]ansible_python_interpreter=/usr/bin/python2.7 nginx.conf.j2 模板文件 1234$ cat nginx.conf.j2| head -n 3user www-data;worker_processes &#123;&#123; ansible_processor_cores &#125;&#125;;pid /run/nginx.pid; 部署nignx的 playbook 1234567891011121314---- hosts: sate tasks: - name: install nginx apt: name=nginx state=present - name: copy nginx.conf template: src=./nginx.conf.j2 dest=/etc/nginx/nginx.conf owner=root group=root mode=0644 validate='nginx -t -c %s' notify: - restart nginx handlers: - name : restart nginx service: name=nginx state=restarted 检查语法 1$ ansible-playbook nginx.yaml --syntax-check","categories":[{"name":"Anisble","slug":"Anisble","permalink":"http://yoursite.com/categories/Anisble/"}],"tags":[{"name":"Anisble","slug":"Anisble","permalink":"http://yoursite.com/tags/Anisble/"}]},{"title":"Ansible简单使用","slug":"Ansible简单使用","date":"2016-12-15T07:20:43.000Z","updated":"2016-12-15T07:21:42.000Z","comments":true,"path":"2016/12/15/Ansible简单使用/","link":"","permalink":"http://yoursite.com/2016/12/15/Ansible简单使用/","excerpt":"","text":"介绍Ansible是新出现的运维工具是基于Python研发的，糅合了众多老牌运维工具的优点实现了批量操作系统配置、批量程序的部署、批量运行命令等功能。 安装实验环境： 12 系统：centos 6.5 机器：node1（192.168.174.128），node2（192.168.174.129） 安装： 1[root@node1 ~]# yum -y install ansible 基本使用定义Host Inventory ： 123[root@node1 ~]# cat /etc/ansible/hosts[node]192.168.174.129 操作实例： 12345[root@node1 ~]# ansible -i /etc/ansible/hosts nodetest -m command -a 'date'192.168.174.129 | success | rc=0 &gt;&gt;Mon Oct 12 13:23:56 CST 2015注：-i 使用默认hosts，该参数可以省略该命令执行成功的前提是先通过ssh-copy-id同步ssh key认证。如果没有，则需要加-k参数（需要安装sshpass）。 命令常用参数 123456789101112-m 导入模块-i 指定host-u 指定远程用户-s 使用sudo-k 询问密码例：$ ansible -i /xx/hosts wx-test -m ping -u zyadmin -s -kSSH password:xxx.xxx.xxx.x | success &gt;&gt; &#123;\"changed\": false,\"ping\": \"pong\"&#125; 如果客户端服务器的端口和用户名不为默认的22和root，也可以在hosts这样写： 12345[group name]wx-sate1 ansible_ssh_host=xxx.xx.xxx.x ansible_ssh_port=3544 ansible_ssh_user=satewx-sate2 ansible_ssh_host=xx.xxx.xx.xx ansible_ssh_port=4002 ansible_ssh_user=zyadmin例：$ ansible -i /xx/hosts wx-sate1 -m ping","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/tags/Ansible/"}]},{"title":"Ansible安装","slug":"Ansible安装","date":"2016-12-15T07:18:57.000Z","updated":"2016-12-15T07:20:10.000Z","comments":true,"path":"2016/12/15/Ansible安装/","link":"","permalink":"http://yoursite.com/2016/12/15/Ansible安装/","excerpt":"","text":"分两大类，源码安装和用包管理安装 源码安装一、 从GitHub 源码库安装 1、提取 ansible 源码 123$ git clone git@github.com:ansible/ansible.git --recursive$ cd ./ansible$ source ./hacking/env-setup -q #-q 参数可以减少安装过程中的告警/错误信息输出 2、安装对应python版本的pip 1$ sudo easy_install pip 3、安装ansible 控制主机需要的Python模板 1$ sudo pip install paramiko PyYAML Jinja2 httplib2 six 4、当更新Ansible 版本时，不但要更新git源码树，还要更新git中指向ansible 自身的模块，称为 submodules 12$ git pull --rebase$ git submodule update --init --recursive 5、一旦运行env-setup 脚本，就意味着ansible从源码中运行起来了。 二、Tar 包安装方式 可以在Http://release.ansible.com/ansible 中下载 Tar 包，安装过程和上边源码安装方式一样。 三、制作RPM 包安装 在 github 中提取代码或者直接下载 tar 包，使用 make rpm 命令创建 RPM 软件包。不过确保已经安装了 rpm-bulid、make、python2-devel 组件。 1234$ git clone git@github.com:ansible/ansible.git$ cd ./ansible$ make rpm$ sudo rpm -Uvh ~ /rpmbulid/ansible-*.noarch.rpm 用包管理工具安装（方便）一、yum 方式安装 对于 RHEL、CentOS 的官方 yum 源中没有 ansible 包，或者比较老旧,所以先安装支持第三方的 yum 仓库组件，最常用的有 EPEL、Remi、RPMForge 等。 下面安装 EPEL 作为部署 ansible 的默认 yum 源。 12345678910# RHEL(CentOS)5rpm -Uvh http://mirrors.zju.edu.cn/epel/5/i386/epel-release-5-4.noarch.rpmrpm -Uvh http://mirrors.zju.edu.cn/epel/5/x86_64/epel-release-5-4.noarch.rpm# RHEL(CentOS)6rpm -Uvh http://mirrors.zju.edu.cn/epel/6/i386/epel-release-6-8.noarch.rpmrpm -Uvh http://mirrors.zju.edu.cn/epel/6/x86_64/epel-release-6-8.noarch.rpm# RHEL(CentOS)7rpm -Uvh http://mirrors.zju.edu.cn/epel/7/x86_64/e/epel-release-7-6.noarch.rpm 准备好 yum 源后，直接 yum 安装 1$ yum install ansible 二、Apt（Ubuntu）方式安装 1234$ apt-get install software-properties-common$ apt-add-repository ppa:ansible/ansible$ apt-get update$ apt-get install ansible 三、Homebrew（Mac OSX）安装方式 在 MAC 系统确保安装 Homebrew，直接使用下面命令安装： 12$ brew update$ brew install Ansible 四、pip 方式安装 12$ sudo easy_install pip$ sudo pip install ansible","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/tags/Ansible/"}]},{"title":"Linux客户端连接(PPTP)VPN","slug":"PPTP客户端","date":"2016-12-15T06:58:37.000Z","updated":"2016-12-15T07:09:09.000Z","comments":true,"path":"2016/12/15/PPTP客户端/","link":"","permalink":"http://yoursite.com/2016/12/15/PPTP客户端/","excerpt":"","text":"环境 Ubuntu 12.04.4pptp version 1.7.2 安装1apt-get install pptp-linux 创建连接帐号1sudo pptpsetup --create myvpn --server xxx.xxx.xxx.xxx --username xxx --password xxxxx --encrypt 连接VPN12345678#打开vpnpon myvpn#查看当前路由规则route#删除老的defaultroute del default#创建新的路由规则route add default gw 192.168.250.1 pon myvpn成功时会生成ppp0： 关闭VPN12345678#关闭vpnpoff myvpn#查看当前路由规则route#删除刚加的default规则（关闭vpn时，刚加的默认路由已经删除，此步可忽略）route del default#还原以前的路由规则route add default gw 121.197.7.254","categories":[{"name":"Linux工具","slug":"Linux工具","permalink":"http://yoursite.com/categories/Linux工具/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"VPN","slug":"VPN","permalink":"http://yoursite.com/tags/VPN/"}]},{"title":"Tcpdump命令使用","slug":"Tcpdump命令使用","date":"2016-12-15T06:55:55.000Z","updated":"2016-12-15T07:11:41.000Z","comments":true,"path":"2016/12/15/Tcpdump命令使用/","link":"","permalink":"http://yoursite.com/2016/12/15/Tcpdump命令使用/","excerpt":"","text":"tcpdump命令是一款sniffer工具，它可以打印所有经过网络接口的数据包的头信息，也可以使用-w选项将数据包保存到文件中，方便以后分析。 语法1tcpdump(选项) 选项12345678910111213141516171819202122232425-a：尝试将网络和广播地址转换成名称；-c&lt;数据包数目&gt;：收到指定的数据包数目后，就停止进行倾倒操作；-d：把编译过的数据包编码转换成可阅读的格式，并倾倒到标准输出；-dd：把编译过的数据包编码转换成C语言的格式，并倾倒到标准输出；-ddd：把编译过的数据包编码转换成十进制数字的格式，并倾倒到标准输出；-e：在每列倾倒资料上显示连接层级的文件头；-f：用数字显示网际网络地址；-F&lt;表达文件&gt;：指定内含表达方式的文件；-i&lt;网络界面&gt;：使用指定的网络截面送出数据包；-l：使用标准输出列的缓冲区；-n：不把主机的网络地址转换成名字；-N：不列出域名；-O：不将数据包编码最佳化；-p：不让网络界面进入混杂模式；-q ：快速输出，仅列出少数的传输协议信息；-r&lt;数据包文件&gt;：从指定的文件读取数据包数据；-s&lt;数据包大小&gt;：设置每个数据包的大小；-S：用绝对而非相对数值列出TCP关联数；-t：在每列倾倒资料上不显示时间戳记；-tt： 在每列倾倒资料上显示未经格式化的时间戳记；-T&lt;数据包类型&gt;：强制将表达方式所指定的数据包转译成设置的数据包类型；-v：详细显示指令执行过程；-vv：更详细显示指令执行过程；-x：用十六进制字码列出数据包资料；-w&lt;数据包文件&gt;：把数据包数据写入指定的文件。 实例直接启动tcpdump将监视第一个网络接口上所有流过的数据包 1tcpdump 监视指定网络接口的数据包 1tcpdump -i eth1 如果不指定网卡，默认tcpdump只会监视第一个网络接口，一般是eth0，下面的例子都没有指定网络接口。 监视指定主机的数据包 打印所有进入或离开sundown的数据包。 1tcpdump host sundown 也可以指定ip,例如截获所有210.27.48.1 的主机收到的和发出的所有的数据包 1tcpdump host 210.27.48.1 打印helios 与 hot 或者与 ace 之间通信的数据包 123tcpdump host helios and \\( hot or ace \\)``` - 截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信 tcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 )1- 打印ace与任何其他主机之间通信的IP 数据包, 但不包括与helios之间的数据包. tcpdump ip host ace and not helios1- 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令： tcpdump ip host 210.27.48.1 and ! 210.27.48.21- 截获主机hostname发送的所有数据 tcpdump -i eth0 src host hostname1- 监视所有送到主机hostname的数据包 tcpdump -i eth0 dst host hostname123** 监视指定主机和端口的数据包**- 如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令 tcpdump tcp port 23 host 210.27.48.11- 对本机的udp 123 端口进行监视 123 为ntp的服务端口 tcpdump udp port 123123** 监视指定网络的数据包**- 打印本地主机与Berkeley网络上的主机之间的所有通信数据包 tcpdump net ucb-ether123 ucb-ether此处可理解为“Berkeley网络”的网络地址，此表达式最原始的含义可表达为：打印网络地址为ucb-ether的所有数据包- 打印所有通过网关snup的ftp数据包 tcpdump ‘gateway snup and (port ftp or ftp-data)’123 注意：表达式被单引号括起来了，这可以防止shell对其中的括号进行错误解析- 打印所有源地址或目标地址是本地主机的IP数据包 tcpdump ip and not net localnet``` 如果本地网络通过网关连到了另一网络，则另一网络并不能算作本地网络。","categories":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://yoursite.com/categories/Linux命令/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"Tcpdump","slug":"Tcpdump","permalink":"http://yoursite.com/tags/Tcpdump/"}]},{"title":"Strace命令分析","slug":"Strace命令分析","date":"2016-12-15T06:52:07.000Z","updated":"2016-12-15T07:11:17.000Z","comments":true,"path":"2016/12/15/Strace命令分析/","link":"","permalink":"http://yoursite.com/2016/12/15/Strace命令分析/","excerpt":"","text":"strace是个很好用的诊断手段，该文章整合了自己查找的比较好的网络资料和一些自己的理解，作为记录和学习。借鉴网址：http://man.linuxde.net/strace Strace命令是个集诊断、调试、统计与一体的工具，我们可以使用strace对应用的系统调用和信号传递的跟踪结果来对应用进行分析，以达到解决问题或者是了解应用工作过程的目的。语法&amp;释义： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@node2 ~]# strace -husage: strace [-dDffhiqrtttTvVxx] [-a column] [-e expr] ... [-o file] [-p pid] ... [-s strsize] [-u username] [-E var=val] ... [command [arg ...]] or: strace -c [-D] [-e expr] ... [-O overhead] [-S sortby] [-E var=val] ... [command [arg ...]]-c -- count time, calls, and errors for each syscall and report summary 统计每一系统调用的所执行的时间,次数和出错的次数等.-f -- follow forks, -ff -- with output into separate files -f 跟踪由fork产生的子进程 -ff 常与-o选项一起使用，不同进程(子进程)产生的系统调用输出到filename.PI,D文件如果提供-o filename,则所有进程的跟踪结果输出到相应的filename.pid中,pid是各进程的进程号.-F -- attempt to follow vforks, -h -- print help message 尝试跟踪vfork调用。在-f时，vfork不被跟踪-i -- print instruction pointer at time of syscall 输出系统调用的入口指针-q -- suppress messages about attaching, detaching, etc. 禁止输出关于脱离的消息-r -- print relative timestamp 打印每个系统调用的相对时间 -t -- absolute timestamp, -tt -- with usecs 在输出中的每一行前加上时间信息 -tt 时间确定到微秒级-T -- print time spent in each syscall, -V -- print version 显示每个调用的花费时间-v -- verbose mode: print unabbreviated argv, stat, termio[s], etc. args 输出所有的系统调用.一些调用关于环境变量,状态,输入输出等调用由于使用频繁,默认不输出.-x -- print non-ascii strings in hex, -xx -- print all strings in hex 以十六进制形式输出非标准字符串 -xx 所有字符串以十六进制形式输出-a column -- alignment COLUMN for printing syscall results (default 40) 设置返回值的输出位置.默认 为40.-e expr -- a qualifying expression: option=[!]all or option=[!]val1[,val2]... options: trace, abbrev, verbose, raw, signal, read, or write -e expr 指定一个表达式,用来控制如何跟踪.格式：[qualifier=][!]value1[,value2]... qualifier只能是 trace,abbrev,verbose,raw,signal,read,write其中之一.value是用来限定的符号或数字.默认的 qualifier是 trace.感叹号是否定符号.例如:-eopen等价于 -e trace=open,表示只跟踪open调用.而-etrace!=open 表示跟踪除了open以外的其他调用.有两个特殊的符号 all 和 none. 注意有些shell使用!来执行历史记录里的命令,所以要使用\\\\. -e trace=set 只跟踪指定的系统 调用.例如:-e trace=open,close,rean,write表示只跟踪这四个系统调用.默认的为set=all. -e trace=file 只跟踪有关文件操作的系统调用. -e trace=process 只跟踪有关进程控制的系统调用. -e trace=network 跟踪与网络有关的所有系统调用. -e strace=signal 跟踪所有与系统信号有关的 系统调用 -e trace=ipc 跟踪所有与进程通讯有关的系统调用 -e abbrev=set 设定strace输出的系统调用的结果集.-v 等与 abbrev=none.默认为abbrev=all. -e raw=set 将指定的系统调用的参数以十六进制显示. -e signal=set 指定跟踪的系统信号.默认为all.如 signal=!SIGIO(或者signal=!io),表示不跟踪SIGIO信号. -e read=set 输出从指定文件中读出 的数据.例如: -e read=3,5 -e write=set 输出写入到指定文件中的数据.-o file -- send trace output to FILE instead of stderr 将strace的输出写入文件filename-O overhead -- set overhead for tracing syscalls to OVERHEAD usecs-p pid -- trace process with process id PID, may be repeated 跟踪指定的进程pid.-D -- run tracer process as a detached grandchild, not as parent-s strsize -- limit length of print strings to STRSIZE chars (default 32) 指定输出的字符串的最大长度.默认为32.文件名一直全部输出-S sortby -- sort syscall counts by: time, calls, name, nothing (default time)-u username -- run command as username handling setuid and/or setgid 以username的UID和GID执行被跟踪的命令-E var=val -- put var=val in the environment for command-E var -- remove var from the environment for command","categories":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://yoursite.com/categories/Linux命令/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"Strace","slug":"Strace","permalink":"http://yoursite.com/tags/Strace/"}]},{"title":"SSH代理登录服务器","slug":"SSH代理登录","date":"2016-12-15T06:47:59.000Z","updated":"2016-12-15T07:10:33.000Z","comments":true,"path":"2016/12/15/SSH代理登录/","link":"","permalink":"http://yoursite.com/2016/12/15/SSH代理登录/","excerpt":"","text":"ssh 代理登录服务器场景： 1234A机器：10.0.0.1B机器：10.0.0.2C机器：10.0.0.3D机器：10.0.0.4 现在我们在A机器上，要登陆D机器，必须要经过B、C两台跳板机，一台台的登陆太复杂，而且如果要传文件的话，那要一层层的传，我们现在要求是在A机器上直接登陆到D机器。 一：使用ProxyCommand编辑.ssh/config文件 12345678Host machineB HostName 10.0.0.2Host machineC ProxyCommand ssh -q machineB nc 10.0.0.3 22Host machineD ProxyCommand ssh -q machineC nc 10.0.0.4 22 登陆D机器时， 直接ssh machineD。注：登陆时，可能要输入BCD机器的密码，可以事先打通key。 二：使用ssh端口转发命令在B机器上 1ssh -CfgNL 2222:10.0.0.3:222 localhost 在C机器上 1ssh -CfgNL 222:10.0.0.4:22 localhost 连接D机器是，连接B机器的2222端口即可： 1ssh -p 2222 10.0.0.2","categories":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://yoursite.com/categories/Linux命令/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"ssh","slug":"ssh","permalink":"http://yoursite.com/tags/ssh/"}]},{"title":"Logrotate安装配置","slug":"Logrotate安装配置","date":"2016-12-15T06:35:43.000Z","updated":"2016-12-15T07:13:36.000Z","comments":true,"path":"2016/12/15/Logrotate安装配置/","link":"","permalink":"http://yoursite.com/2016/12/15/Logrotate安装配置/","excerpt":"","text":"原文链接：https://linux.cn/article-4126-1.html logrotate是个十分有用的工具，它可以自动对日志进行截断（或轮循）、压缩以及删除旧的日志文件。 安装logrotate安装非常简单。yum或apt-get安装即可。 1yum -y install logrotate 配置文件目录：/etc/logrotate.conf ，通常不需要对它进行修改。日志文件的轮循设置在独立的配置文件中，它（们）放在/etc/logrotate.d/目录下 配置以下给出三个配置文件的实例： 示例一创建一个log文件进行测试 123touch /var/log/test.loghead -c 20M &lt; /dev/urandom &gt; /var/log/test.log#填入一个20MB的随机比特流数据 创建配置文件/etc/logrotate.d/test.conf，并写入： 123456789101112131415161718192021/var/log/test.log&#123;monthlyrotate 5compressdelaycompressmissingoknotifemptycreate 644 root rootpostrotate /usr/bin/killall -HUP rsyslogdendscript&#125;#注释：#monthly: 日志文件将按月轮循。其它可用值为‘daily’，‘weekly’或者‘yearly’。#rotate 5: 一次将存储5个归档日志。对于第六个归档，时间最久的归档将被删除。#compress: 在轮循任务完成后，已轮循的归档将使用gzip进行压缩。#delaycompress: 总是与compress选项一起用，delaycompress选项指示logrotate不要将最近的归档压缩，压缩将在#下一次轮循周期进行。这在你或任何软件仍然需要读取最新归档时很有用。#missingok: 在日志轮循期间，任何错误将被忽略，例如“文件无法找到”之类的错误。#notifempty: 如果日志文件为空，轮循不会进行。#create 644 root root: 以指定的权限创建全新的日志文件，同时logrotate也会重命名原始日志文件。#postrotate/endscript: 在所有其它指令完成后，postrotate和endscript里面指定的命令将被执行。在这种情况下，#rsyslogd 进程将立即再次读取其配置并继续运行。 示例二我们只想要轮循一个日志文件，然而日志文件大小可以增长到50MB。 123456789#/etc/logrotate.d/test.conf 写入：/var/log/log-file &#123; size=50M rotate 5 create 644 root root postrotate /usr/bin/killall -HUP rsyslogd endscript&#125; 示例三我们想要让旧日志文件以创建日期命名，这可以通过添加dateext常熟实现。 12345678910#/etc/logrotate.d/test.conf 写入：/var/log/log-file &#123; monthly rotate 5 dateext create 644 root root postrotate /usr/bin/killall -HUP rsyslogd endscript&#125; 这将让归档文件在它们的文件名中包含日期信息。 测试logrotate可以在任何时候从命令行手动调用。要调用为/etc/lograte.d/下配置的所有日志调用logrotate： 123[root@node2 ~]# ls /etc/logrotate.d/dracut redis salt syslog test.conf vsftpd yum[root@node2 ~]# logrotate /etc/logrotate.conf 要为某个特定的配置调用logrotate： 1[root@node2 ~]# logrotate /etc/logrotate.d/test.conf 预演方式运行使用‘-d’选项以预演方式运行logrotate。要进行验证，不用实际轮循任何日志文件，可以模拟演练日志轮循并显示其输出。 1234567891011[root@node2 ~]# logrotate -d /etc/logrotate.d/test.conf reading config file /etc/logrotate.d/test.confreading config info for /var/log/test.logHandling 1 logsrotating pattern: /var/log/test.log monthly (5 rotations)empty log files are not rotated, old logs are removedconsidering log /var/log/test.log log does not need rotatingnot running postrotate script, since no logs were rotated 正如我们从上面的输出结果可以看到的，logrotate判断该轮循是不必要的。 强制方式运行 123456789101112131415161718[root@node2 bin]# logrotate -vf /etc/logrotate.d/test.conf reading config file /etc/logrotate.d/test.confreading config info for /var/log/test.logHandling 1 logsrotating pattern: /var/log/test.log forced from command line (5 rotations)empty log files are not rotated, old logs are removedconsidering log /var/log/test.log log needs rotatingrotating log /var/log/test.log, log-&gt;rotateCount is 5dateext suffix '-20150923'glob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'glob finding logs to compress failedglob finding old rotated logs failedrenaming /var/log/test.log to /var/log/test.log-20150923creating new /var/log/test.log mode = 0644 uid = 0 gid = 0running postrotate script 之后配置crontab进行定时处理。","categories":[{"name":"Linux工具","slug":"Linux工具","permalink":"http://yoursite.com/categories/Linux工具/"}],"tags":[{"name":"Logrotate","slug":"Logrotate","permalink":"http://yoursite.com/tags/Logrotate/"},{"name":"Log","slug":"Log","permalink":"http://yoursite.com/tags/Log/"}]},{"title":"Linux_inode_100%问题","slug":"Linux-inode-100-问题","date":"2016-12-15T06:31:02.000Z","updated":"2016-12-15T07:07:17.000Z","comments":true,"path":"2016/12/15/Linux-inode-100-问题/","link":"","permalink":"http://yoursite.com/2016/12/15/Linux-inode-100-问题/","excerpt":"","text":"查看系统的 innode 占用情况1df -ih 查找那个目录下文件最多12for i in /*; do echo $i; find $i | wc -l; done# find $i 会列出该目录下所有文件，然后wc -l 计算总和 删除那个目录的的所有文件一般情况下，如果这个目录下应该会有数以百万的文件，如果你直接用 rm -rf 目录名 的话效率会很低，可以用下面方法,最好开一个 screen 来处理 ```find 目录 -type f -name ‘*’ -print0 | xargs -0 rm","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"inode","slug":"inode","permalink":"http://yoursite.com/tags/inode/"}]},{"title":"Linux_inodes","slug":"Linux-inodes","date":"2016-12-15T06:18:23.000Z","updated":"2016-12-15T06:32:15.000Z","comments":true,"path":"2016/12/15/Linux-inodes/","link":"","permalink":"http://yoursite.com/2016/12/15/Linux-inodes/","excerpt":"","text":"一、inode是什么？理解inode，要从文件储存说起。 文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。 操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个sector组成一个 block。 文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。 每一个文件都有对应的inode，里面包含了与该文件有关的一些信息。 二、inode的内容inode包含文件的元信息，具体来说有以下内容： 1234567* 文件的字节数 * 文件拥有者的User ID * 文件的Group ID * 文件的读、写、执行权限 * 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。 * 链接数，即有多少文件名指向这个inode * 文件数据block的位置 可以用stat命令，查看某个文件的inode信息： 123456789$ stat sina.html File: ‘sina.html’ Size: 590188 Blocks: 1160 IO Block: 4096 regular fileDevice: ca01h/51713d Inode: 921437 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2016-08-03 18:08:50.961342023 +0800Modify: 2016-08-01 11:11:43.600409902 +0800Change: 2016-08-01 11:11:43.600409902 +0800 Birth: - 三、inode的大小inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。 每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。 查看每个硬盘分区的inode总数和已经使用的数量，可以使用df -i命令。 123456789$ df -iFilesystem Inodes IUsed IFree IUse% Mounted on/dev/xvda1 2621440 295029 2326411 12% /none 127041 11 127030 1% /sys/fs/cgroupudev 124329 424 123905 1% /devtmpfs 127041 338 126703 1% /runnone 127041 3 127038 1% /run/locknone 127041 1 127040 1% /run/shmnone 127041 2 127039 1% /run/user 查看每个inode节点的大小，可以用如下命令 123$ sudo dumpe2fs -h /dev/xvda1 | grep \"Inode size\"dumpe2fs 1.42.9 (4-Feb-2014)Inode size: 256 由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。 四、inode号码每个inode都有一个号码，操作系统用inode号码来识别不同的文件。 这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。 表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。使用ls -i命令，可以看到文件名对应的inode号码： 12$ ls -i sina.html921437 sina.html 五、目录文件Unix/Linux系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。 ls -i命令列出整个目录文件，即文件名和inode号码： 12$ ls -i /mnt/919572 a.py 919588 b.py 919592 kong1 919591 kong2 919546 passwd 理解了上面这些知识，就能理解目录的权限。目录文件的读权限（r）和写权限（w），都是针对目录文件本身。由于目录文件内只有文件名和inode号码，所以如果只有读权限，只能获取文件名，无法获取其他信息，因为其他信息都储存在inode节点中，而读取inode节点内的信息需要目录文件的执行权限（x）。 六、硬链接一般情况下，文件名和inode号码是”一一对应”关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。 这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为”硬链接”（hard link）。 ln命令可以创建硬链接： 12345678910111213141516171819ln 源文件 目标文件$ touch testa$ ln testa testb$ ll -i test*919070 -rw-r--r-- 2 root root 0 Aug 4 09:49 testa919070 -rw-r--r-- 2 root root 0 Aug 4 09:49 testb# 一些更改操作,更改操作会同时更改两个文件，删除其中一个，不会影响到另一个$ echo aa &gt; testa$ cat testbaa$ echo bb &gt; testb$ cat testabb$ rm -rf testa$ lsa.py b.py kong1 kong2 passwd testb testv$ cat testbbb 运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做”链接数”，记录指向该inode的文件名总数，这时就会增加1。 反过来，删除一个文件名，就会使得inode节点中的”链接数”减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。这里顺便说一下目录文件的”链接数”。创建目录时，默认会生成两个目录项：”.”和”..”。前者的inode号码就是当前目录的inode号码，等同于当前目录的”硬链接”；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的”硬链接”。所以，任何一个目录的”硬链接”总数，总是等于2加上它的子目录总数（含隐藏目录）。 七、软链接文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的”软链接”（soft link）或者”符号链接（symbolic link）。这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：&quot;No such file or directory&quot;。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode“链接数”不会因此发生变化。 1$ ln -s 源文文件或目录 目标文件或目录 八、inode的特殊作用由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。 1. 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。 2. 移动文件或重命名文件，只是改变文件名，不影响inode号码。 3. 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。 第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"inode","slug":"inode","permalink":"http://yoursite.com/tags/inode/"}]},{"title":"Python_递归","slug":"Python-递归","date":"2016-12-15T03:10:37.000Z","updated":"2016-12-15T06:16:50.000Z","comments":true,"path":"2016/12/15/Python-递归/","link":"","permalink":"http://yoursite.com/2016/12/15/Python-递归/","excerpt":"","text":"递归：函数对自身定义的引用。 每次函数调用时，针对这个调用的新命名空间会被创建，意味着当函数调用“自身”时，实际上运行的是两个不同的函数（或者说同一个函数具有两个不同的命名空间）。 阶乘计算数 n 的阶乘(n * (n-1) * (n-2) .. * 1)： 1234567891011121314# for 循环实现def fac(n): result = n for i in range(1, n): result *= i return result # 递归实现def fac(n):def rec_fac(n): if n == 1: return n else: return n * rec_fac(n - 1) 二分法12345678910111213def search(sequence, number, lower=0, upper=None): if upper is None: upper = len(sequence) - 1 if lower == upper: assert number == sequence[upper] return upper else: middle = (lower + upper)//2 if number &gt; sequence[middle]: return search(sequence, number, middle+1, upper) else: return search(sequence, number, lower, middle) 查找目录下的所有文件123456def Test(rootDir): for lists in os.listdir(rootDir): path = os.path.join(rootDir, lists) print path if os.path.isdir(path): Test(path)","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python语法","slug":"Python语法","permalink":"http://yoursite.com/tags/Python语法/"},{"name":"递归","slug":"递归","permalink":"http://yoursite.com/tags/递归/"}]}]}